{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Lagoon # Lagoon - the Open Source Application Delivery Platform for Kubernetes # Lagoon gives developers what they dream about. It's a system that allows developers to run the exact same code in their local and production environment. The same Docker images, the same service configurations, and the same code. Who are you? # If you want to use Lagoon to host your website or application, visit Using Lagoon . If you want to develop Lagoon (add features, fix bugs), Developing Lagoon . TL;DR: How Lagoon Works # Developers define and configure needed services within YAML files. When they are happy, they push the code to Git. Lagoon parses the YAML files and adds in any additional needed configuration. Lagoon builds the needed Docker images. Lagoon pushes them to a Docker registry. Lagoon creates the needed resources in Kubernetes. Lagoon monitors the deployment of the containers. When all is done, Lagoon informs the developers in different ways (Slack, email, website, etc.). Help? # Questions? Ideas? Meet the maintainers and contributors. Chat with us on the Lagoon Discord: https://discord.gg/te5hHe95JE A couple of things about Lagoon # Lagoon is based on microservices . The deployment and build workflow is very complex. We have multiple version control sources, multiple clusters, and multiple notification systems. Each deployment is unique and can take from seconds to hours. It's built with flexibility and robustness in mind. Microservices communicate through a messaging system, which allows us to scale individual services up and down. It allows us to survive down times of individual services. It also allows us to try out new parts of Lagoon in production without affecting others. Lagoon uses many programming languages . Each programming language has specific strengths. We try to decide which language makes the most sense for each service. Currently, a lot of Lagoon is built in Node.js. This is partly because we started with Node.js, but also because Node.js allows asynchronous processing of webhooks, tasks and more. We are likely going to change the programming language of some services. This is what is great about microservices! We can replace a single service with another language without worrying about other parts of the platform. Lagoon is not Drupal-specific . Everything has been built so that it can run any Docker image. There are existing Docker images for Drupal, and support for Drupal-specific tools like Drush. But that's it! Lagoon is DevOps . It allows developers to define the services they need and customize them as they need. You might think this is not the right way to do it, and gives too much power to developers. We believe that as system engineers, we need to empower developers. If we allow developers to define services locally, and test them locally, they will find bugs and mistakes themselves. Lagoon runs on Docker and Kubernetes. (That one should be obvious, right?) Lagoon can be completely locally developed and tested. Lagoon is completely integration tested . This means we can test the whole process. From receiving Git webhooks to deploying into a Docker container, the same Git hash is deployed in the cluster. Most important: It's a work in progress . It's not done yet. At amazee.io, we believe that as a hosting community, we need to work together and share code where we can. We want you to understand the Lagoon infrastructure and how the services work together. Here is a schema (it's a little out of date - it doesn't include some of the more recent services we've added, or cover Kubernetes, so we're working on an update!): https://www.lucidchart.com/documents/view/a3cf0c4f-1bc1-438f-977d-4b26f235ceac \u200c History of Lagoon # As described, Lagoon is a dream come true. At amazee.io, we've been hosting Drupal for more than 8 years. This is the fourth major iteration of our hosting platform. The third iteration was built around Puppet and Ansible. Every single piece of the platform was done with configuration management. This allowed very fast setup of new servers, but at the same time was also lacking customizability for developers. We implemented some customizability, with some already with Docker in production. However, we were never completely happy with it. We realized that our existing platform wasn't enough. With the rise of decoupled Drupal, the need to run Node.js on the server side, the requests for Elasticsearch, and different Solr versions, we had to do more. \u200c At the same time, we've been using Docker for many years for local development. It was always an idea to use Docker for everything in production. The only problem was the connection between local development and production environments. There are other systems that allow you to run Drupal in Docker in production. But, nothing allowed you to test the exact same images and services locally and in production. Lagoon was born in 2017. It has since been developed into a system that runs Docker in production. Lagoon has replaced our third generation hosting platform with a cutting edge all Docker-based system. Open Source # At amazee.io, we believe in open source. It was always troubling for us that open source code like Drupal was hosted on proprietary hosting platforms. The strength and success of a hosting company is not just their deployment systems or service configurations. It's the the people and knowledge that run the platform. The processes, skills, ability to react to unforeseen situations, and last but not least, the support they provide their clients. License # Lagoon is available under an Apache 2.0 License .","title":"Home"},{"location":"#lagoon","text":"","title":"Lagoon"},{"location":"#lagoon-the-open-source-application-delivery-platform-for-kubernetes","text":"Lagoon gives developers what they dream about. It's a system that allows developers to run the exact same code in their local and production environment. The same Docker images, the same service configurations, and the same code.","title":"Lagoon - the Open Source Application Delivery Platform for Kubernetes"},{"location":"#who-are-you","text":"If you want to use Lagoon to host your website or application, visit Using Lagoon . If you want to develop Lagoon (add features, fix bugs), Developing Lagoon .","title":"Who are you?"},{"location":"#tldr-how-lagoon-works","text":"Developers define and configure needed services within YAML files. When they are happy, they push the code to Git. Lagoon parses the YAML files and adds in any additional needed configuration. Lagoon builds the needed Docker images. Lagoon pushes them to a Docker registry. Lagoon creates the needed resources in Kubernetes. Lagoon monitors the deployment of the containers. When all is done, Lagoon informs the developers in different ways (Slack, email, website, etc.).","title":"TL;DR: How Lagoon Works"},{"location":"#help","text":"Questions? Ideas? Meet the maintainers and contributors. Chat with us on the Lagoon Discord: https://discord.gg/te5hHe95JE","title":"Help?"},{"location":"#a-couple-of-things-about-lagoon","text":"Lagoon is based on microservices . The deployment and build workflow is very complex. We have multiple version control sources, multiple clusters, and multiple notification systems. Each deployment is unique and can take from seconds to hours. It's built with flexibility and robustness in mind. Microservices communicate through a messaging system, which allows us to scale individual services up and down. It allows us to survive down times of individual services. It also allows us to try out new parts of Lagoon in production without affecting others. Lagoon uses many programming languages . Each programming language has specific strengths. We try to decide which language makes the most sense for each service. Currently, a lot of Lagoon is built in Node.js. This is partly because we started with Node.js, but also because Node.js allows asynchronous processing of webhooks, tasks and more. We are likely going to change the programming language of some services. This is what is great about microservices! We can replace a single service with another language without worrying about other parts of the platform. Lagoon is not Drupal-specific . Everything has been built so that it can run any Docker image. There are existing Docker images for Drupal, and support for Drupal-specific tools like Drush. But that's it! Lagoon is DevOps . It allows developers to define the services they need and customize them as they need. You might think this is not the right way to do it, and gives too much power to developers. We believe that as system engineers, we need to empower developers. If we allow developers to define services locally, and test them locally, they will find bugs and mistakes themselves. Lagoon runs on Docker and Kubernetes. (That one should be obvious, right?) Lagoon can be completely locally developed and tested. Lagoon is completely integration tested . This means we can test the whole process. From receiving Git webhooks to deploying into a Docker container, the same Git hash is deployed in the cluster. Most important: It's a work in progress . It's not done yet. At amazee.io, we believe that as a hosting community, we need to work together and share code where we can. We want you to understand the Lagoon infrastructure and how the services work together. Here is a schema (it's a little out of date - it doesn't include some of the more recent services we've added, or cover Kubernetes, so we're working on an update!): https://www.lucidchart.com/documents/view/a3cf0c4f-1bc1-438f-977d-4b26f235ceac \u200c","title":"A couple of things about Lagoon"},{"location":"#history-of-lagoon","text":"As described, Lagoon is a dream come true. At amazee.io, we've been hosting Drupal for more than 8 years. This is the fourth major iteration of our hosting platform. The third iteration was built around Puppet and Ansible. Every single piece of the platform was done with configuration management. This allowed very fast setup of new servers, but at the same time was also lacking customizability for developers. We implemented some customizability, with some already with Docker in production. However, we were never completely happy with it. We realized that our existing platform wasn't enough. With the rise of decoupled Drupal, the need to run Node.js on the server side, the requests for Elasticsearch, and different Solr versions, we had to do more. \u200c At the same time, we've been using Docker for many years for local development. It was always an idea to use Docker for everything in production. The only problem was the connection between local development and production environments. There are other systems that allow you to run Drupal in Docker in production. But, nothing allowed you to test the exact same images and services locally and in production. Lagoon was born in 2017. It has since been developed into a system that runs Docker in production. Lagoon has replaced our third generation hosting platform with a cutting edge all Docker-based system.","title":"History of Lagoon"},{"location":"#open-source","text":"At amazee.io, we believe in open source. It was always troubling for us that open source code like Drupal was hosted on proprietary hosting platforms. The strength and success of a hosting company is not just their deployment systems or service configurations. It's the the people and knowledge that run the platform. The processes, skills, ability to react to unforeseen situations, and last but not least, the support they provide their clients.","title":"Open Source"},{"location":"#license","text":"Lagoon is available under an Apache 2.0 License .","title":"License"},{"location":"code-of-conduct/","text":"Code of Conduct # Our Pledge # In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation. Our Standards # Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language. Being respectful of differing viewpoints and experiences. Gracefully accepting constructive criticism. Focusing on what is best for the community. Showing empathy towards other community members. Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances. Trolling, insulting/derogatory comments, and personal or political attacks. Public or private harassment. Publishing others' private information, such as a physical or electronic address, without explicit permission. Other conduct which could reasonably be considered inappropriate in a professional setting. Our Responsibilities # Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope # This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project email address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Enforcement # Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at uselagoon@amazee.io . The project team will review and investigate all complaints, and will respond in a way that it deems appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership. Attribution # This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at http://contributor-covenant.org/version/1/4 .","title":"Code of Conduct"},{"location":"code-of-conduct/#code-of-conduct","text":"","title":"Code of Conduct"},{"location":"code-of-conduct/#our-pledge","text":"In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.","title":"Our Pledge"},{"location":"code-of-conduct/#our-standards","text":"Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language. Being respectful of differing viewpoints and experiences. Gracefully accepting constructive criticism. Focusing on what is best for the community. Showing empathy towards other community members. Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances. Trolling, insulting/derogatory comments, and personal or political attacks. Public or private harassment. Publishing others' private information, such as a physical or electronic address, without explicit permission. Other conduct which could reasonably be considered inappropriate in a professional setting.","title":"Our Standards"},{"location":"code-of-conduct/#our-responsibilities","text":"Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.","title":"Our Responsibilities"},{"location":"code-of-conduct/#scope","text":"This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project email address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.","title":"Scope"},{"location":"code-of-conduct/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at uselagoon@amazee.io . The project team will review and investigate all complaints, and will respond in a way that it deems appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.","title":"Enforcement"},{"location":"code-of-conduct/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at http://contributor-covenant.org/version/1/4 .","title":"Attribution"},{"location":"contributing/","text":"Contributing # We gladly welcome any and all contributions to Lagoon! What kind of contributions do we need? # Lagoon benefits from any kind of contribution - whether it's a bugfix, new feature, documentation update, or simply some queue maintenance - we're happy that you want to help Developing for Lagoon # There's a whole section on how to get Lagoon running on your local machine using KinD over at Developing Lagoon . This documentation is still very WIP - but there are a lot of Makefile routines to help you out. Installing Lagoon # We've got another section that outlines how to install Lagoon from Helm charts at Installing Lagoon Into Existing Kubernetes Cluster - we'd love to get this process as slick as possible! Help us with our examples # Right now one of our biggest needs is putting together examples of Lagoon working with various content management systems, etc, other than Drupal. If you can spin up an open source CMS or framework that we don\u2019t currently have as a docker-compose stack, send us a PR. Look at the existing examples at https://github.com/uselagoon/lagoon-examples for tips, pointers and starter issues. One small catch \u2013 wherever possible, we\u2019d like them to be built using our base Docker hub images https://hub.docker.com/u/uselagoon \u2013 if we don\u2019t have a suitable image, or our images need modifying \u2013 throw us a PR (if you can) or create an issue (so someone else can) at https://github.com/uselagoon/lagoon-images . Help us improve our existing examples, if you can - are we following best practices, is there something we\u2019re doing that doesn\u2019t make sense? Bonus points for anyone that helps contribute to tests for any of these examples \u2013 we\u2019ve got some example tests in a couple of the projects you can use for guidance \u2013 https://github.com/amazeeio/drupal-example-simple/blob/8.x/TESTING_dockercompose.md . The testing framework we\u2019re using is Leia , from the excellent team behind Lando . Help us to document our other examples better \u2013 we\u2019re not expecting a full manuscript, but tidy-ups, links to helpful resources and clarifying statements are all super-awesome. If you have any questions, reach out to us on Discord ! I found a security issue \ud83d\udd13 # We take security very seriously. If you discover a security issue or think you found one, please bring it to the maintainers' attention. Danger: Please send your findings to security@amazee.io . Please DO NOT file a GitHub issue for them. Security reports are greatly appreciated and will receive public karma and swag! We're also working on a Bug Bounty system. I found an issue # We're always interested in fixing issues, therefore issue reports are very welcome. Please make sure to check that your issue does not already exist in the issue queue . I have a feature request or idea # Cool! Create an issue and we're happy to look over it. We can't guarantee that it will be implemented. But we are always interested in hearing ideas of what we could bring to Lagoon. Another good way is also to talk to us via Discord about your idea. Join today ! I wrote some code # Epic! Please send us a pull request for it, we will do our best to review it and merge it if possible.","title":"Contributing"},{"location":"contributing/#contributing","text":"We gladly welcome any and all contributions to Lagoon!","title":"Contributing"},{"location":"contributing/#what-kind-of-contributions-do-we-need","text":"Lagoon benefits from any kind of contribution - whether it's a bugfix, new feature, documentation update, or simply some queue maintenance - we're happy that you want to help","title":"What kind of contributions do we need?"},{"location":"contributing/#developing-for-lagoon","text":"There's a whole section on how to get Lagoon running on your local machine using KinD over at Developing Lagoon . This documentation is still very WIP - but there are a lot of Makefile routines to help you out.","title":"Developing for Lagoon"},{"location":"contributing/#installing-lagoon","text":"We've got another section that outlines how to install Lagoon from Helm charts at Installing Lagoon Into Existing Kubernetes Cluster - we'd love to get this process as slick as possible!","title":"Installing Lagoon"},{"location":"contributing/#help-us-with-our-examples","text":"Right now one of our biggest needs is putting together examples of Lagoon working with various content management systems, etc, other than Drupal. If you can spin up an open source CMS or framework that we don\u2019t currently have as a docker-compose stack, send us a PR. Look at the existing examples at https://github.com/uselagoon/lagoon-examples for tips, pointers and starter issues. One small catch \u2013 wherever possible, we\u2019d like them to be built using our base Docker hub images https://hub.docker.com/u/uselagoon \u2013 if we don\u2019t have a suitable image, or our images need modifying \u2013 throw us a PR (if you can) or create an issue (so someone else can) at https://github.com/uselagoon/lagoon-images . Help us improve our existing examples, if you can - are we following best practices, is there something we\u2019re doing that doesn\u2019t make sense? Bonus points for anyone that helps contribute to tests for any of these examples \u2013 we\u2019ve got some example tests in a couple of the projects you can use for guidance \u2013 https://github.com/amazeeio/drupal-example-simple/blob/8.x/TESTING_dockercompose.md . The testing framework we\u2019re using is Leia , from the excellent team behind Lando . Help us to document our other examples better \u2013 we\u2019re not expecting a full manuscript, but tidy-ups, links to helpful resources and clarifying statements are all super-awesome. If you have any questions, reach out to us on Discord !","title":"Help us with our examples"},{"location":"contributing/#i-found-a-security-issue","text":"We take security very seriously. If you discover a security issue or think you found one, please bring it to the maintainers' attention. Danger: Please send your findings to security@amazee.io . Please DO NOT file a GitHub issue for them. Security reports are greatly appreciated and will receive public karma and swag! We're also working on a Bug Bounty system.","title":"I found a security issue \ud83d\udd13"},{"location":"contributing/#i-found-an-issue","text":"We're always interested in fixing issues, therefore issue reports are very welcome. Please make sure to check that your issue does not already exist in the issue queue .","title":"I found an issue"},{"location":"contributing/#i-have-a-feature-request-or-idea","text":"Cool! Create an issue and we're happy to look over it. We can't guarantee that it will be implemented. But we are always interested in hearing ideas of what we could bring to Lagoon. Another good way is also to talk to us via Discord about your idea. Join today !","title":"I have a feature request or idea"},{"location":"contributing/#i-wrote-some-code","text":"Epic! Please send us a pull request for it, we will do our best to review it and merge it if possible.","title":"I wrote some code"},{"location":"administering-lagoon/feature-flags/","text":"Feature flags # Some Lagoon features can be controlled by setting feature flags. This is designed to assist users and administrators to roll out new platform features in a controlled manner. Environment variables # The following environment variables can be set on an environment or project to toggle feature flags. Environment Variable Name Active scope Version introduced Version removed Default Value Description LAGOON_FEATURE_FLAG_ROOTLESS_WORKLOAD global 2.2.0 - disabled Set to enabled to set a non-root pod security context on the pods in this environment or project. This flag will eventually be deprecated, at which point non-root workloads will be enforced. LAGOON_FEATURE_FLAG_ISOLATION_NETWORK_POLICY global 2.2.0 - disabled Set to enabled to add a default namespace isolation network policy to each environment on deployment. This flag will eventually be deprecated, at which point the namespace isolation network policy will be enforced. NOTE: enabling and then disabling this feature will not remove any existing network policy from previous deployments. Those must be removed manually. Cluster-level controls # Feature flags may also be controlled at the cluster level. There is support for this in the lagoon-build-deploy chart . For each feature flag there are two flavours of values which can be set: default and force . default controls the default policy for environments deployed to the cluster, but can be overridden at the project or environment level by the environment variables documented above. force also controls the policy for environments deployed to the cluster, but cannot be overridden by the environment variables documented above.","title":"Feature Flags"},{"location":"administering-lagoon/feature-flags/#feature-flags","text":"Some Lagoon features can be controlled by setting feature flags. This is designed to assist users and administrators to roll out new platform features in a controlled manner.","title":"Feature flags"},{"location":"administering-lagoon/feature-flags/#environment-variables","text":"The following environment variables can be set on an environment or project to toggle feature flags. Environment Variable Name Active scope Version introduced Version removed Default Value Description LAGOON_FEATURE_FLAG_ROOTLESS_WORKLOAD global 2.2.0 - disabled Set to enabled to set a non-root pod security context on the pods in this environment or project. This flag will eventually be deprecated, at which point non-root workloads will be enforced. LAGOON_FEATURE_FLAG_ISOLATION_NETWORK_POLICY global 2.2.0 - disabled Set to enabled to add a default namespace isolation network policy to each environment on deployment. This flag will eventually be deprecated, at which point the namespace isolation network policy will be enforced. NOTE: enabling and then disabling this feature will not remove any existing network policy from previous deployments. Those must be removed manually.","title":"Environment variables"},{"location":"administering-lagoon/feature-flags/#cluster-level-controls","text":"Feature flags may also be controlled at the cluster level. There is support for this in the lagoon-build-deploy chart . For each feature flag there are two flavours of values which can be set: default and force . default controls the default policy for environments deployed to the cluster, but can be overridden at the project or environment level by the environment variables documented above. force also controls the policy for environments deployed to the cluster, but cannot be overridden by the environment variables documented above.","title":"Cluster-level controls"},{"location":"administering-lagoon/graphql-queries/","text":"GraphQL API # Running GraphQL queries # Direct API interactions in Lagoon are done via GraphQL . In order to authenticate with the API, we need a JWT (JSON Web Token) that allows us to use the GraphQL API as admin. To generate this token, open the terminal of the storage-calculator pod via your Kubernetes UI, or via kubectl and run the following command: ./create_jwt.sh This will return a long string which is the JWT token. Make a note of this, as we will need it to send queries. We also need the URL of the API endpoint, which can be found under \"Ingresses\" in your Kubernetes UI or via kubectl on the command line. Make a note of this endpoint URL, which we will also need. To compose and send GraphQL queries, we recommend GraphiQL.app , a desktop GraphQL client with features such as autocomplete. To continue with the next steps, install and start the app. Under \"GraphQL Endpoint\", enter the API endpoint URL with /graphql on the end. Then click on \"Edit HTTP Headers\" and add a new header: \"Header name\": Authorization \"Header value\": Bearer [JWT token] (make sure that the JWT token has no spaces, as this would not work) Press ESC to close the HTTP header overlay and now we are ready to send the first GraphQL request! Enter this in the left panel query allProjects{ allProjects { name } } And press the \u25b6\ufe0f button (or press CTRL+ENTER). If all went well, your first GraphQL response should appear shortly afterwards in the right pane. Creating the first project # Let's create the first project for Lagoon to deploy! For this we'll use the queries from the GraphQL query template in create-project.gql . For each of the queries (the blocks starting with mutation { ), fill in all of the empty fields marked by TODO comments and run the queries in GraphiQL.app. This will create one of each of the following two objects: kubernetes : The Kubernetes (or Openshift) cluster to which Lagoon should deploy. Lagoon is not only capable of deploying to its own Kubernetes cluster, but also to any Kubernetes cluster anywhere in the world. project : The Lagoon project to be deployed, which is a Git repository with a .lagoon.yml configuration file committed in the root. Allowing access to the project # In Lagoon, each developer authenticates via their SSH key(s). This determines their access to: The Lagoon API, where they can see and edit projects they have access to. Remote shell access to containers that are running in projects they have access to. The Lagoon logging system, where a developer can find request logs, container logs, Lagoon logs and more. To allow access to the project, we first need to add a new group to the API: mutation { addGroup ( input: { # TODO: Enter the name for your new group. name: \"\" } ) { id name } } Then we need to add a new user to the API: mutation { addUser( input: { email: \"michael.schmid@example.com\" firstName: \"Michael\" lastName: \"Schmid\" comment: \"CTO\" } ) { # TODO: Make a note of the user ID that is returned. id } } Then we can add an SSH public key for the user to the API: mutation { addSshKey( input: { # TODO: Fill in the name field. # This is a non-unique identifier for the SSH key. name: \"\" # TODO: Fill in the keyValue field. # This is the actual SSH public key (without the type at the beginning and without the comment at the end, ex. `AAAAB3NzaC1yc2EAAAADAQ...3QjzIOtdQERGZuMsi0p`). keyValue: \"\" # TODO: Fill in the keyType field. # Valid values are either SSH_RSA, SSH_ED25519, ECDSA_SHA2_NISTP256/384/521 keyType: SSH_RSA user: { # TODO: Fill in the userId field. # This is the user ID that we noted from the addUser query. id:\"0\", email:\"michael.schmid@example.com\" } } ) { id } } After we add the key, we need to add the user to a group: mutation { addUserToGroup ( input: { user: { #TODO: Enter the email address of the user. email: \"\" } group: { #TODO: Enter the name of the group you want to add the user to. name: \"\" } #TODO: Enter the role of the user. role: OWNER } ) { id name } } After running one or more of these kinds of queries, the user will be granted access to create tokens via SSH, access containers and more. Adding notifications to the project # If you want to know what is going on during a deployment, we suggest configuring notifications for your project, which provide: Push notifications Build start information Build success or failure messages And many more! As notifications can be quite different in terms of the information they need, each notification type has its own mutation. As with users, we first add the notification: mutation { addNotificationSlack( input: { # TODO: Fill in the name field. # This is your own identifier for the notification. name: \"\" # TODO: Fill in the channel field. # This is the channel for the message to be sent to. channel: \"\" # TODO: Fill in the webhook field. # This is the URL of the webhook where messages should be sent, this is usually provided by the chat system to you. webhook: \"\" } ) { id } } After the notification is created, we can now assign it to our project: mutation { addNotificationToProject( input: { notificationType: SLACK # TODO: Fill in the project field. # This is the project name. project: \"\" # TODO: Fill in the notification field. # This is the notification name. notificationName: \"\" # TODO: OPTIONAL # The kind notification class you're interested in defaults to DEPLOYMENT contentType: DEPLOYMENT/PROBLEM # TODO: OPTIONAL # Related to contentType PROBLEM, we can set the threshold for the kinds of problems # we'd like to be notified about notificationSeverityThreshold \"NONE/UNKNOWN/NEGLIGIBLE/LOW/MEDIUM/HIGH/CRITICAL } ) { id } } Now for every deployment you will receive messages in your defined channel. Example GraphQL queries # Adding a new Kubernetes target # Note: In Lagoon, both addKubernetes and addOpenshift can be used for both Kubernetes and OpenShift targets - either will work interchangeably. The cluster to which Lagoon should deploy. mutation { addKubernetes( input: { # TODO: Fill in the name field. # This is the unique identifier of the cluster. name: \"\" # TODO: Fill in consoleUrl field. # This is the URL of the Kubernetes cluster consoleUrl: \"\" # TODO: Fill in the token field. # This is the token of the `lagoon` service account created in this cluster (this is the same token that we also used during installation of Lagoon). token: \"\" } ) { name id } } Adding a group to a project # This query will add a group to a project. Users of that group will be able to access the project. They will be able to make changes, based on their role in that group. mutation { addGroupsToProject ( input: { project: { #TODO: Enter the name of the project. name: \"\" } groups: { #TODO: Enter the name of the group that will be added to the project. name: \"\" } } ) { id } } Adding a new project # This query adds a new Lagoon project to be deployed, which is a Git repository with a .lagoon.yml configuration file committed in the root. If you omit the privateKey field, a new SSH key for the project will be generated automatically. If you would like to reuse a key from another project. you will need to supply the key in the addProject mutation. mutation { addProject( input: { # TODO: Fill in the name field. # This is the project name. name: \"\" # TODO: Fill in the private key field (replace newlines with '\\n'). # This is the private key for a project, which is used to access the Git code. privateKey: \"\" # TODO: Fill in the Kubernetes field. # This is the id of the Kubernetes or Openshift to assign to the project. kubernetes: 0 # TODO: Fill in the name field. # This is the project name. gitUrl: \"\" # TODO: Fill in the branches to be deployed. branches: \"\" # TODO: Define the production environment. productionEnvironment: \"\" } ) { name kubernetes { name id } gitUrl activeSystemsDeploy activeSystemsRemove branches pullrequests } } List projects and groups # This is a good query to see an overview of all projects, clusters and groups that exist within our Lagoon. query { allProjects { name gitUrl } allKubernetes { name id } allGroups{ id name members { # This will display the users in this group. user { id firstName lastName } role } groups { id name } } } Single project # If you want a detailed look at a single project, this query has been proven quite good: query { projectByName( # TODO: Fill in the project name. name: \"\" ) { id branches gitUrl pullrequests productionEnvironment notifications(type: SLACK) { ... on NotificationSlack { name channel webhook id } } environments { name deployType environmentType } kubernetes { id } } } Querying a project by its Git URL # Don't remember the name of a project, but know the Git URL? Search no longer, there is a GraphQL query for that: query { projectByGitUrl(gitUrl: \"git@server.com:org/repo.git\") { name } } Updating objects # The Lagoon GraphQL API can not only display objects and create objects, it also has the capability to update existing objects, using a patch object . Update the branches to deploy within a project: mutation { updateProject( input: { id: 109, patch: { branches: \"^(prod|stage|dev|update)$\" } } ) { id } } Update the production environment within a project: Warning: This requires a redeploy in order for the changes to be reflected in the containers. mutation { updateProject( input: { id: 109, patch: { productionEnvironment: \"main\" } } ) { id } } You can also combine multiple changes at once: mutation { updateProject( input: { id: 109 patch: { productionEnvironment: \"main\" branches: \"^(prod|stage|dev|update)$\" } } ) { id } } Deleting Environments # You can also use the Lagoon GraphQL API to delete an environment. You'll need to know the project name and the environment name in order to run the command. mutation { deleteEnvironment( input: { # TODO: Fill in the name field. # This is the environment name. name:\"\" # TODO: Fill in the project field. # This is the project name. project:\"\" execute:true } ) } Querying a project to see what groups and users are assigned # Want to see what groups and users have access to a project? Want to know what their roles are? Do I have a query for you! Using the query below you can search for a project and display the groups, users, and roles that are assigned to that project. query search{ projectByName( #TODO: Enter the name of the project. name: \"\" ) { id, branches, productionEnvironment, pullrequests, gitUrl, kubernetes { id }, groups{ id name groups { id name } members { role user { id email } } } } } Maintaining project metadata # Project metadata can be assigned using arbitrary key/value pairs. Projects can then be queried by the associated metadata; for example you may categorize projects by type of software, version number, or any other categorization you may wish to query on later. Add/update metadata on a project # Updates to metadata expect a key/value pair. It operates as an UPSERT , meaning if a key already exists the value will be updated, otherwise inserted. You may have any number of k/v pairs stored against a project. mutation { updateProjectMetadata( input: { id: 1, patch: { key: \"type\", value: \"saas\" } } ) { id metadata } } Query for projects by metadata # Queries may be by key only (e.g return all projects where a specific key exists) or both key and value where both key and value must match. All projects that have the version tag: query projectsByMetadata { projectsByMetadata(metadata: [{key: \"version\"] ) { id name } } All projects that have the version tag, specifically version 8 : query projectsByMetadata { projectsByMetadata(metadata: [{key: \"version\", value: \"8\"] ) { id name } } Removing metadata on a project # Metadata can be removed on a per-key basis. Other metadata key/value pairs will persist. mutation { removeProjectMetadataByKey ( input: { id: 1, key: \"version\" } ) { id metadata } }","title":"GraphQL API"},{"location":"administering-lagoon/graphql-queries/#graphql-api","text":"","title":"GraphQL API"},{"location":"administering-lagoon/graphql-queries/#running-graphql-queries","text":"Direct API interactions in Lagoon are done via GraphQL . In order to authenticate with the API, we need a JWT (JSON Web Token) that allows us to use the GraphQL API as admin. To generate this token, open the terminal of the storage-calculator pod via your Kubernetes UI, or via kubectl and run the following command: ./create_jwt.sh This will return a long string which is the JWT token. Make a note of this, as we will need it to send queries. We also need the URL of the API endpoint, which can be found under \"Ingresses\" in your Kubernetes UI or via kubectl on the command line. Make a note of this endpoint URL, which we will also need. To compose and send GraphQL queries, we recommend GraphiQL.app , a desktop GraphQL client with features such as autocomplete. To continue with the next steps, install and start the app. Under \"GraphQL Endpoint\", enter the API endpoint URL with /graphql on the end. Then click on \"Edit HTTP Headers\" and add a new header: \"Header name\": Authorization \"Header value\": Bearer [JWT token] (make sure that the JWT token has no spaces, as this would not work) Press ESC to close the HTTP header overlay and now we are ready to send the first GraphQL request! Enter this in the left panel query allProjects{ allProjects { name } } And press the \u25b6\ufe0f button (or press CTRL+ENTER). If all went well, your first GraphQL response should appear shortly afterwards in the right pane.","title":"Running GraphQL queries"},{"location":"administering-lagoon/graphql-queries/#creating-the-first-project","text":"Let's create the first project for Lagoon to deploy! For this we'll use the queries from the GraphQL query template in create-project.gql . For each of the queries (the blocks starting with mutation { ), fill in all of the empty fields marked by TODO comments and run the queries in GraphiQL.app. This will create one of each of the following two objects: kubernetes : The Kubernetes (or Openshift) cluster to which Lagoon should deploy. Lagoon is not only capable of deploying to its own Kubernetes cluster, but also to any Kubernetes cluster anywhere in the world. project : The Lagoon project to be deployed, which is a Git repository with a .lagoon.yml configuration file committed in the root.","title":"Creating the first project"},{"location":"administering-lagoon/graphql-queries/#allowing-access-to-the-project","text":"In Lagoon, each developer authenticates via their SSH key(s). This determines their access to: The Lagoon API, where they can see and edit projects they have access to. Remote shell access to containers that are running in projects they have access to. The Lagoon logging system, where a developer can find request logs, container logs, Lagoon logs and more. To allow access to the project, we first need to add a new group to the API: mutation { addGroup ( input: { # TODO: Enter the name for your new group. name: \"\" } ) { id name } } Then we need to add a new user to the API: mutation { addUser( input: { email: \"michael.schmid@example.com\" firstName: \"Michael\" lastName: \"Schmid\" comment: \"CTO\" } ) { # TODO: Make a note of the user ID that is returned. id } } Then we can add an SSH public key for the user to the API: mutation { addSshKey( input: { # TODO: Fill in the name field. # This is a non-unique identifier for the SSH key. name: \"\" # TODO: Fill in the keyValue field. # This is the actual SSH public key (without the type at the beginning and without the comment at the end, ex. `AAAAB3NzaC1yc2EAAAADAQ...3QjzIOtdQERGZuMsi0p`). keyValue: \"\" # TODO: Fill in the keyType field. # Valid values are either SSH_RSA, SSH_ED25519, ECDSA_SHA2_NISTP256/384/521 keyType: SSH_RSA user: { # TODO: Fill in the userId field. # This is the user ID that we noted from the addUser query. id:\"0\", email:\"michael.schmid@example.com\" } } ) { id } } After we add the key, we need to add the user to a group: mutation { addUserToGroup ( input: { user: { #TODO: Enter the email address of the user. email: \"\" } group: { #TODO: Enter the name of the group you want to add the user to. name: \"\" } #TODO: Enter the role of the user. role: OWNER } ) { id name } } After running one or more of these kinds of queries, the user will be granted access to create tokens via SSH, access containers and more.","title":"Allowing access to the project"},{"location":"administering-lagoon/graphql-queries/#adding-notifications-to-the-project","text":"If you want to know what is going on during a deployment, we suggest configuring notifications for your project, which provide: Push notifications Build start information Build success or failure messages And many more! As notifications can be quite different in terms of the information they need, each notification type has its own mutation. As with users, we first add the notification: mutation { addNotificationSlack( input: { # TODO: Fill in the name field. # This is your own identifier for the notification. name: \"\" # TODO: Fill in the channel field. # This is the channel for the message to be sent to. channel: \"\" # TODO: Fill in the webhook field. # This is the URL of the webhook where messages should be sent, this is usually provided by the chat system to you. webhook: \"\" } ) { id } } After the notification is created, we can now assign it to our project: mutation { addNotificationToProject( input: { notificationType: SLACK # TODO: Fill in the project field. # This is the project name. project: \"\" # TODO: Fill in the notification field. # This is the notification name. notificationName: \"\" # TODO: OPTIONAL # The kind notification class you're interested in defaults to DEPLOYMENT contentType: DEPLOYMENT/PROBLEM # TODO: OPTIONAL # Related to contentType PROBLEM, we can set the threshold for the kinds of problems # we'd like to be notified about notificationSeverityThreshold \"NONE/UNKNOWN/NEGLIGIBLE/LOW/MEDIUM/HIGH/CRITICAL } ) { id } } Now for every deployment you will receive messages in your defined channel.","title":"Adding notifications to the project"},{"location":"administering-lagoon/graphql-queries/#example-graphql-queries","text":"","title":"Example GraphQL queries"},{"location":"administering-lagoon/graphql-queries/#adding-a-new-kubernetes-target","text":"Note: In Lagoon, both addKubernetes and addOpenshift can be used for both Kubernetes and OpenShift targets - either will work interchangeably. The cluster to which Lagoon should deploy. mutation { addKubernetes( input: { # TODO: Fill in the name field. # This is the unique identifier of the cluster. name: \"\" # TODO: Fill in consoleUrl field. # This is the URL of the Kubernetes cluster consoleUrl: \"\" # TODO: Fill in the token field. # This is the token of the `lagoon` service account created in this cluster (this is the same token that we also used during installation of Lagoon). token: \"\" } ) { name id } }","title":"Adding a new Kubernetes target"},{"location":"administering-lagoon/graphql-queries/#adding-a-group-to-a-project","text":"This query will add a group to a project. Users of that group will be able to access the project. They will be able to make changes, based on their role in that group. mutation { addGroupsToProject ( input: { project: { #TODO: Enter the name of the project. name: \"\" } groups: { #TODO: Enter the name of the group that will be added to the project. name: \"\" } } ) { id } }","title":"Adding a group to a project"},{"location":"administering-lagoon/graphql-queries/#adding-a-new-project","text":"This query adds a new Lagoon project to be deployed, which is a Git repository with a .lagoon.yml configuration file committed in the root. If you omit the privateKey field, a new SSH key for the project will be generated automatically. If you would like to reuse a key from another project. you will need to supply the key in the addProject mutation. mutation { addProject( input: { # TODO: Fill in the name field. # This is the project name. name: \"\" # TODO: Fill in the private key field (replace newlines with '\\n'). # This is the private key for a project, which is used to access the Git code. privateKey: \"\" # TODO: Fill in the Kubernetes field. # This is the id of the Kubernetes or Openshift to assign to the project. kubernetes: 0 # TODO: Fill in the name field. # This is the project name. gitUrl: \"\" # TODO: Fill in the branches to be deployed. branches: \"\" # TODO: Define the production environment. productionEnvironment: \"\" } ) { name kubernetes { name id } gitUrl activeSystemsDeploy activeSystemsRemove branches pullrequests } }","title":"Adding a new project"},{"location":"administering-lagoon/graphql-queries/#list-projects-and-groups","text":"This is a good query to see an overview of all projects, clusters and groups that exist within our Lagoon. query { allProjects { name gitUrl } allKubernetes { name id } allGroups{ id name members { # This will display the users in this group. user { id firstName lastName } role } groups { id name } } }","title":"List projects and groups"},{"location":"administering-lagoon/graphql-queries/#single-project","text":"If you want a detailed look at a single project, this query has been proven quite good: query { projectByName( # TODO: Fill in the project name. name: \"\" ) { id branches gitUrl pullrequests productionEnvironment notifications(type: SLACK) { ... on NotificationSlack { name channel webhook id } } environments { name deployType environmentType } kubernetes { id } } }","title":"Single project"},{"location":"administering-lagoon/graphql-queries/#querying-a-project-by-its-git-url","text":"Don't remember the name of a project, but know the Git URL? Search no longer, there is a GraphQL query for that: query { projectByGitUrl(gitUrl: \"git@server.com:org/repo.git\") { name } }","title":"Querying a project by its Git URL"},{"location":"administering-lagoon/graphql-queries/#updating-objects","text":"The Lagoon GraphQL API can not only display objects and create objects, it also has the capability to update existing objects, using a patch object . Update the branches to deploy within a project: mutation { updateProject( input: { id: 109, patch: { branches: \"^(prod|stage|dev|update)$\" } } ) { id } } Update the production environment within a project: Warning: This requires a redeploy in order for the changes to be reflected in the containers. mutation { updateProject( input: { id: 109, patch: { productionEnvironment: \"main\" } } ) { id } } You can also combine multiple changes at once: mutation { updateProject( input: { id: 109 patch: { productionEnvironment: \"main\" branches: \"^(prod|stage|dev|update)$\" } } ) { id } }","title":"Updating objects"},{"location":"administering-lagoon/graphql-queries/#deleting-environments","text":"You can also use the Lagoon GraphQL API to delete an environment. You'll need to know the project name and the environment name in order to run the command. mutation { deleteEnvironment( input: { # TODO: Fill in the name field. # This is the environment name. name:\"\" # TODO: Fill in the project field. # This is the project name. project:\"\" execute:true } ) }","title":"Deleting Environments"},{"location":"administering-lagoon/graphql-queries/#querying-a-project-to-see-what-groups-and-users-are-assigned","text":"Want to see what groups and users have access to a project? Want to know what their roles are? Do I have a query for you! Using the query below you can search for a project and display the groups, users, and roles that are assigned to that project. query search{ projectByName( #TODO: Enter the name of the project. name: \"\" ) { id, branches, productionEnvironment, pullrequests, gitUrl, kubernetes { id }, groups{ id name groups { id name } members { role user { id email } } } } }","title":"Querying a project to see what groups and users are assigned"},{"location":"administering-lagoon/graphql-queries/#maintaining-project-metadata","text":"Project metadata can be assigned using arbitrary key/value pairs. Projects can then be queried by the associated metadata; for example you may categorize projects by type of software, version number, or any other categorization you may wish to query on later.","title":"Maintaining project metadata"},{"location":"administering-lagoon/graphql-queries/#addupdate-metadata-on-a-project","text":"Updates to metadata expect a key/value pair. It operates as an UPSERT , meaning if a key already exists the value will be updated, otherwise inserted. You may have any number of k/v pairs stored against a project. mutation { updateProjectMetadata( input: { id: 1, patch: { key: \"type\", value: \"saas\" } } ) { id metadata } }","title":"Add/update metadata on a project"},{"location":"administering-lagoon/graphql-queries/#query-for-projects-by-metadata","text":"Queries may be by key only (e.g return all projects where a specific key exists) or both key and value where both key and value must match. All projects that have the version tag: query projectsByMetadata { projectsByMetadata(metadata: [{key: \"version\"] ) { id name } } All projects that have the version tag, specifically version 8 : query projectsByMetadata { projectsByMetadata(metadata: [{key: \"version\", value: \"8\"] ) { id name } }","title":"Query for projects by metadata"},{"location":"administering-lagoon/graphql-queries/#removing-metadata-on-a-project","text":"Metadata can be removed on a per-key basis. Other metadata key/value pairs will persist. mutation { removeProjectMetadataByKey ( input: { id: 1, key: \"version\" } ) { id metadata } }","title":"Removing metadata on a project"},{"location":"administering-lagoon/rbac/","text":"Role-Based Access Control (RBAC) # Version 1.0 of Lagoon changed how you access your projects! Access to your project is handled via groups, with projects assigned to one or multiple groups. Users are added to groups with a role. Groups can also be nested within sub-groups. This change provides a lot more flexibility and the possibility to recreate real world teams within Lagoon. Roles # When assigning a user to a group, you need to provide a group role for that user inside this group. Each one of the 5 current existing group roles gives the user different permissions to the group and projects assigned to the group. Here are the platform-wide roles and the group roles that are currently found in Lagoon: Platform-Wide Roles # Platform-Wide Admin # The platform-wide admin has access to everything across all of Lagoon. That includes dangerous mutations like deleting all projects. Use very, very, very carefully. Platform-Wide Owner # The platform-wide owner has access to every Lagoon group, like the group owner role, and can be used if you need a user that needs access to everything but you don't want to assign the user to every group. Group Roles # Owner # The owner role can do everything within a group and its associated projects. They can add and manage users of a group. Be careful with this role, as it can delete projects and production environments! Maintainer # The maintainer role can do everything within a group and its associated projects except deleting the project itself or the production environment. They can add and manage users of a group. Developer # The developer role has SSH access only to development environments. This role cannot access, update or delete the production environment. They can run a sync task with the production environment as a source, but not as the destination. Cannot manage users of a group. Danger: IMPORTANT: This role does not prevent the deployment of the production environment as a deployment is triggered via a Git push! You need to make sure that your Git server prevents these users from pushing into the branch defined as production environment. Reporter # The reporter role has view access only. They cannot access any environments via SSH or make modifications to them. They can run cache-clear tasks. This role is mostly used for stakeholders to have access to Lagoon UI and logging. Guest # The guest role has the same privileges as the reporter role listed above. Here is a table that lists the roles and the access they have: \ud83d\udca1 Tip: Scroll to the right to see the whole table! Lagoon 1.0.0 RBAC Permission Matrix # Name Resource Scope Attributes Platform-Wide Admin Platform-Wide Owner Owner Maintainer Developer Reporter Guest Self addBackup backup add projectID Yes Yes Yes Yes Yes No No deleteBackup backup delete projectID Yes Yes Yes Yes No No No deleteAllBackups backup deleteAll Yes No No No No No No getBackupsByEnvironmentId backup view projectID Yes Yes Yes Yes Yes No No deployment view projectID Yes Yes Yes Yes Yes Yes Yes addEnvVariable (to Project) env_var project:add projectID Yes Yes Yes Yes No No No addEnvVariable (to Environment) env_var environment:add:development projectID Yes Yes Yes Yes Yes No No addEnvVariable (to Environment) env_var environment:add:production projectID Yes Yes Yes Yes No No No deleteEnvVariable env_var delete projectID Yes Yes Yes Yes No No No getEnvVarsByProjectId env_var project:view projectID Yes Yes Yes Yes No No No getEnvVarsByEnvironmentId env_var environment:view:development projectID Yes Yes Yes Yes Yes No No getEnvVarsByEnvironmentId env_var environment:view:production projectID Yes Yes Yes Yes No No No addOrUpdateEnvironment environment addOrUpdate:development projectID Yes Yes Yes Yes Yes No No addOrUpdateEnvironment environment addOrUpdate:production projectID Yes Yes Yes Yes No No No updateEnvironment environment update:development projectID Yes Yes Yes Yes Yes No No updateEnvironment environment update:production projectID Yes Yes Yes Yes No No No deleteEnvironment environment delete:development projectID Yes Yes Yes Yes Yes No No deleteEnvironment environment delete:production projectID Yes Yes Yes No No No No deleteAllEnvironments environment deleteAll Yes No No No No No No addOrUpdateEnvironmentStorage environment storage Yes Yes No No No No No addDeployment environment deploy:development projectID Yes Yes Yes Yes Yes No No addDeployment environment deploy:production projectID Yes Yes Yes Yes No No No deleteDeployment deployment delete projectID Yes Yes Yes Yes No No No updateDeployment deployment update projectID Yes Yes Yes Yes No No No setEnvironmentServices environment update:development projectID Yes Yes Yes Yes Yes No No setEnvironmentServices environment update:production projectID Yes Yes Yes Yes No No No deployEnvironmentLatest environment deploy:development projectID Yes Yes Yes Yes Yes No No deployEnvironmentLatest environment deploy:production projectID Yes Yes Yes Yes No No No deployEnvironmentBranch environment deploy:development projectID Yes Yes Yes Yes Yes No No deployEnvironmentBranch environment deploy:production projectID Yes Yes Yes Yes No No No deployEnvironmentPullrequest environment deploy:development projectID Yes Yes Yes Yes Yes No No deployEnvironmentPullrequest environment deploy:production projectID Yes Yes Yes Yes No No No deployEnvironmentPromote environment deploy:development projectID Yes Yes Yes Yes Yes No No deployEnvironmentPromote environment deploy:production projectID Yes Yes Yes Yes No No No getEnvironmentsByProjectId environment view projectID Yes Yes Yes Yes Yes Yes Yes getEnvironmentStorageMonthByEnvironmentId environment storage Yes No No No No No No getEnvironmentHoursMonthByEnvironmentId environment storage Yes No No No No No No getEnvironmentHitsMonthByEnvironmentId environment storage Yes No No No No No No getEnvironmentServicesByEnvironmentId environment view projectID Yes Yes Yes Yes Yes Yes Yes addGroup group add Yes Yes Yes Yes Yes Yes Yes updateGroup group update groupID Yes Yes Yes Yes No No No deleteGroup group delete groupID Yes Yes Yes Yes No No No deleteAllGroups group deleteAll Yes No No No No No No addUserToGroup group addUser groupID Yes Yes Yes Yes No No No removeUserFromGroup group removeUser groupID Yes Yes Yes Yes No No No addNotificationSlack notification add Yes Yes No No No No No updateNotificationSlack notification update Yes Yes No No No No No deleteNotificationSlack notification delete Yes Yes No No No No No deleteAllNotificationSlacks notification deleteAll Yes No No No No No No addNotificationRocketChat notification add Yes Yes No No No No No updateNotificationRocketChat notification update Yes Yes No No No No No deleteNotificationRocketChat notification delete Yes Yes No No No No No deleteAllNotificationRocketChats notification deleteAll Yes No No No No No No removeAllNotificationsFromAllProjects notification removeAll Yes No No No No No No getNotificationsByProjectId notification view projectID Yes Yes Yes Yes Yes No No addKubernetes kubernetes add Yes Yes No No No No No updateKubernetes kubernetes update Yes Yes No No No No No deleteKubernetes kubernetes delete Yes Yes No No No No No deleteAllKubernetes kubernetes deleteAll Yes Yes No No No No No getAllOpenshifts openshift viewAll Yes No No No No No No getOpenshiftByProjectId openshift view projectID Yes Yes Yes Yes Yes Yes Yes addNotificationToProject project addNotification projectID Yes Yes Yes Yes No No No removeNotificationFromProject project removeNotification projectID Yes Yes Yes Yes No No No addProject project add Yes Yes Yes Yes Yes Yes Yes updateProject project update projectID Yes Yes Yes Yes No No No deleteProject project delete projectID Yes Yes Yes No No No No deleteAllProjects project deleteAll Yes No No No No No No addGroupsToProject project addGroup projectID Yes Yes Yes Yes No No No removeGroupsFromProject project removeGroup projectID Yes Yes Yes Yes No No No getAllProjects project viewAll Yes Yes No No No No No getProjectByEnvironmentId project view projectID Yes Yes Yes Yes Yes Yes Yes getProjectByGitUrl project view projectID Yes Yes Yes Yes Yes Yes Yes getProjectByName project view projectID Yes Yes Yes Yes Yes Yes Yes addRestore restore add projectID Yes Yes Yes Yes Yes Yes Yes updateRestore restore update projectID Yes Yes Yes Yes Yes Yes Yes addSshKey ssh_key add userId Yes Yes No No No No No Yes updateSshKey ssh_key update userId Yes Yes No No No No No Yes deleteSshKey ssh_key delete userId Yes Yes No No No No No Yes deleteAllSshKeys ssh_key deleteAll Yes No No No No No No No removeAllSshKeysFromAllUsers ssh_key removeAll Yes No No No No No No No getUserSshKeys ssh_key view:user userID Yes Yes No No No No No Yes addTask task add:development projectID Yes Yes Yes Yes Yes No No addTask task add:production projectID Yes Yes Yes Yes No No No taskDrushArchiveDump task drushArchiveDump:development projectID Yes Yes Yes Yes Yes No No taskDrushArchiveDump task drushArchiveDump:production projectID Yes Yes Yes Yes Yes No No taskDrushSqlDump task drushSqlDump:development projectID Yes Yes Yes Yes Yes No No taskDrushSqlDump task drushSqlDump:production projectID Yes Yes Yes Yes Yes No No taskDrushCacheClear task drushCacheClear:development projectID Yes Yes Yes Yes Yes Yes Yes taskDrushCacheClear task drushCacheClear:production projectID Yes Yes Yes Yes Yes Yes Yes taskDrushCron task drushCron:development projectID Yes Yes Yes Yes Yes Yes Yes taskDrushCron task drushCron:production projectID Yes Yes Yes Yes Yes Yes Yes taskDrushUserLogin task drushUserLogin:destination:production EnvironmentID Yes Yes Yes Yes No No No taskDrushUserLogin task drushUserLogin:destination:development EnvironmentID Yes Yes Yes Yes Yes No No taskDrushSqlSync task drushSqlSync:source:development ProjectID Yes Yes Yes Yes Yes No No taskDrushSqlSync task drushSqlSync:source:production ProjectID Yes Yes Yes Yes Yes No No taskDrushSqlSync task drushSqlSync:destination:production ProjectID Yes Yes Yes Yes No No No taskDrushSqlSync task drushSqlSync:destination:development ProjectID Yes Yes Yes Yes Yes No No taskDrushRsyncFiles task drushRsync:source:development ProjectID Yes Yes Yes Yes Yes No No taskDrushRsyncFiles task drushRsync:source:production ProjectID Yes Yes Yes Yes Yes No No taskDrushRsyncFiles task drushRsync:destination:production ProjectID Yes Yes Yes Yes No No No taskDrushRsyncFiles task drushRsync:destination:development ProjectID Yes Yes Yes Yes Yes No No deleteTask task delete ProjectID Yes Yes Yes Yes Yes No No updateTask task update ProjectID Yes Yes Yes Yes Yes No No uploadFilesForTask task update projectID Yes Yes Yes Yes Yes No No deleteFilesForTask task delete projectID Yes Yes Yes Yes Yes No No getFilesByTaskId task view projectID Yes Yes Yes Yes Yes Yes Yes getTasksByEnvironmentId task view projectID Yes Yes Yes Yes Yes Yes Yes getTaskByRemoteId task view projectID Yes Yes Yes Yes Yes Yes Yes getTaskById task view projectID Yes Yes Yes Yes Yes Yes Yes addUser user add Yes Yes Yes Yes Yes Yes Yes updateUser user update userId Yes Yes No No No No No Yes deleteUser user delete userId Yes Yes No No No No No Yes deleteAllUsers user deleteAll Yes No No No No No No getProjectByEnvironmentId project viewPrivateKey projectID Yes Yes Yes No No No No getProjectByGitUrl project viewPrivateKey projectID Yes Yes Yes No No No No getProjectByName project viewPrivateKey projectID Yes Yes Yes No No No No","title":"Role-Based Access Control (RBAC)"},{"location":"administering-lagoon/rbac/#role-based-access-control-rbac","text":"Version 1.0 of Lagoon changed how you access your projects! Access to your project is handled via groups, with projects assigned to one or multiple groups. Users are added to groups with a role. Groups can also be nested within sub-groups. This change provides a lot more flexibility and the possibility to recreate real world teams within Lagoon.","title":"Role-Based Access Control (RBAC)"},{"location":"administering-lagoon/rbac/#roles","text":"When assigning a user to a group, you need to provide a group role for that user inside this group. Each one of the 5 current existing group roles gives the user different permissions to the group and projects assigned to the group. Here are the platform-wide roles and the group roles that are currently found in Lagoon:","title":"Roles"},{"location":"administering-lagoon/rbac/#platform-wide-roles","text":"","title":"Platform-Wide Roles"},{"location":"administering-lagoon/rbac/#platform-wide-admin","text":"The platform-wide admin has access to everything across all of Lagoon. That includes dangerous mutations like deleting all projects. Use very, very, very carefully.","title":"Platform-Wide Admin"},{"location":"administering-lagoon/rbac/#platform-wide-owner","text":"The platform-wide owner has access to every Lagoon group, like the group owner role, and can be used if you need a user that needs access to everything but you don't want to assign the user to every group.","title":"Platform-Wide Owner"},{"location":"administering-lagoon/rbac/#group-roles","text":"","title":"Group Roles"},{"location":"administering-lagoon/rbac/#owner","text":"The owner role can do everything within a group and its associated projects. They can add and manage users of a group. Be careful with this role, as it can delete projects and production environments!","title":"Owner"},{"location":"administering-lagoon/rbac/#maintainer","text":"The maintainer role can do everything within a group and its associated projects except deleting the project itself or the production environment. They can add and manage users of a group.","title":"Maintainer"},{"location":"administering-lagoon/rbac/#developer","text":"The developer role has SSH access only to development environments. This role cannot access, update or delete the production environment. They can run a sync task with the production environment as a source, but not as the destination. Cannot manage users of a group. Danger: IMPORTANT: This role does not prevent the deployment of the production environment as a deployment is triggered via a Git push! You need to make sure that your Git server prevents these users from pushing into the branch defined as production environment.","title":"Developer"},{"location":"administering-lagoon/rbac/#reporter","text":"The reporter role has view access only. They cannot access any environments via SSH or make modifications to them. They can run cache-clear tasks. This role is mostly used for stakeholders to have access to Lagoon UI and logging.","title":"Reporter"},{"location":"administering-lagoon/rbac/#guest","text":"The guest role has the same privileges as the reporter role listed above. Here is a table that lists the roles and the access they have: \ud83d\udca1 Tip: Scroll to the right to see the whole table!","title":"Guest"},{"location":"administering-lagoon/rbac/#lagoon-100-rbac-permission-matrix","text":"Name Resource Scope Attributes Platform-Wide Admin Platform-Wide Owner Owner Maintainer Developer Reporter Guest Self addBackup backup add projectID Yes Yes Yes Yes Yes No No deleteBackup backup delete projectID Yes Yes Yes Yes No No No deleteAllBackups backup deleteAll Yes No No No No No No getBackupsByEnvironmentId backup view projectID Yes Yes Yes Yes Yes No No deployment view projectID Yes Yes Yes Yes Yes Yes Yes addEnvVariable (to Project) env_var project:add projectID Yes Yes Yes Yes No No No addEnvVariable (to Environment) env_var environment:add:development projectID Yes Yes Yes Yes Yes No No addEnvVariable (to Environment) env_var environment:add:production projectID Yes Yes Yes Yes No No No deleteEnvVariable env_var delete projectID Yes Yes Yes Yes No No No getEnvVarsByProjectId env_var project:view projectID Yes Yes Yes Yes No No No getEnvVarsByEnvironmentId env_var environment:view:development projectID Yes Yes Yes Yes Yes No No getEnvVarsByEnvironmentId env_var environment:view:production projectID Yes Yes Yes Yes No No No addOrUpdateEnvironment environment addOrUpdate:development projectID Yes Yes Yes Yes Yes No No addOrUpdateEnvironment environment addOrUpdate:production projectID Yes Yes Yes Yes No No No updateEnvironment environment update:development projectID Yes Yes Yes Yes Yes No No updateEnvironment environment update:production projectID Yes Yes Yes Yes No No No deleteEnvironment environment delete:development projectID Yes Yes Yes Yes Yes No No deleteEnvironment environment delete:production projectID Yes Yes Yes No No No No deleteAllEnvironments environment deleteAll Yes No No No No No No addOrUpdateEnvironmentStorage environment storage Yes Yes No No No No No addDeployment environment deploy:development projectID Yes Yes Yes Yes Yes No No addDeployment environment deploy:production projectID Yes Yes Yes Yes No No No deleteDeployment deployment delete projectID Yes Yes Yes Yes No No No updateDeployment deployment update projectID Yes Yes Yes Yes No No No setEnvironmentServices environment update:development projectID Yes Yes Yes Yes Yes No No setEnvironmentServices environment update:production projectID Yes Yes Yes Yes No No No deployEnvironmentLatest environment deploy:development projectID Yes Yes Yes Yes Yes No No deployEnvironmentLatest environment deploy:production projectID Yes Yes Yes Yes No No No deployEnvironmentBranch environment deploy:development projectID Yes Yes Yes Yes Yes No No deployEnvironmentBranch environment deploy:production projectID Yes Yes Yes Yes No No No deployEnvironmentPullrequest environment deploy:development projectID Yes Yes Yes Yes Yes No No deployEnvironmentPullrequest environment deploy:production projectID Yes Yes Yes Yes No No No deployEnvironmentPromote environment deploy:development projectID Yes Yes Yes Yes Yes No No deployEnvironmentPromote environment deploy:production projectID Yes Yes Yes Yes No No No getEnvironmentsByProjectId environment view projectID Yes Yes Yes Yes Yes Yes Yes getEnvironmentStorageMonthByEnvironmentId environment storage Yes No No No No No No getEnvironmentHoursMonthByEnvironmentId environment storage Yes No No No No No No getEnvironmentHitsMonthByEnvironmentId environment storage Yes No No No No No No getEnvironmentServicesByEnvironmentId environment view projectID Yes Yes Yes Yes Yes Yes Yes addGroup group add Yes Yes Yes Yes Yes Yes Yes updateGroup group update groupID Yes Yes Yes Yes No No No deleteGroup group delete groupID Yes Yes Yes Yes No No No deleteAllGroups group deleteAll Yes No No No No No No addUserToGroup group addUser groupID Yes Yes Yes Yes No No No removeUserFromGroup group removeUser groupID Yes Yes Yes Yes No No No addNotificationSlack notification add Yes Yes No No No No No updateNotificationSlack notification update Yes Yes No No No No No deleteNotificationSlack notification delete Yes Yes No No No No No deleteAllNotificationSlacks notification deleteAll Yes No No No No No No addNotificationRocketChat notification add Yes Yes No No No No No updateNotificationRocketChat notification update Yes Yes No No No No No deleteNotificationRocketChat notification delete Yes Yes No No No No No deleteAllNotificationRocketChats notification deleteAll Yes No No No No No No removeAllNotificationsFromAllProjects notification removeAll Yes No No No No No No getNotificationsByProjectId notification view projectID Yes Yes Yes Yes Yes No No addKubernetes kubernetes add Yes Yes No No No No No updateKubernetes kubernetes update Yes Yes No No No No No deleteKubernetes kubernetes delete Yes Yes No No No No No deleteAllKubernetes kubernetes deleteAll Yes Yes No No No No No getAllOpenshifts openshift viewAll Yes No No No No No No getOpenshiftByProjectId openshift view projectID Yes Yes Yes Yes Yes Yes Yes addNotificationToProject project addNotification projectID Yes Yes Yes Yes No No No removeNotificationFromProject project removeNotification projectID Yes Yes Yes Yes No No No addProject project add Yes Yes Yes Yes Yes Yes Yes updateProject project update projectID Yes Yes Yes Yes No No No deleteProject project delete projectID Yes Yes Yes No No No No deleteAllProjects project deleteAll Yes No No No No No No addGroupsToProject project addGroup projectID Yes Yes Yes Yes No No No removeGroupsFromProject project removeGroup projectID Yes Yes Yes Yes No No No getAllProjects project viewAll Yes Yes No No No No No getProjectByEnvironmentId project view projectID Yes Yes Yes Yes Yes Yes Yes getProjectByGitUrl project view projectID Yes Yes Yes Yes Yes Yes Yes getProjectByName project view projectID Yes Yes Yes Yes Yes Yes Yes addRestore restore add projectID Yes Yes Yes Yes Yes Yes Yes updateRestore restore update projectID Yes Yes Yes Yes Yes Yes Yes addSshKey ssh_key add userId Yes Yes No No No No No Yes updateSshKey ssh_key update userId Yes Yes No No No No No Yes deleteSshKey ssh_key delete userId Yes Yes No No No No No Yes deleteAllSshKeys ssh_key deleteAll Yes No No No No No No No removeAllSshKeysFromAllUsers ssh_key removeAll Yes No No No No No No No getUserSshKeys ssh_key view:user userID Yes Yes No No No No No Yes addTask task add:development projectID Yes Yes Yes Yes Yes No No addTask task add:production projectID Yes Yes Yes Yes No No No taskDrushArchiveDump task drushArchiveDump:development projectID Yes Yes Yes Yes Yes No No taskDrushArchiveDump task drushArchiveDump:production projectID Yes Yes Yes Yes Yes No No taskDrushSqlDump task drushSqlDump:development projectID Yes Yes Yes Yes Yes No No taskDrushSqlDump task drushSqlDump:production projectID Yes Yes Yes Yes Yes No No taskDrushCacheClear task drushCacheClear:development projectID Yes Yes Yes Yes Yes Yes Yes taskDrushCacheClear task drushCacheClear:production projectID Yes Yes Yes Yes Yes Yes Yes taskDrushCron task drushCron:development projectID Yes Yes Yes Yes Yes Yes Yes taskDrushCron task drushCron:production projectID Yes Yes Yes Yes Yes Yes Yes taskDrushUserLogin task drushUserLogin:destination:production EnvironmentID Yes Yes Yes Yes No No No taskDrushUserLogin task drushUserLogin:destination:development EnvironmentID Yes Yes Yes Yes Yes No No taskDrushSqlSync task drushSqlSync:source:development ProjectID Yes Yes Yes Yes Yes No No taskDrushSqlSync task drushSqlSync:source:production ProjectID Yes Yes Yes Yes Yes No No taskDrushSqlSync task drushSqlSync:destination:production ProjectID Yes Yes Yes Yes No No No taskDrushSqlSync task drushSqlSync:destination:development ProjectID Yes Yes Yes Yes Yes No No taskDrushRsyncFiles task drushRsync:source:development ProjectID Yes Yes Yes Yes Yes No No taskDrushRsyncFiles task drushRsync:source:production ProjectID Yes Yes Yes Yes Yes No No taskDrushRsyncFiles task drushRsync:destination:production ProjectID Yes Yes Yes Yes No No No taskDrushRsyncFiles task drushRsync:destination:development ProjectID Yes Yes Yes Yes Yes No No deleteTask task delete ProjectID Yes Yes Yes Yes Yes No No updateTask task update ProjectID Yes Yes Yes Yes Yes No No uploadFilesForTask task update projectID Yes Yes Yes Yes Yes No No deleteFilesForTask task delete projectID Yes Yes Yes Yes Yes No No getFilesByTaskId task view projectID Yes Yes Yes Yes Yes Yes Yes getTasksByEnvironmentId task view projectID Yes Yes Yes Yes Yes Yes Yes getTaskByRemoteId task view projectID Yes Yes Yes Yes Yes Yes Yes getTaskById task view projectID Yes Yes Yes Yes Yes Yes Yes addUser user add Yes Yes Yes Yes Yes Yes Yes updateUser user update userId Yes Yes No No No No No Yes deleteUser user delete userId Yes Yes No No No No No Yes deleteAllUsers user deleteAll Yes No No No No No No getProjectByEnvironmentId project viewPrivateKey projectID Yes Yes Yes No No No No getProjectByGitUrl project viewPrivateKey projectID Yes Yes Yes No No No No getProjectByName project viewPrivateKey projectID Yes Yes Yes No No No No","title":"Lagoon 1.0.0 RBAC Permission Matrix"},{"location":"administering-lagoon/ssl-ciphers/","text":"Cipher Support # A cipher suite is a set of algorithms that help secure a network connection that uses Transport Layer Security (TLS) or its now-deprecated predecessor Secure Socket Layer (SSL). The set of algorithms that cipher suites usually contain include: a key exchange algorithm, a bulk encryption algorithm, and a message authentication code (MAC) algorithm. - Wikipedia Lagoon supports three default cipher suites, and also supports defining supported cipher suites directly. These cipher suites can be controlled by setting the ROUTER_CIPHERS environment variable. The three default selections available for this variable are: modern , intermediate , and old . Selectable Cipher Suites # Due to the versions of HAProxy and OpenSSL in use by the router service, modern and intermediate are currently the same settings: Support for TLS 1.2 No support for SSLv3 , TLS 1.0 or TLS 1.1 The following bind ciphers supported: ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384 In order to allow more relaxed settings, we also support an old config: Support for TLS 1.2 and TLS 1.1 No support for SSLv3 and TLS 1.0 The following bind ciphers supported: ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA:ECDHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES256-SHA256:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:DES-CBC3-SHA Custom Cipher Suites # If particular cipher settings are required, these can be provided via the environment vairable directly. TLS 1.0 and SSLv3 will not be allowed no matter which cipher suites are requested.","title":"SSL Ciphers"},{"location":"administering-lagoon/ssl-ciphers/#cipher-support","text":"A cipher suite is a set of algorithms that help secure a network connection that uses Transport Layer Security (TLS) or its now-deprecated predecessor Secure Socket Layer (SSL). The set of algorithms that cipher suites usually contain include: a key exchange algorithm, a bulk encryption algorithm, and a message authentication code (MAC) algorithm. - Wikipedia Lagoon supports three default cipher suites, and also supports defining supported cipher suites directly. These cipher suites can be controlled by setting the ROUTER_CIPHERS environment variable. The three default selections available for this variable are: modern , intermediate , and old .","title":"Cipher Support"},{"location":"administering-lagoon/ssl-ciphers/#selectable-cipher-suites","text":"Due to the versions of HAProxy and OpenSSL in use by the router service, modern and intermediate are currently the same settings: Support for TLS 1.2 No support for SSLv3 , TLS 1.0 or TLS 1.1 The following bind ciphers supported: ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384 In order to allow more relaxed settings, we also support an old config: Support for TLS 1.2 and TLS 1.1 No support for SSLv3 and TLS 1.0 The following bind ciphers supported: ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA:ECDHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES256-SHA256:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:DES-CBC3-SHA","title":"Selectable Cipher Suites"},{"location":"administering-lagoon/ssl-ciphers/#custom-cipher-suites","text":"If particular cipher settings are required, these can be provided via the environment vairable directly. TLS 1.0 and SSLv3 will not be allowed no matter which cipher suites are requested.","title":"Custom Cipher Suites"},{"location":"administering-lagoon/using-harbor/","text":"Harbor # Harbor is used as the default package repository for Lagoon when deploying to Kubernetes infrastructure. Harbor provides a Docker registry and a container security scanning solution provided by Trivy . Note: When running Lagoon locally, the configuration for Harbor is handled entirely automagically. If you are running Lagoon locally, you can access that UI at localhost:8084 . The username is admin and the password is admin . Note: If you are hosting a site with a provider (such as amazee.io), they may not allow customer access to the Harbor UI. Once logged in, the first screen is a list of all repositories your user has access to. Each \"repository\" in Harbor correlates to a project in Lagoon. Within each Harbor repository, you'll see a list of container images from all environments with a single Lagoon project. From here, you can drill down into an individual container in order to see its details, including an overview of its security scan results.","title":"Using Harbor"},{"location":"administering-lagoon/using-harbor/#harbor","text":"Harbor is used as the default package repository for Lagoon when deploying to Kubernetes infrastructure. Harbor provides a Docker registry and a container security scanning solution provided by Trivy . Note: When running Lagoon locally, the configuration for Harbor is handled entirely automagically. If you are running Lagoon locally, you can access that UI at localhost:8084 . The username is admin and the password is admin . Note: If you are hosting a site with a provider (such as amazee.io), they may not allow customer access to the Harbor UI. Once logged in, the first screen is a list of all repositories your user has access to. Each \"repository\" in Harbor correlates to a project in Lagoon. Within each Harbor repository, you'll see a list of container images from all environments with a single Lagoon project. From here, you can drill down into an individual container in order to see its details, including an overview of its security scan results.","title":"Harbor"},{"location":"administering-lagoon/using-harbor/security-scanning/","text":"Security Scanning # Harbor comes with a built-in security scanning solution provided by the Trivy service. This service analyzes a specified container image for any installed packages, and collects the version numbers of those installed packages. The Trivy service then searches the National Vulnerability Database for any CVEs (common vulnerabilities and exposures) affecting those package versions. Trivy is also library aware, so it will scan any Composer files or other package library definition files and report any vulnerabilities found within those package versions. These vulnerabilities are then reported within Harbor for each individual container. An example of a security scan in Harbor, showing applicable vulnerabilities for a scanned container:","title":"Security Scanning"},{"location":"administering-lagoon/using-harbor/security-scanning/#security-scanning","text":"Harbor comes with a built-in security scanning solution provided by the Trivy service. This service analyzes a specified container image for any installed packages, and collects the version numbers of those installed packages. The Trivy service then searches the National Vulnerability Database for any CVEs (common vulnerabilities and exposures) affecting those package versions. Trivy is also library aware, so it will scan any Composer files or other package library definition files and report any vulnerabilities found within those package versions. These vulnerabilities are then reported within Harbor for each individual container. An example of a security scan in Harbor, showing applicable vulnerabilities for a scanned container:","title":"Security Scanning"},{"location":"administering-lagoon/using-harbor/harbor-settings/","text":"Running Harbor Locally # Lagoon supports running Harbor locally, and it is automatically used for hosting all Kubernetes-based builds (any time the project's activeSystemsDeploy value is set to lagoon_kubernetesBuildDeploy ). When Harbor is ran locally, it makes use of MinIO as a storage backend, which is an AWS S3 compatible local storage solution. Settings # Harbor is composed of multiple containers, which all require different settings in order for them to run successfully. Environment Variables # The following environment variables are required to be set in order for Harbor to properly start: HARBOR_REGISTRY_STORAGE_AMAZON_BUCKET This needs to be set to the name of the AWS bucket which Harbor will save images to. Defaults to harbor-images when Lagoon is run locally or during CI testing. HARBOR_REGISTRY_STORAGE_AMAZON_REGION This needs to be set to the AWS region in which Harbor's bucket is located. Defaults to us-east-1 when Lagoon is run locally or during CI testing. REGISTRY_STORAGE_S3_ACCESSKEY This needs to be set to the AWS access key Harbor should use to read and write to the AWS bucket. Defaults to an empty string when Lagoon is run locally or during CI testing, as MinIO does not require authentication. REGISTRY_STORAGE_S3_SECRETKEY This needs to be set to the AWS secret key Harbor should use to read and write to the AWS bucket. Defaults to an empty string when Lagoon is run locally or during CI testing, as MinIO does not require authentication. The following environment variables can be set if required: HARBOR_REGISTRY_STORAGE_AMAZON_ENDPOINT If this variable is set, the Harbor registry will use its value as the address of the s3 entrypoint. Defaults to https://s3.amazonaws.com when this variable is not set. Container Specific Settings # The following containers make use of configuration files: HarborRegistry HarborRegistryCtl Harbor-Core Harbor-Database Harbor-Jobservice Harbor-Trivy The following containers do not require configuration files to run: Harbor-Nginx Harbor-Portal Harbor-Redis","title":"Harbor Settings"},{"location":"administering-lagoon/using-harbor/harbor-settings/#running-harbor-locally","text":"Lagoon supports running Harbor locally, and it is automatically used for hosting all Kubernetes-based builds (any time the project's activeSystemsDeploy value is set to lagoon_kubernetesBuildDeploy ). When Harbor is ran locally, it makes use of MinIO as a storage backend, which is an AWS S3 compatible local storage solution.","title":"Running Harbor Locally"},{"location":"administering-lagoon/using-harbor/harbor-settings/#settings","text":"Harbor is composed of multiple containers, which all require different settings in order for them to run successfully.","title":"Settings"},{"location":"administering-lagoon/using-harbor/harbor-settings/#environment-variables","text":"The following environment variables are required to be set in order for Harbor to properly start: HARBOR_REGISTRY_STORAGE_AMAZON_BUCKET This needs to be set to the name of the AWS bucket which Harbor will save images to. Defaults to harbor-images when Lagoon is run locally or during CI testing. HARBOR_REGISTRY_STORAGE_AMAZON_REGION This needs to be set to the AWS region in which Harbor's bucket is located. Defaults to us-east-1 when Lagoon is run locally or during CI testing. REGISTRY_STORAGE_S3_ACCESSKEY This needs to be set to the AWS access key Harbor should use to read and write to the AWS bucket. Defaults to an empty string when Lagoon is run locally or during CI testing, as MinIO does not require authentication. REGISTRY_STORAGE_S3_SECRETKEY This needs to be set to the AWS secret key Harbor should use to read and write to the AWS bucket. Defaults to an empty string when Lagoon is run locally or during CI testing, as MinIO does not require authentication. The following environment variables can be set if required: HARBOR_REGISTRY_STORAGE_AMAZON_ENDPOINT If this variable is set, the Harbor registry will use its value as the address of the s3 entrypoint. Defaults to https://s3.amazonaws.com when this variable is not set.","title":"Environment Variables"},{"location":"administering-lagoon/using-harbor/harbor-settings/#container-specific-settings","text":"The following containers make use of configuration files: HarborRegistry HarborRegistryCtl Harbor-Core Harbor-Database Harbor-Jobservice Harbor-Trivy The following containers do not require configuration files to run: Harbor-Nginx Harbor-Portal Harbor-Redis","title":"Container Specific Settings"},{"location":"administering-lagoon/using-harbor/harbor-settings/harbor-core/","text":"Harbor-Core # Harbor-Core requires a configuration file to start, which is located at /etc/core/app.conf within the container. Any changes made to this config file are temporary and will not persist once the pod is restarted. The configmap from which this config file is generated is stored within Lagoon in the services/harbor-core/harbor-core.yml file. Any changes made to this configmap will be persisted across container restarts. Config File Contents # _REDIS_URL Tells harbor-core and the Chartmuseum service connection info for the Redis server. The default value is harbor-redis:6379,100, . _REDIS_URL_REG The url which harborregistry should use to connect to the Redis server. The default value is redis://harbor-redis:6379/2 . ADMIRAL_URL Tells harbor-core where to find the admiral service. This service is not used with Lagoon's implementation of Harbor. The default value is NA . CFG_EXPIRATION This value is not used. The default value is 5 . CHART_CACHE_DRIVER Tells harbor-core where to store any uploaded charts. The default value is redis . CLAIR_ADAPTER_URL The URL that harbor-core should use to connect to the harbor-trivy service. The default value is http://harbor-trivy:8080 . CLAIR_DB The database type harborclair should use. This value is not used, and is included only for legacy support The default value is postgres . CLAIR_DB_HOST This value is not used, and is included only for legacy support Tells harbor-core where to find the harborclair service. The default value is harbor-database . CLAIR_DB_PASSWORD The password used to access harborclair's postgres database. The default value is test123 when run locally or during CI testing. This value is not used, and is included only for legacy support This value is retrieved from a secret created when Harbor is first set up on a running Lagoon. CLAIR_DB_PORT The port harborclair should use to connect to the harborclair server. This value is not used, and is included only for legacy support The default value is 5432 . CLAIR_DB_SSLMODE Whether or not harborclair should use SSL to connect to the postgresql server. This value is not used, and is included only for legacy support The default value is disable . CLAIR_DB_USERNAME The user harborclair should use to connect to the postgresql server. This value is not used, and is included only for legacy support The default value is postgres . CLAIR_HEALTH_CHECK_SERVER_URL This value tells harbor-core where it should issue health checks to for the harbor-trivy service. The default value is http://harbor-trivy:8080 CLAIR_URL The URL that harbor-core should use to connect to the harbor-trivy service. The default value is http://harbor-trivy:6060 . CONFIG_PATH Where harbor-core should look for its config file. The default value is /etc/core/app.conf . CORE_SECRET This value is a pre-shared key that must match between the various services connecting to harbor-core. The default value is set to secret123 when Harbor is run locally or during CI testing. This value is retrieved from a secret created when Harbor is first set up on a running Lagoon. CORE_URL The URL that harbor-core should publish to other Harbor services in order for them to connect to the harbor-core service. The default value is http://harbor-core:8080 . DATABASE_TYPE The database type Harbor should use. The default value is postgresql . HARBOR_ADMIN_PASSWORD The password which should be used to access harbor using the admin user. The default value is admin when run locally or during CI testing. This value is retreived from a secret created when Harbor is first set up on a running Lagoon. HARBOR_NGINX_ENDPOINT This environment variable tells harborregistry where its Nginx ingress controller, harbor-nginx, is running in order to construct proper push and pull instructions in the UI, among other things. The default value is set to http://harbor-nginx:8080 when run locally or during CI testing. Lagoon attempts to obtain and set this variable automagically when run in production. If that process fails, this service will fail to run. HTTP_PROXY The default value is an empty string. HTTPS_PROXY The default value is an empty string. JOBSERVICE_SECRET This value is a pre-shared key that must match between the various services connecting to harbor-jobservice. The default value is set to secret123 when Harbor is run locally or during CI testing. This value is retrieved from a secret created when Harbor is first set up on a running Lagoon. JOBSERVICE_URL The URL that harbor-core should use to connect to the harbor-jobservice service. The default value is http://harbor-jobservice:8080 . LOG_LEVEL The default log level of the harbor-core service. The default value is error . NO_PROXY A list of hosts which should never have their requests proxied. The default is harbor-core,harbor-jobservice,harbor-database,harbor-trivy,harborregistry,harbor-portal,127.0.0.1,localhost,.local,.internal . PORTAL_URL This value tells the service where to connect to the harbor-portal service. The default value is http://harbor-portal:8080 . POSTGRESQL_DATABASE The postgres database harbor-core should use when connecting to the postgresql server. The default value is registry . POSTGRESQL_HOST Where harbor-core should connect to the postgresql server. The default value is harbor-database . POSTGRESQL_MAX_IDLE_CONNS The maximum number of idle connections harbor-core should leave open to the postgresql server. The default value is 50 . POSTGRESQL_MAX_OPEN_CONNS The maximum number of open connections harbor-core should have to the postgresql server. The default value is 100 . POSTGRESQL_PASSWORD The password Harbor should use to connect to the postgresql server. The default value is a randomly generated value. POSTGRESQL_PORT The port harbor-core should use to connect to the postgresql server. The default value is 5432 . POSTGRESQL_USERNAME The username harbor-core should use to connect to the postgresql server. The default value is postgres . POSTGRESQL_SSLMODE Whether or not harbor-core should use SSL to connect to the postgresql server. The default value is disable . REGISTRY_HTTP_SECRET This value is a pre-shared key that must match between the various services connecting to harborregistry. The default value is set to secret123 when Harbor is run locally or during CI testing. This value is retreived from a secret created when Harbor is first set up on a running Lagoon. REGISTRY_STORAGE_PROVIDER_NAME The storage backend that harborregistry should use. The default value is s3 . REGISTRY_URL The URL that harbor-core should use to connect to the harborregistry service.. The default value is http://harborregistry:5000 . REGISTRYCTL_URL This value tells the service where to connect to the harborregistryctl service. The default value is set to http://harborregistryctl:8080 . ROBOT_TOKEN_DURATION This values sets how many days each issues robot token should be valid for. The default value is set to 999 . SYNC_REGISTRY This value is not used. The default value is false . TOKEN_SERVICE_URL The URL that the harbor-core service publishes to other services in order to retrieve a JWT token. The default value is http://harbor-core:8080/service/token . TRIVY_ADAPTER_URL The URL that the harbor-core service should use to connect to the harbor-trivy service. The default value is http://harbor-trivy:8080 . WITH_CHARTMUSEUM Tells harbor-core if the Chartmuseum service is being used. This service is not used with Lagoon's implementation of Harbor. The default value is false . WITH_CLAIR Tells harbor-core if the harborclair service is being used. Lagoon does use this service in its implementation of Harbor. The default value is true . WITH_NOTARY Tells harbor-core if the Notary service is being used. This service is not used with Lagoon's implementation of Harbor. The default value is false . WITH_TRIVY Tells harbor-core if the Trivy service is being used. The default value is true .","title":"Harbor-Core"},{"location":"administering-lagoon/using-harbor/harbor-settings/harbor-core/#harbor-core","text":"Harbor-Core requires a configuration file to start, which is located at /etc/core/app.conf within the container. Any changes made to this config file are temporary and will not persist once the pod is restarted. The configmap from which this config file is generated is stored within Lagoon in the services/harbor-core/harbor-core.yml file. Any changes made to this configmap will be persisted across container restarts.","title":"Harbor-Core"},{"location":"administering-lagoon/using-harbor/harbor-settings/harbor-core/#config-file-contents","text":"_REDIS_URL Tells harbor-core and the Chartmuseum service connection info for the Redis server. The default value is harbor-redis:6379,100, . _REDIS_URL_REG The url which harborregistry should use to connect to the Redis server. The default value is redis://harbor-redis:6379/2 . ADMIRAL_URL Tells harbor-core where to find the admiral service. This service is not used with Lagoon's implementation of Harbor. The default value is NA . CFG_EXPIRATION This value is not used. The default value is 5 . CHART_CACHE_DRIVER Tells harbor-core where to store any uploaded charts. The default value is redis . CLAIR_ADAPTER_URL The URL that harbor-core should use to connect to the harbor-trivy service. The default value is http://harbor-trivy:8080 . CLAIR_DB The database type harborclair should use. This value is not used, and is included only for legacy support The default value is postgres . CLAIR_DB_HOST This value is not used, and is included only for legacy support Tells harbor-core where to find the harborclair service. The default value is harbor-database . CLAIR_DB_PASSWORD The password used to access harborclair's postgres database. The default value is test123 when run locally or during CI testing. This value is not used, and is included only for legacy support This value is retrieved from a secret created when Harbor is first set up on a running Lagoon. CLAIR_DB_PORT The port harborclair should use to connect to the harborclair server. This value is not used, and is included only for legacy support The default value is 5432 . CLAIR_DB_SSLMODE Whether or not harborclair should use SSL to connect to the postgresql server. This value is not used, and is included only for legacy support The default value is disable . CLAIR_DB_USERNAME The user harborclair should use to connect to the postgresql server. This value is not used, and is included only for legacy support The default value is postgres . CLAIR_HEALTH_CHECK_SERVER_URL This value tells harbor-core where it should issue health checks to for the harbor-trivy service. The default value is http://harbor-trivy:8080 CLAIR_URL The URL that harbor-core should use to connect to the harbor-trivy service. The default value is http://harbor-trivy:6060 . CONFIG_PATH Where harbor-core should look for its config file. The default value is /etc/core/app.conf . CORE_SECRET This value is a pre-shared key that must match between the various services connecting to harbor-core. The default value is set to secret123 when Harbor is run locally or during CI testing. This value is retrieved from a secret created when Harbor is first set up on a running Lagoon. CORE_URL The URL that harbor-core should publish to other Harbor services in order for them to connect to the harbor-core service. The default value is http://harbor-core:8080 . DATABASE_TYPE The database type Harbor should use. The default value is postgresql . HARBOR_ADMIN_PASSWORD The password which should be used to access harbor using the admin user. The default value is admin when run locally or during CI testing. This value is retreived from a secret created when Harbor is first set up on a running Lagoon. HARBOR_NGINX_ENDPOINT This environment variable tells harborregistry where its Nginx ingress controller, harbor-nginx, is running in order to construct proper push and pull instructions in the UI, among other things. The default value is set to http://harbor-nginx:8080 when run locally or during CI testing. Lagoon attempts to obtain and set this variable automagically when run in production. If that process fails, this service will fail to run. HTTP_PROXY The default value is an empty string. HTTPS_PROXY The default value is an empty string. JOBSERVICE_SECRET This value is a pre-shared key that must match between the various services connecting to harbor-jobservice. The default value is set to secret123 when Harbor is run locally or during CI testing. This value is retrieved from a secret created when Harbor is first set up on a running Lagoon. JOBSERVICE_URL The URL that harbor-core should use to connect to the harbor-jobservice service. The default value is http://harbor-jobservice:8080 . LOG_LEVEL The default log level of the harbor-core service. The default value is error . NO_PROXY A list of hosts which should never have their requests proxied. The default is harbor-core,harbor-jobservice,harbor-database,harbor-trivy,harborregistry,harbor-portal,127.0.0.1,localhost,.local,.internal . PORTAL_URL This value tells the service where to connect to the harbor-portal service. The default value is http://harbor-portal:8080 . POSTGRESQL_DATABASE The postgres database harbor-core should use when connecting to the postgresql server. The default value is registry . POSTGRESQL_HOST Where harbor-core should connect to the postgresql server. The default value is harbor-database . POSTGRESQL_MAX_IDLE_CONNS The maximum number of idle connections harbor-core should leave open to the postgresql server. The default value is 50 . POSTGRESQL_MAX_OPEN_CONNS The maximum number of open connections harbor-core should have to the postgresql server. The default value is 100 . POSTGRESQL_PASSWORD The password Harbor should use to connect to the postgresql server. The default value is a randomly generated value. POSTGRESQL_PORT The port harbor-core should use to connect to the postgresql server. The default value is 5432 . POSTGRESQL_USERNAME The username harbor-core should use to connect to the postgresql server. The default value is postgres . POSTGRESQL_SSLMODE Whether or not harbor-core should use SSL to connect to the postgresql server. The default value is disable . REGISTRY_HTTP_SECRET This value is a pre-shared key that must match between the various services connecting to harborregistry. The default value is set to secret123 when Harbor is run locally or during CI testing. This value is retreived from a secret created when Harbor is first set up on a running Lagoon. REGISTRY_STORAGE_PROVIDER_NAME The storage backend that harborregistry should use. The default value is s3 . REGISTRY_URL The URL that harbor-core should use to connect to the harborregistry service.. The default value is http://harborregistry:5000 . REGISTRYCTL_URL This value tells the service where to connect to the harborregistryctl service. The default value is set to http://harborregistryctl:8080 . ROBOT_TOKEN_DURATION This values sets how many days each issues robot token should be valid for. The default value is set to 999 . SYNC_REGISTRY This value is not used. The default value is false . TOKEN_SERVICE_URL The URL that the harbor-core service publishes to other services in order to retrieve a JWT token. The default value is http://harbor-core:8080/service/token . TRIVY_ADAPTER_URL The URL that the harbor-core service should use to connect to the harbor-trivy service. The default value is http://harbor-trivy:8080 . WITH_CHARTMUSEUM Tells harbor-core if the Chartmuseum service is being used. This service is not used with Lagoon's implementation of Harbor. The default value is false . WITH_CLAIR Tells harbor-core if the harborclair service is being used. Lagoon does use this service in its implementation of Harbor. The default value is true . WITH_NOTARY Tells harbor-core if the Notary service is being used. This service is not used with Lagoon's implementation of Harbor. The default value is false . WITH_TRIVY Tells harbor-core if the Trivy service is being used. The default value is true .","title":"Config File Contents"},{"location":"administering-lagoon/using-harbor/harbor-settings/harbor-database/","text":"Harbor-Database # Harbor-Database requires specific environment variables to be set in order to start, which are stored within secrets as described in the services/harbor-database/harbor-core.yml file. Config File Contents # POSTGRES_DB The default database to be set up when initializing the Postgres service. The default value is postgres . POSTGRES_PASSWORD The root password for the Postgres database. The default value is test123 . This value is retrieved from a secret created when Harbor is first set up on a running Lagoon. POSTGRES_USER The default user to be set up when initializing the Postgres service. The default value is postgres .","title":"Harbor-Database"},{"location":"administering-lagoon/using-harbor/harbor-settings/harbor-database/#harbor-database","text":"Harbor-Database requires specific environment variables to be set in order to start, which are stored within secrets as described in the services/harbor-database/harbor-core.yml file.","title":"Harbor-Database"},{"location":"administering-lagoon/using-harbor/harbor-settings/harbor-database/#config-file-contents","text":"POSTGRES_DB The default database to be set up when initializing the Postgres service. The default value is postgres . POSTGRES_PASSWORD The root password for the Postgres database. The default value is test123 . This value is retrieved from a secret created when Harbor is first set up on a running Lagoon. POSTGRES_USER The default user to be set up when initializing the Postgres service. The default value is postgres .","title":"Config File Contents"},{"location":"administering-lagoon/using-harbor/harbor-settings/harbor-jobservice/","text":"Harbor-Jobservice # Harbor-Jobservice requires a configuration file to start, which is located at /etc/jobservice/config.yml within the container. Any changes made to this config file are temporary and will not persist once the pod is restarted. The configmap from which this config file is generated is stored within Lagoon in the services/harbor-jobservice/harbor-jobservice.yml file. Any changes made to this configmap will be persisted across container restarts. Config File Contents # CORE_URL This value tells harbor-jobservice where harbor-core can be reached. The default value is http://harbor-core:8080 . CORE_SECRET This value is a pre-shared key that must match between the various services connecting to harbor-core . The default value is set to secret123 when Harbor is run locally or during CI testing. This value is retrieved from a secret created when Harbor is first set up on a running Lagoon. HTTP_PROXY The default value is an empty string. HTTPS_PROXY The default value is an empty string. JOBSERVICE_SECRET This value is a pre-shared key that must match between the various services connecting to harbor-jobservice . The default value is set to secret123 when Harbor is run locally or during CI testing. This value is retrieved from a secret created when Harbor is first set up on a running Lagoon. LOG_LEVEL The logging level this service should use. The default value is error . This can also be set to debug to enable very verbose logging. NO_PROXY A list of hosts which should never have their requests proxied. The default is harbor-core,harbor-jobservice,harbor-database,harbor-trivy,harborregistry,harbor-portal,127.0.0.1,localhost,.local,.internal . REGISTRY_CONTROLLER_URL This value tells the service where to connect to the harborregistryctl service. The default value is set to http://harborregistryctl:8080 SCANNER_LOG_LEVEL The logging level the scanning service should use. The default value is error . This can also be set to debug to enable very verbose logging. SCANNER_STORE_REDIS_URL This value tells harbor-trivy how to connect to its Redis store. The default value is redis://harbor-redis:6379/4 .","title":"Harbor-Jobservice"},{"location":"administering-lagoon/using-harbor/harbor-settings/harbor-jobservice/#harbor-jobservice","text":"Harbor-Jobservice requires a configuration file to start, which is located at /etc/jobservice/config.yml within the container. Any changes made to this config file are temporary and will not persist once the pod is restarted. The configmap from which this config file is generated is stored within Lagoon in the services/harbor-jobservice/harbor-jobservice.yml file. Any changes made to this configmap will be persisted across container restarts.","title":"Harbor-Jobservice"},{"location":"administering-lagoon/using-harbor/harbor-settings/harbor-jobservice/#config-file-contents","text":"CORE_URL This value tells harbor-jobservice where harbor-core can be reached. The default value is http://harbor-core:8080 . CORE_SECRET This value is a pre-shared key that must match between the various services connecting to harbor-core . The default value is set to secret123 when Harbor is run locally or during CI testing. This value is retrieved from a secret created when Harbor is first set up on a running Lagoon. HTTP_PROXY The default value is an empty string. HTTPS_PROXY The default value is an empty string. JOBSERVICE_SECRET This value is a pre-shared key that must match between the various services connecting to harbor-jobservice . The default value is set to secret123 when Harbor is run locally or during CI testing. This value is retrieved from a secret created when Harbor is first set up on a running Lagoon. LOG_LEVEL The logging level this service should use. The default value is error . This can also be set to debug to enable very verbose logging. NO_PROXY A list of hosts which should never have their requests proxied. The default is harbor-core,harbor-jobservice,harbor-database,harbor-trivy,harborregistry,harbor-portal,127.0.0.1,localhost,.local,.internal . REGISTRY_CONTROLLER_URL This value tells the service where to connect to the harborregistryctl service. The default value is set to http://harborregistryctl:8080 SCANNER_LOG_LEVEL The logging level the scanning service should use. The default value is error . This can also be set to debug to enable very verbose logging. SCANNER_STORE_REDIS_URL This value tells harbor-trivy how to connect to its Redis store. The default value is redis://harbor-redis:6379/4 .","title":"Config File Contents"},{"location":"administering-lagoon/using-harbor/harbor-settings/harbor-trivy/","text":"Harbor-Trivy # Harbor-Trivy is configured via specific environment variables and does not use a config file. Environment Variables # SCANNER_LOG_LEVEL The logging level this service should use. The default value is error . This can be set to debug to enable very verbose logging. SCANNER_STORE_REDIS_URL This value tells harbor-trivy how to connect to its Redis store. The default value is redis://harbor-redis:6379/4 . SCANNER_JOB_QUEUE_REDIS_URL This value tells harbor-trivy how to connect to its Redis store. The default value is redis://harbor-redis:6379/4 . SCANNER_TRIVY_VULN_TYPE This value tells harbor-trivy what types of vulnerabilities it should be searching for. The default value is os,library","title":"Harbor-Trivy"},{"location":"administering-lagoon/using-harbor/harbor-settings/harbor-trivy/#harbor-trivy","text":"Harbor-Trivy is configured via specific environment variables and does not use a config file.","title":"Harbor-Trivy"},{"location":"administering-lagoon/using-harbor/harbor-settings/harbor-trivy/#environment-variables","text":"SCANNER_LOG_LEVEL The logging level this service should use. The default value is error . This can be set to debug to enable very verbose logging. SCANNER_STORE_REDIS_URL This value tells harbor-trivy how to connect to its Redis store. The default value is redis://harbor-redis:6379/4 . SCANNER_JOB_QUEUE_REDIS_URL This value tells harbor-trivy how to connect to its Redis store. The default value is redis://harbor-redis:6379/4 . SCANNER_TRIVY_VULN_TYPE This value tells harbor-trivy what types of vulnerabilities it should be searching for. The default value is os,library","title":"Environment Variables"},{"location":"administering-lagoon/using-harbor/harbor-settings/harborregistry/","text":"HarborRegistry # HarborRegistry requires a configuration file to start, which is located at /etc/registry/config.yml within the container. Any changes made to this config file are temporary and will not persist once the pod is restarted. This config file is stored within the services/harborregistry/harborregistry.yml file and loaded into the container as /etc/registry/pre-config.yml . A custom container entrypoint, services/harborregistry/entrypoint.sh , then transposes provided environment variables into this config file and saves the results as /etc/registry/config.yml . Config File Contents # CORE_SECRET This value is a pre-shared key that must match between the various services connecting to harbor-core . The default value is set to secret123 when Harbor is run locally or during CI testing. This value is retrieved from a secret created when Harbor is first set up on a running Lagoon. HARBOR_NGINX_ENDPOINT This environment variable tells harborregistry where its Nginx ingress controller, harbor-nginx , is running in order to construct proper push and pull instructions in the UI, among other things. The default value is set to http://harbor-nginx:8080 when run locally or during CI testing. Lagoon attempts to obtain and set this variable automagically when run in production. If that process fails, this service will fail to run. JOBSERVICE_SECRET This value is a pre-shared key that must match between the various services connecting to harbor-jobservice . The default value is set to secret123 when Harbor is run locally or during CI testing. This value is retrieved from a secret created when Harbor is first set up on a running Lagoon. REGISTRY_HTTP_SECRET This value is a pre-shared key that must match between the various services connecting to harborregistry . The default value is set to secret123 when Harbor is run locally or during CI testing. This value is retrieved from a secret created when Harbor is first set up on a running Lagoon. REGISTRY_REDIS_PASSWORD This environment variable tells harborregistryctl the password that should be used to connect to Redis. The default value is an empty string.","title":"HarborRegistry"},{"location":"administering-lagoon/using-harbor/harbor-settings/harborregistry/#harborregistry","text":"HarborRegistry requires a configuration file to start, which is located at /etc/registry/config.yml within the container. Any changes made to this config file are temporary and will not persist once the pod is restarted. This config file is stored within the services/harborregistry/harborregistry.yml file and loaded into the container as /etc/registry/pre-config.yml . A custom container entrypoint, services/harborregistry/entrypoint.sh , then transposes provided environment variables into this config file and saves the results as /etc/registry/config.yml .","title":"HarborRegistry"},{"location":"administering-lagoon/using-harbor/harbor-settings/harborregistry/#config-file-contents","text":"CORE_SECRET This value is a pre-shared key that must match between the various services connecting to harbor-core . The default value is set to secret123 when Harbor is run locally or during CI testing. This value is retrieved from a secret created when Harbor is first set up on a running Lagoon. HARBOR_NGINX_ENDPOINT This environment variable tells harborregistry where its Nginx ingress controller, harbor-nginx , is running in order to construct proper push and pull instructions in the UI, among other things. The default value is set to http://harbor-nginx:8080 when run locally or during CI testing. Lagoon attempts to obtain and set this variable automagically when run in production. If that process fails, this service will fail to run. JOBSERVICE_SECRET This value is a pre-shared key that must match between the various services connecting to harbor-jobservice . The default value is set to secret123 when Harbor is run locally or during CI testing. This value is retrieved from a secret created when Harbor is first set up on a running Lagoon. REGISTRY_HTTP_SECRET This value is a pre-shared key that must match between the various services connecting to harborregistry . The default value is set to secret123 when Harbor is run locally or during CI testing. This value is retrieved from a secret created when Harbor is first set up on a running Lagoon. REGISTRY_REDIS_PASSWORD This environment variable tells harborregistryctl the password that should be used to connect to Redis. The default value is an empty string.","title":"Config File Contents"},{"location":"administering-lagoon/using-harbor/harbor-settings/harborregistryctl/","text":"HarborRegistryCtl # HarborRegistryCtl requires a configuration file to start, which is located at /etc/registryctl/config.yml within the container. Any changes made to this config file are temporary and will not persist once the pod is restarted. The configmap from which this config file is generated is stored within Lagoon in the services/harborregistryctl/harborregistry.yml file. Any changes made to this configmap will be persisted across container restarts. Config File Contents # CORE_SECRET This value is a pre-shared key that must match between the various services connecting to harbor-core . The default value is set to secret123 when Harbor is run locally or during CI testing. This value is retrieved from a secret created when Harbor is first set up on a running Lagoon. JOBSERVICE_SECRET This value is a pre-shared key that must match between the various services connecting to harbor-jobservice . The default value is set to secret123 when Harbor is run locally or during CI testing. This value is retrieved from a secret created when Harbor is first set up on a running Lagoon. REGISTRY_HTTP_SECRET This value is a pre-shared key that must match between the various services connecting to harborregistry . The default value is set to secret123 when Harbor is run locally or during CI testing. This value is retrieved from a secret created when Harbor is first set up on a running Lagoon. REGISTRY_REDIS_PASSWORD This environment variable tells harborregistryctl the password that should be used to connect to Redis. The default value is an empty string.","title":"HarborRegistryCtl"},{"location":"administering-lagoon/using-harbor/harbor-settings/harborregistryctl/#harborregistryctl","text":"HarborRegistryCtl requires a configuration file to start, which is located at /etc/registryctl/config.yml within the container. Any changes made to this config file are temporary and will not persist once the pod is restarted. The configmap from which this config file is generated is stored within Lagoon in the services/harborregistryctl/harborregistry.yml file. Any changes made to this configmap will be persisted across container restarts.","title":"HarborRegistryCtl"},{"location":"administering-lagoon/using-harbor/harbor-settings/harborregistryctl/#config-file-contents","text":"CORE_SECRET This value is a pre-shared key that must match between the various services connecting to harbor-core . The default value is set to secret123 when Harbor is run locally or during CI testing. This value is retrieved from a secret created when Harbor is first set up on a running Lagoon. JOBSERVICE_SECRET This value is a pre-shared key that must match between the various services connecting to harbor-jobservice . The default value is set to secret123 when Harbor is run locally or during CI testing. This value is retrieved from a secret created when Harbor is first set up on a running Lagoon. REGISTRY_HTTP_SECRET This value is a pre-shared key that must match between the various services connecting to harborregistry . The default value is set to secret123 when Harbor is run locally or during CI testing. This value is retrieved from a secret created when Harbor is first set up on a running Lagoon. REGISTRY_REDIS_PASSWORD This environment variable tells harborregistryctl the password that should be used to connect to Redis. The default value is an empty string.","title":"Config File Contents"},{"location":"applications/","text":"A wide range of Applications, Frameworks and Languages are supported by Lagoon # Lagoon broadly classifies three levels in the application stack: - Languages - The core building blocks of any Lagoon project, these are usually provided by Lagoon-specific images. - Frameworks - These take those base images, and add in the necessary logic, tools and packages needed to serve a website, or drive an application. - Applications - Usually built on top of Frameworks, this is the layer that content editors or developers will interact with to shape the finished product. When we reference any repositories for use on Lagoon, we usually refer to them in three ways: - Templates - These are fully-functional, cloneable starter repositories, maintained and updated regularly, ready to be extended and used with little customization. - Examples - These are fully functional repositories, maintained and updated regularly, but may require some effort to make work for your individual project. - Demos - These are repositories that have been built as a demonstration, and are usable for some of the concepts within, but aren't routinely maintained or updated. For a more complete list, checkout out our GitHub repository: https://www.github.com/lagoon-examples and our website https://lagoon.sh/applications","title":"Overview"},{"location":"applications/#a-wide-range-of-applications-frameworks-and-languages-are-supported-by-lagoon","text":"Lagoon broadly classifies three levels in the application stack: - Languages - The core building blocks of any Lagoon project, these are usually provided by Lagoon-specific images. - Frameworks - These take those base images, and add in the necessary logic, tools and packages needed to serve a website, or drive an application. - Applications - Usually built on top of Frameworks, this is the layer that content editors or developers will interact with to shape the finished product. When we reference any repositories for use on Lagoon, we usually refer to them in three ways: - Templates - These are fully-functional, cloneable starter repositories, maintained and updated regularly, ready to be extended and used with little customization. - Examples - These are fully functional repositories, maintained and updated regularly, but may require some effort to make work for your individual project. - Demos - These are repositories that have been built as a demonstration, and are usable for some of the concepts within, but aren't routinely maintained or updated. For a more complete list, checkout out our GitHub repository: https://www.github.com/lagoon-examples and our website https://lagoon.sh/applications","title":"A wide range of Applications, Frameworks and Languages are supported by Lagoon"},{"location":"applications/node/","text":"Node.js # Introduction # Lagoon provides Node.js images that are based on top of the official Node Alpine images . More information on how to adapt your project to run on Lagoon can be found in our Node.js Docker Images section.","title":"Overview"},{"location":"applications/node/#nodejs","text":"","title":"Node.js"},{"location":"applications/node/#introduction","text":"Lagoon provides Node.js images that are based on top of the official Node Alpine images . More information on how to adapt your project to run on Lagoon can be found in our Node.js Docker Images section.","title":"Introduction"},{"location":"applications/options/","text":"Configuring Applications for use on Lagoon # lagoon.yml # Project- and environment-level configuration for Lagoon is provided in the .lagoon.yml file in your repository. See lagoon-yml.md . docker-compose.yml # Service-level configuration for Lagoon in provided in the docker-compose.yml file in your repository. In particular, the lagoon.type and associated service labels are documented in the individual services. See docker-compose-yml.md Storage # Lagoon has the ability to provision storage for most services - the built-in Lagoon service types have a -persistent variant that can add in the necessary PVCs, volumes, etc. We have updated our examples to reflect this configuration locally. Databases # Lagoon has configurations available for: Mariadb - all supported versions PostgreSQL - all supported versions Database-as-a-service # Lagoon also has the capability to utilize the dbaas-operator to automatically provision these databases using an underlying managed database service (i.e. RDS, Google Cloud Databases, Azure Database). This will happen automatically when these services are provisioned and configured for your cluster. If these are not available, a pod will be provisioned as a fallback. Cache # Lagoon supports Redis as a cache backend. In production, some users provision a managed Redis service for their production environments to help them scale. Search # Lagoon supports Elasticsearch, Solr and (soon) OpenSearch as search providers. External search providers can also be configured if required. Ingress/Routes # Lagoon auto-generates routes for services that have ingress requirements. Custom routes can be provided in the .lagoon.yml on a per-service basis. Environment Variables # Lagoon makes heavy use of environment variables, at build and runtime. Where these are used to provide critical configuration for your application (e.g. database config/credentials) - it is important that the local and Lagoon versions are named similarly. See environment-variables.md .","title":"Options"},{"location":"applications/options/#configuring-applications-for-use-on-lagoon","text":"","title":"Configuring Applications for use on Lagoon"},{"location":"applications/options/#lagoonyml","text":"Project- and environment-level configuration for Lagoon is provided in the .lagoon.yml file in your repository. See lagoon-yml.md .","title":"lagoon.yml"},{"location":"applications/options/#docker-composeyml","text":"Service-level configuration for Lagoon in provided in the docker-compose.yml file in your repository. In particular, the lagoon.type and associated service labels are documented in the individual services. See docker-compose-yml.md","title":"docker-compose.yml"},{"location":"applications/options/#storage","text":"Lagoon has the ability to provision storage for most services - the built-in Lagoon service types have a -persistent variant that can add in the necessary PVCs, volumes, etc. We have updated our examples to reflect this configuration locally.","title":"Storage"},{"location":"applications/options/#databases","text":"Lagoon has configurations available for: Mariadb - all supported versions PostgreSQL - all supported versions","title":"Databases"},{"location":"applications/options/#database-as-a-service","text":"Lagoon also has the capability to utilize the dbaas-operator to automatically provision these databases using an underlying managed database service (i.e. RDS, Google Cloud Databases, Azure Database). This will happen automatically when these services are provisioned and configured for your cluster. If these are not available, a pod will be provisioned as a fallback.","title":"Database-as-a-service"},{"location":"applications/options/#cache","text":"Lagoon supports Redis as a cache backend. In production, some users provision a managed Redis service for their production environments to help them scale.","title":"Cache"},{"location":"applications/options/#search","text":"Lagoon supports Elasticsearch, Solr and (soon) OpenSearch as search providers. External search providers can also be configured if required.","title":"Search"},{"location":"applications/options/#ingressroutes","text":"Lagoon auto-generates routes for services that have ingress requirements. Custom routes can be provided in the .lagoon.yml on a per-service basis.","title":"Ingress/Routes"},{"location":"applications/options/#environment-variables","text":"Lagoon makes heavy use of environment variables, at build and runtime. Where these are used to provide critical configuration for your application (e.g. database config/credentials) - it is important that the local and Lagoon versions are named similarly. See environment-variables.md .","title":"Environment Variables"},{"location":"applications/other/","text":"Running other applications on Lagoon # Even if Lagoon doesn't have a base image for your particular application, framework or language, Lagoon can still build it! Extending on, or inheriting from the commons image , Lagoon can run almost any workload. Hugo # This brief example shows how to build a Hugo website and serve it as static files in an nginx image. The commons image is used to add Hugo, copy the site in, and build it. The nginx image is then used to serve the site, with the addition of a customised nginx config. nginx.dockerfile snippet FROM uselagoon/commons as builder RUN apk add hugo git WORKDIR /app COPY . /app RUN hugo FROM uselagoon/nginx COPY --from = builder /app/public/ /app COPY lagoon/static-files.conf /etc/nginx/conf.d/app.conf RUN fix-permissions /usr/local/openresty/nginx docker-compose.yml snippet services : nginx : build : context : . dockerfile : lagoon/nginx.Dockerfile labels : lagoon.type : nginx","title":"Overview"},{"location":"applications/other/#running-other-applications-on-lagoon","text":"Even if Lagoon doesn't have a base image for your particular application, framework or language, Lagoon can still build it! Extending on, or inheriting from the commons image , Lagoon can run almost any workload.","title":"Running other applications on Lagoon"},{"location":"applications/other/#hugo","text":"This brief example shows how to build a Hugo website and serve it as static files in an nginx image. The commons image is used to add Hugo, copy the site in, and build it. The nginx image is then used to serve the site, with the addition of a customised nginx config. nginx.dockerfile snippet FROM uselagoon/commons as builder RUN apk add hugo git WORKDIR /app COPY . /app RUN hugo FROM uselagoon/nginx COPY --from = builder /app/public/ /app COPY lagoon/static-files.conf /etc/nginx/conf.d/app.conf RUN fix-permissions /usr/local/openresty/nginx docker-compose.yml snippet services : nginx : build : context : . dockerfile : lagoon/nginx.Dockerfile labels : lagoon.type : nginx","title":"Hugo"},{"location":"applications/php/","text":"PHP # Introduction # Lagoon supports a wide-range of PHP-based applications, such as Drupal , Laravel, Wordpress , Magento and Symfony. More information on how to adapt your php project to run on Lagoon can be found in our PHP-cli Docker Images and PHP-FPM Docker Images sections.","title":"Overview"},{"location":"applications/php/#php","text":"","title":"PHP"},{"location":"applications/php/#introduction","text":"Lagoon supports a wide-range of PHP-based applications, such as Drupal , Laravel, Wordpress , Magento and Symfony. More information on how to adapt your php project to run on Lagoon can be found in our PHP-cli Docker Images and PHP-FPM Docker Images sections.","title":"Introduction"},{"location":"applications/python/","text":"Python # Introduction # Lagoon provides images for Python 3.7 and above that can be used to build web apps in a wide range of Python-based frameworks and applications. More information on how to adapt your Python project to run on Lagoon can be found in our Python Docker Images section.","title":"Overview"},{"location":"applications/python/#python","text":"","title":"Python"},{"location":"applications/python/#introduction","text":"Lagoon provides images for Python 3.7 and above that can be used to build web apps in a wide range of Python-based frameworks and applications. More information on how to adapt your Python project to run on Lagoon can be found in our Python Docker Images section.","title":"Introduction"},{"location":"applications/ruby/","text":"Ruby and Ruby on Rails # Introduction # We provide images for Ruby 3.0 and above, built on top of the official Ruby alpine Docker images. Below we assume that you're attempting to get a Rails app deployed on Lagoon, although most of the details described are really framework neutral. Getting Rails running on Lagoon # Responding to requests # The Ruby on Rails example in the Lagoon examples repository is instructive here. In the docker-compose.yml we set up a service named ruby , which is the primary service that will be processing any dynamic requests. If you look at the dockerfile specified for the ruby service, you'll see that we're exposing port 3000. The nginx service will direct any requests for non-static assets to the ruby service on this port (see the nginx configuration file for more details). Logging # The Lagoon logging infrastructure is described in the docs here . Essentially, in order to make use of the infrastructure, logs need to be sent via a UDP message to udp://application-logs.lagoon.svc:5140 . In our Rails example, we're importing the logstash-logger gem, and then in our config/application.rb we're initializing it with the following: if ENV.has_key?('LAGOON_PROJECT') && ENV.has_key?('LAGOON_ENVIRONMENT') then lagoon_namespace = ENV['LAGOON_PROJECT'] + \"-\" + ENV['LAGOON_ENVIRONMENT'] LogStashLogger.configure do |config| config.customize_event do |event| event[\"type\"] = lagoon_namespace end end config.logstash.host = 'application-logs.lagoon.svc' config.logstash.type = :udp config.logstash.port = 5140 end Database configuration # The example uses our Postgresql image (see the docker-compose.yml file). Configuring database access in Rails for Lagoon is very straightforward. Since Lagoon injects the database host, name, and credentials as environment variables, we can change our config/database.yml to be aware of these env vars, and consume them if they exist. default: &default adapter: postgresql encoding: unicode pool: <%= ENV.fetch(\"RAILS_MAX_THREADS\") { 5 } %> username: <%= ENV.fetch(\"POSTGRES_USERNAME\") { \"drupal\" } %> password: <%= ENV.fetch(\"POSTGRES_PASSWORD\") { \"drupal\" } %> host: <%= ENV.fetch(\"POSTGRES_HOST\") { \"postgres\" } %> database: <%= ENV.fetch(\"('POSTGRES_DATABASE'\") { \"drupal\" } %>","title":"Overview"},{"location":"applications/ruby/#ruby-and-ruby-on-rails","text":"","title":"Ruby and Ruby on Rails"},{"location":"applications/ruby/#introduction","text":"We provide images for Ruby 3.0 and above, built on top of the official Ruby alpine Docker images. Below we assume that you're attempting to get a Rails app deployed on Lagoon, although most of the details described are really framework neutral.","title":"Introduction"},{"location":"applications/ruby/#getting-rails-running-on-lagoon","text":"","title":"Getting Rails running on Lagoon"},{"location":"applications/ruby/#responding-to-requests","text":"The Ruby on Rails example in the Lagoon examples repository is instructive here. In the docker-compose.yml we set up a service named ruby , which is the primary service that will be processing any dynamic requests. If you look at the dockerfile specified for the ruby service, you'll see that we're exposing port 3000. The nginx service will direct any requests for non-static assets to the ruby service on this port (see the nginx configuration file for more details).","title":"Responding to requests"},{"location":"applications/ruby/#logging","text":"The Lagoon logging infrastructure is described in the docs here . Essentially, in order to make use of the infrastructure, logs need to be sent via a UDP message to udp://application-logs.lagoon.svc:5140 . In our Rails example, we're importing the logstash-logger gem, and then in our config/application.rb we're initializing it with the following: if ENV.has_key?('LAGOON_PROJECT') && ENV.has_key?('LAGOON_ENVIRONMENT') then lagoon_namespace = ENV['LAGOON_PROJECT'] + \"-\" + ENV['LAGOON_ENVIRONMENT'] LogStashLogger.configure do |config| config.customize_event do |event| event[\"type\"] = lagoon_namespace end end config.logstash.host = 'application-logs.lagoon.svc' config.logstash.type = :udp config.logstash.port = 5140 end","title":"Logging"},{"location":"applications/ruby/#database-configuration","text":"The example uses our Postgresql image (see the docker-compose.yml file). Configuring database access in Rails for Lagoon is very straightforward. Since Lagoon injects the database host, name, and credentials as environment variables, we can change our config/database.yml to be aware of these env vars, and consume them if they exist. default: &default adapter: postgresql encoding: unicode pool: <%= ENV.fetch(\"RAILS_MAX_THREADS\") { 5 } %> username: <%= ENV.fetch(\"POSTGRES_USERNAME\") { \"drupal\" } %> password: <%= ENV.fetch(\"POSTGRES_PASSWORD\") { \"drupal\" } %> host: <%= ENV.fetch(\"POSTGRES_HOST\") { \"postgres\" } %> database: <%= ENV.fetch(\"('POSTGRES_DATABASE'\") { \"drupal\" } %>","title":"Database configuration"},{"location":"applications/wordpress/","text":"WordPress on Lagoon # The WordPress template is configured to use Composer to install WordPress, its dependencies and themes. THe WordPress template is based on the https://github.com/roots/bedrock boilerplate, but extended to match a standardized Lagoon deployment pattern. Composer Install # The template uses Composer to install WordPress and its themes. Database # Lagoon can support MariaDB and PostgreSQL databases, but as support for PostgreSQL is limited in WordPress, it isn't recommended for use. NGINX configuration # Lagoon doesn't have a built-in configuration for WordPress - instead, the template comes with a starting nginx.conf - please contribute any improvements you may find! WP-CLI # The Lagoon template installs wp-cli into the cli image to manage your WordPress install.","title":"Overview"},{"location":"applications/wordpress/#wordpress-on-lagoon","text":"The WordPress template is configured to use Composer to install WordPress, its dependencies and themes. THe WordPress template is based on the https://github.com/roots/bedrock boilerplate, but extended to match a standardized Lagoon deployment pattern.","title":"WordPress on Lagoon"},{"location":"applications/wordpress/#composer-install","text":"The template uses Composer to install WordPress and its themes.","title":"Composer Install"},{"location":"applications/wordpress/#database","text":"Lagoon can support MariaDB and PostgreSQL databases, but as support for PostgreSQL is limited in WordPress, it isn't recommended for use.","title":"Database"},{"location":"applications/wordpress/#nginx-configuration","text":"Lagoon doesn't have a built-in configuration for WordPress - instead, the template comes with a starting nginx.conf - please contribute any improvements you may find!","title":"NGINX configuration"},{"location":"applications/wordpress/#wp-cli","text":"The Lagoon template installs wp-cli into the cli image to manage your WordPress install.","title":"WP-CLI"},{"location":"contributing-to-lagoon/api-debugging/","text":"API Debugging # 1 . Ensure the dev script at services/api/package.json includes the following: node -- inspect = 0.0.0.0 : 9229 2 . Update docker-compose.yml to map the dist folder and expose the 9229 port: api : image : ${IMAGE_REPO:-lagoon}/api command : yarn run dev volumes : - ./services/api/src:/app/services/api/src - ./services/api/dist:/app/services/api/dist depends_on : - api-db - local-api-data-watcher-pusher - keycloak ports : - '3000:3000' - '9229:9229' 3 . Add the following to .vscode/launch.json : { // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387. \"version\" : \"0.2.0\" , \"configurations\" : [ { \"name\" : \"Docker: Attach to Node\" , \"type\" : \"node\" , \"request\" : \"attach\" , \"port\" : 9229 , \"address\" : \"localhost\" , \"outFiles\" : [ \"${workspaceRoot}/app/services/api/dist/**/*.js\" ], \"localRoot\" : \"${workspaceFolder}/services/api\" , \"remoteRoot\" : \"/app/services/api\" , \"sourceMaps\" : true , \"protocol\" : \"inspector\" } ] } 4 . Rebuild/restart the containers: rm build/api && make build/api && docker-compose restart api 5 . Restart VScode.","title":"API Debugging"},{"location":"contributing-to-lagoon/api-debugging/#api-debugging","text":"1 . Ensure the dev script at services/api/package.json includes the following: node -- inspect = 0.0.0.0 : 9229 2 . Update docker-compose.yml to map the dist folder and expose the 9229 port: api : image : ${IMAGE_REPO:-lagoon}/api command : yarn run dev volumes : - ./services/api/src:/app/services/api/src - ./services/api/dist:/app/services/api/dist depends_on : - api-db - local-api-data-watcher-pusher - keycloak ports : - '3000:3000' - '9229:9229' 3 . Add the following to .vscode/launch.json : { // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387. \"version\" : \"0.2.0\" , \"configurations\" : [ { \"name\" : \"Docker: Attach to Node\" , \"type\" : \"node\" , \"request\" : \"attach\" , \"port\" : 9229 , \"address\" : \"localhost\" , \"outFiles\" : [ \"${workspaceRoot}/app/services/api/dist/**/*.js\" ], \"localRoot\" : \"${workspaceFolder}/services/api\" , \"remoteRoot\" : \"/app/services/api\" , \"sourceMaps\" : true , \"protocol\" : \"inspector\" } ] } 4 . Rebuild/restart the containers: rm build/api && make build/api && docker-compose restart api 5 . Restart VScode.","title":"API Debugging"},{"location":"contributing-to-lagoon/code-of-conduct/","text":"Code of Conduct # Our Pledge # In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation. Our Standards # Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language. Being respectful of differing viewpoints and experiences. Gracefully accepting constructive criticism. Focusing on what is best for the community. Showing empathy towards other community members. Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances. Trolling, insulting/derogatory comments, and personal or political attacks. Public or private harassment. Publishing others' private information, such as a physical or electronic address, without explicit permission. Other conduct which could reasonably be considered inappropriate in a professional setting. Our Responsibilities # Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope # This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project email address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Enforcement # Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at hello@amazee.io . The project team will review and investigate all complaints, and will respond in a way that it deems appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership. Attribution # This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at http://contributor-covenant.org/version/1/4 .","title":"Code of Conduct"},{"location":"contributing-to-lagoon/code-of-conduct/#code-of-conduct","text":"","title":"Code of Conduct"},{"location":"contributing-to-lagoon/code-of-conduct/#our-pledge","text":"In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.","title":"Our Pledge"},{"location":"contributing-to-lagoon/code-of-conduct/#our-standards","text":"Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language. Being respectful of differing viewpoints and experiences. Gracefully accepting constructive criticism. Focusing on what is best for the community. Showing empathy towards other community members. Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances. Trolling, insulting/derogatory comments, and personal or political attacks. Public or private harassment. Publishing others' private information, such as a physical or electronic address, without explicit permission. Other conduct which could reasonably be considered inappropriate in a professional setting.","title":"Our Standards"},{"location":"contributing-to-lagoon/code-of-conduct/#our-responsibilities","text":"Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.","title":"Our Responsibilities"},{"location":"contributing-to-lagoon/code-of-conduct/#scope","text":"This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project email address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.","title":"Scope"},{"location":"contributing-to-lagoon/code-of-conduct/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at hello@amazee.io . The project team will review and investigate all complaints, and will respond in a way that it deems appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.","title":"Enforcement"},{"location":"contributing-to-lagoon/code-of-conduct/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at http://contributor-covenant.org/version/1/4 .","title":"Attribution"},{"location":"contributing-to-lagoon/developing-lagoon/","text":"Developing Lagoon # Development of Lagoon locally can now be performed on a local Kubernetes cluster, or via Docker Compose (as a fallback). Note: The full Lagoon stack relies on a range of upstream projects which are currently incompatible with ARM-based architectures, such as the the M1/M2 Apple Silicon-based machines. For this reason, running or developing lagoon-core or lagoon-remote locally on these architectures is not currently supported. See https://github.com/uselagoon/lagoon/issues/3189 for more information. Docker # Docker must be installed to build and run Lagoon locally. Install Docker and Docker Compose # Please check the official docs for how to install Docker. Docker Compose is included in Docker for Mac installations. For Linux installations see the directions here . Configure Docker # You will need to update your insecure registries in Docker. Read the instructions here on how to do that . We suggest adding the entire local IPv4 Private Address Spaces to avoid unnecessary reconfiguration between Kubernetes and Docker Compose. e.g. \"insecure-registries\" : [\"172.16.0.0/12\",\"192.168.0.0/16\"], Allocate Enough Docker Resources # Running a Lagoon, Kubernetes, or Docker cluster on your local machine consumes a lot of resources. We recommend that you give your Docker host a minimum of 8 CPU cores and 12GB RAM. Build Lagoon Locally # Warning: Only consider building Lagoon this way if you intend to develop features or functionality for it, or want to debug internal processes. We will also be providing instruction to install Lagoon without building it (i.e. by using the published releases). We're using make (see the Makefile ) in order to build the needed Docker images, configure Kubernetes and run tests. We have provided a number of routines in the Makefile to cover most local development scenarios. Here we will run through a complete process. Build images # Here -j8 tells make to run 8 tasks in parallel to speed the build up. Adjust as necessary. We have set SCAN_IMAGES=false as a default to not scan the built images for vulnerabilities. If set to true, a scan.txt file will be created in the project root with the scan output. make -j8 build Start Lagoon test routine using the defaults in the Makefile (all tests). make kind/test Warning: There are a lot of tests configured to run by default - please consider only testing locally the minimum that you need to ensure functionality. This can be done by specifying or removing tests from the TESTS variable in the Makefile. This process will: Download the correct versions of the local development tools if not installed - kind , kubectl , helm , jq . Update the necessary Helm repositories for Lagoon to function. Ensure all of the correct images have been built in the previous step. Create a local KinD cluster, which provisions an entire running Kubernetes cluster in a local Docker container. This cluster has been configured to talk to a provisioned image registry that we will be pushing the built Lagoon images to. It has also been configured to allow access to the host filesystem for local development. Clone Lagoon from https://github.com/uselagoon/lagoon-charts (use the CHARTS_TREEISH variable in the Makefile to control which branch if needed). Install the Harbor Image registry into the KinD cluster and configure its ingress and access properly. Docker will push the built images for Lagoon into the Harbor image registry. It then uses the Makefile from lagoon-charts to perform the rest of the setup steps. A suitable ingress controller is installed - we use the NGINX Ingress Controller . A local NFS server provisioner is installed to handle specific volume requests - we use one that handles Read-Write-Many operations (RWX). Lagoon Core is then installed, using the locally built images pushed to the cluster-local Image Registry, and using the default configuration, which may exclude some services not needed for local testing. The installation will wait for the API and Keycloak to come online. The DBaaS providers are installed - MariaDB, PostgreSQL and MongoDB. This step provisions standalone databases to be used by projects running locally, and emulates the managed services available via cloud providers (e.g. Cloud SQL, RDS or Azure Database). Lagoon Remote is then installed, and configured to talk to the Lagoon Core, databases and local storage. The installation will wait for this to complete before continuing. To provision the tests, the Lagoon Test chart is then installed, which provisions a local Git server to host the test repositories, and pre-configures the Lagoon API database with the default test users, accounts and configuration. It then performs readiness checks before starting tests. Lagoon will run all the tests specified in the TESTS variable in the Makefile. Each test creates its own project & environments, performs the tests, and then removes the environments & projects. The test runs are output to the console log in the lagoon-test-suite-* pod, and can be accessed one test per container. Ideally, all of the tests pass and it's all done! View the test progress and your local cluster # The test routine creates a local Kubeconfig file (called kubeconfig.kind.lagoon in the root of the project, that can be used with a Kubernetes dashboard, viewer or CLI tool to access the local cluster. We use tools like Lens , Octant , kubectl or Portainer in our workflows. Lagoon Core, Remote and Tests all build in the Lagoon namespace, and each environment creates its own namespace to run, so make sure to use the correct context when inspecting. In order to use kubectl with the local cluster, you will need to use the correct Kubeconfig. This can be done for every command or it can be added to your preferred tool: KUBECONFIG = ./kubeconfig.kind.lagoon kubectl get pods -n lagoon The Helm charts used to build the local Lagoon are cloned into a local folder and symlinked to lagoon-charts.kind.lagoon where you can see the configuration. We'll cover how to make easy modifications later in this documentation. Interact with your local Lagoon cluster # The Makefile includes a few simple routines that will make interacting with the installed Lagoon simpler: make kind/port-forwards This will create local ports to expose the UI (6060), API (7070) and Keycloak (8080). Note that this logs to stdout , so it should be performed in a secondary terminal/window. make kind/get-admin-creds This will retrieve the necessary credentials to interact with the Lagoon. The JWT is an admin-scoped token for use as a bearer token with your local GraphQL client. See more in our GraphQL documentation . There is a token for use with the \"admin\" user in Keycloak, who can access all users, groups, roles, etc. There is also a token for use with the \"lagoonadmin\" user in Lagoon, which can be allocated default groups, permissions, etc. make kind/dev This will re-push the images listed in KIND_SERVICES with the correct tag, and redeploy the lagoon-core chart. This is useful for testing small changes to Lagoon services, but does not support \"live\" development. You will need to rebuild these images locally first, e.g rm build/api && make build/api . make kind/local-dev-patch This will build the typescript services, using your locally installed Node.js (it should be >16.0). It will then: Mount the \"dist\" folders from the Lagoon services into the correct lagoon-core pods in Kubernetes Redeploy the lagoon-core chart with the services running with nodemon watching the code for changes This will facilitate \"live\" development on Lagoon. Note that occasionally the pod in Kubernetes may require redeployment for a change to show. Clean any build artifacts from those services if you're rebuilding different branches with git clean -dfx as the dist folders are ignored by Git. make kind/local-dev-logging This will create a standalone OpenDistro for Elasticsearch cluster in your local Docker, and configure Lagoon to dispatch all logs (Lagoon and project) to it, using the configuration in lagoon-logging . make kind/retest # OR make kind/retest TESTS = '[features-kubernetes]' This will re-run a suite of tests (defined in the TESTS variable) against the existing cluster. It will re-push the images needed for tests (tests, local-git, and the data-watcher-pusher). You can specify tests to run by passing the TESTS variable inline. If updating a test configuration, the tests image will need to be rebuilt and pushed, e.g rm build/tests && make build/tests && make kind/push-images IMAGES='tests' && make kind/retest TESTS='[api]' make kind/push-images # OR make kind/push-images IMAGES = 'tests local-git' This will push all the images up to the image registry. Specifying IMAGES will tag and push specific images. make kind/clean This will remove the KinD Lagoon cluster from your local Docker. Ansible # The Lagoon test uses Ansible to run the test suite. Each range of tests for a specific function has been split into its own routine. If you are performing development work locally, select which tests to run, and update the $TESTS variable in the Makefile to reduce the concurrent tests running. The configuration for these tests is held in three services: tests is the Ansible test services themselves. The local testing routine runs each individual test as a separate container within a test-suite pod. These are listed below. local-git is a Git server hosted in the cluster that holds the source files for the tests. Ansible pulls and pushes to this repository throughout the tests api-data-watcher-pusher is a set of GraphQL mutations that pre-populates local Lagoon with the necessary Kubernetes configuration, test user accounts and SSH keys, and the necessary groups and notifications. Note that this will wipe local projects and environments on each run. The individual routines relevant to Kubernetes are: active-standby-kubernetes runs tests to check active/standby in Kubernetes. api runs tests for the API - branch/PR deployment, promotion. bitbucket , gitlab and github run tests for the specific SCM providers. drupal-php74 runs a single-pod MariaDB, MariaDB DBaaS and a Drush-specific test for a Drupal 8/9 project ( drupal-php73 doesn't do the Drush test). drupal-postgres runs a single-pod PostgreSQL and a PostgreSQL DBaaS test for a Drupal 8 project. elasticsearch runs a simple NGINX proxy to an Elasticsearch single-pod. features-api-variables runs tests that utilize variables in Lagoon. features-kubernetes runs a range of standard Lagoon tests, specific to Kubernetes. features-kubernetes-2 runs more advanced kubernetes-specific tests - covering multi-project and subfolder configurations. nginx , node and python run basic tests against those project types. node-mongodb runs a single-pod MongoDB test and a MongoDB DBaaS test against a Node.js app. Local Development # Most services are written in Node.js . As many of these services share similar Node.js code and Node.js packages, we're using a feature of Yarn , called Yarn workspaces . Yarn workspaces need a package.json in the project's root directory that defines the workspaces. The development of the services can happen directly within Docker. Each container for each service is set up in a way that its source code is mounted into the running container ( see docker-compose.yml ). Node.js itself is watching the code via nodemon , and restarts the Node.js process automatically on a change. lagoon-commons # The services not only share many Node.js packages, but also share actual custom code. This code is within node-packages/lagoon-commons . It will be automatically symlinked by Yarn workspaces. Additionally, the nodemon of the services is set up in a way that it checks for changes in node-packages and will restart the node process automatically. Troubleshooting # \u26a0I can't build a docker image for any Node.js based service # Rebuild the images via: make clean make build \u26a0 I get errors about missing node_modules content when I try to build / run a Node.js based image # Make sure to run yarn in Lagoon's root directory, since some services have common dependencies managed by yarn workspaces. \u26a0 I get an error resolving the nip.io domains # Error response from daemon: Get https://registry.172.18.0.2.nip.io:32080/v2/: dial tcp: lookup registry.172.18.0.2.nip.io: no such host This can happen if your local resolver filters private IPs from results. You can work around this by editing /etc/resolv.conf and adding a line like nameserver 8.8.8.8 at the top to use a public resolver that doesn't filter results. Example workflows # Here are some development scenarios and useful workflows for getting things done. Editing kubectl-build-deploy-dind # This example shows a workflow for editing the Lagoon deploy logic. Edit kubectl-build-deploy-dind # In this example we want to add some functionality to the Lagoon deploy logic in the kubectl-build-deploy-dind image. Start a local KinD cluster with Lagoon installed from locally built images, and smoke-test it by running a single test suite: make -j8 kind/test TESTS = '[features-api-variables]' Edit images/kubectl-build-deploy-dind/build-deploy-docker-compose.sh . --- a/images/kubectl-build-deploy-dind/build-deploy-docker-compose.sh +++ b/images/kubectl-build-deploy-dind/build-deploy-docker-compose.sh @@ -1,5 +1,7 @@ #!/bin/bash +echo HELLO WORLD + function cronScheduleMoreOftenThan30Minutes() { #takes a unexpanded cron schedule, returns 0 if it's more often that 30 minutes MINUTE=$(echo $1 | (read -a ARRAY; echo ${ARRAY[0]}) ) Now rebuild the kubectl-build-deploy-dind image with the edits included. rm build/kubectl-build-deploy-dind make -j8 build/kubectl-build-deploy-dind Push the newly built image into the cluster registry. It will now be used for future deploys. make kind/push-images IMAGES = kubectl-build-deploy-dind Rerun the tests. make kind/retest TESTS = '[features-api-variables]' See the edits have been applied. $ kubectl -n ci-features-api-variables-control-k8s-lagoon-api-variables logs lagoon-build-lat2b | grep -A2 build-deploy-docker-compose.sh + . /kubectl-build-deploy/build-deploy-docker-compose.sh ++ echo HELLO WORLD HELLO WORLD Add tests # Repeat the first step above. Edit tests/tests/features-api-variables.yaml and add a test case. Rebuild the tests image. rm build/tests make -j8 build/tests Push the new tests image into the cluster registry. make kind/push-images IMAGES = tests Rerun the tests. make kind/retest TESTS = '[features-api-variables]'","title":"Developing Lagoon"},{"location":"contributing-to-lagoon/developing-lagoon/#developing-lagoon","text":"Development of Lagoon locally can now be performed on a local Kubernetes cluster, or via Docker Compose (as a fallback). Note: The full Lagoon stack relies on a range of upstream projects which are currently incompatible with ARM-based architectures, such as the the M1/M2 Apple Silicon-based machines. For this reason, running or developing lagoon-core or lagoon-remote locally on these architectures is not currently supported. See https://github.com/uselagoon/lagoon/issues/3189 for more information.","title":"Developing Lagoon"},{"location":"contributing-to-lagoon/developing-lagoon/#docker","text":"Docker must be installed to build and run Lagoon locally.","title":"Docker"},{"location":"contributing-to-lagoon/developing-lagoon/#install-docker-and-docker-compose","text":"Please check the official docs for how to install Docker. Docker Compose is included in Docker for Mac installations. For Linux installations see the directions here .","title":"Install Docker and Docker Compose"},{"location":"contributing-to-lagoon/developing-lagoon/#configure-docker","text":"You will need to update your insecure registries in Docker. Read the instructions here on how to do that . We suggest adding the entire local IPv4 Private Address Spaces to avoid unnecessary reconfiguration between Kubernetes and Docker Compose. e.g. \"insecure-registries\" : [\"172.16.0.0/12\",\"192.168.0.0/16\"],","title":"Configure Docker"},{"location":"contributing-to-lagoon/developing-lagoon/#allocate-enough-docker-resources","text":"Running a Lagoon, Kubernetes, or Docker cluster on your local machine consumes a lot of resources. We recommend that you give your Docker host a minimum of 8 CPU cores and 12GB RAM.","title":"Allocate Enough Docker Resources"},{"location":"contributing-to-lagoon/developing-lagoon/#build-lagoon-locally","text":"Warning: Only consider building Lagoon this way if you intend to develop features or functionality for it, or want to debug internal processes. We will also be providing instruction to install Lagoon without building it (i.e. by using the published releases). We're using make (see the Makefile ) in order to build the needed Docker images, configure Kubernetes and run tests. We have provided a number of routines in the Makefile to cover most local development scenarios. Here we will run through a complete process.","title":"Build Lagoon Locally"},{"location":"contributing-to-lagoon/developing-lagoon/#build-images","text":"Here -j8 tells make to run 8 tasks in parallel to speed the build up. Adjust as necessary. We have set SCAN_IMAGES=false as a default to not scan the built images for vulnerabilities. If set to true, a scan.txt file will be created in the project root with the scan output. make -j8 build Start Lagoon test routine using the defaults in the Makefile (all tests). make kind/test Warning: There are a lot of tests configured to run by default - please consider only testing locally the minimum that you need to ensure functionality. This can be done by specifying or removing tests from the TESTS variable in the Makefile. This process will: Download the correct versions of the local development tools if not installed - kind , kubectl , helm , jq . Update the necessary Helm repositories for Lagoon to function. Ensure all of the correct images have been built in the previous step. Create a local KinD cluster, which provisions an entire running Kubernetes cluster in a local Docker container. This cluster has been configured to talk to a provisioned image registry that we will be pushing the built Lagoon images to. It has also been configured to allow access to the host filesystem for local development. Clone Lagoon from https://github.com/uselagoon/lagoon-charts (use the CHARTS_TREEISH variable in the Makefile to control which branch if needed). Install the Harbor Image registry into the KinD cluster and configure its ingress and access properly. Docker will push the built images for Lagoon into the Harbor image registry. It then uses the Makefile from lagoon-charts to perform the rest of the setup steps. A suitable ingress controller is installed - we use the NGINX Ingress Controller . A local NFS server provisioner is installed to handle specific volume requests - we use one that handles Read-Write-Many operations (RWX). Lagoon Core is then installed, using the locally built images pushed to the cluster-local Image Registry, and using the default configuration, which may exclude some services not needed for local testing. The installation will wait for the API and Keycloak to come online. The DBaaS providers are installed - MariaDB, PostgreSQL and MongoDB. This step provisions standalone databases to be used by projects running locally, and emulates the managed services available via cloud providers (e.g. Cloud SQL, RDS or Azure Database). Lagoon Remote is then installed, and configured to talk to the Lagoon Core, databases and local storage. The installation will wait for this to complete before continuing. To provision the tests, the Lagoon Test chart is then installed, which provisions a local Git server to host the test repositories, and pre-configures the Lagoon API database with the default test users, accounts and configuration. It then performs readiness checks before starting tests. Lagoon will run all the tests specified in the TESTS variable in the Makefile. Each test creates its own project & environments, performs the tests, and then removes the environments & projects. The test runs are output to the console log in the lagoon-test-suite-* pod, and can be accessed one test per container. Ideally, all of the tests pass and it's all done!","title":"Build images"},{"location":"contributing-to-lagoon/developing-lagoon/#view-the-test-progress-and-your-local-cluster","text":"The test routine creates a local Kubeconfig file (called kubeconfig.kind.lagoon in the root of the project, that can be used with a Kubernetes dashboard, viewer or CLI tool to access the local cluster. We use tools like Lens , Octant , kubectl or Portainer in our workflows. Lagoon Core, Remote and Tests all build in the Lagoon namespace, and each environment creates its own namespace to run, so make sure to use the correct context when inspecting. In order to use kubectl with the local cluster, you will need to use the correct Kubeconfig. This can be done for every command or it can be added to your preferred tool: KUBECONFIG = ./kubeconfig.kind.lagoon kubectl get pods -n lagoon The Helm charts used to build the local Lagoon are cloned into a local folder and symlinked to lagoon-charts.kind.lagoon where you can see the configuration. We'll cover how to make easy modifications later in this documentation.","title":"View the test progress and your local cluster"},{"location":"contributing-to-lagoon/developing-lagoon/#interact-with-your-local-lagoon-cluster","text":"The Makefile includes a few simple routines that will make interacting with the installed Lagoon simpler: make kind/port-forwards This will create local ports to expose the UI (6060), API (7070) and Keycloak (8080). Note that this logs to stdout , so it should be performed in a secondary terminal/window. make kind/get-admin-creds This will retrieve the necessary credentials to interact with the Lagoon. The JWT is an admin-scoped token for use as a bearer token with your local GraphQL client. See more in our GraphQL documentation . There is a token for use with the \"admin\" user in Keycloak, who can access all users, groups, roles, etc. There is also a token for use with the \"lagoonadmin\" user in Lagoon, which can be allocated default groups, permissions, etc. make kind/dev This will re-push the images listed in KIND_SERVICES with the correct tag, and redeploy the lagoon-core chart. This is useful for testing small changes to Lagoon services, but does not support \"live\" development. You will need to rebuild these images locally first, e.g rm build/api && make build/api . make kind/local-dev-patch This will build the typescript services, using your locally installed Node.js (it should be >16.0). It will then: Mount the \"dist\" folders from the Lagoon services into the correct lagoon-core pods in Kubernetes Redeploy the lagoon-core chart with the services running with nodemon watching the code for changes This will facilitate \"live\" development on Lagoon. Note that occasionally the pod in Kubernetes may require redeployment for a change to show. Clean any build artifacts from those services if you're rebuilding different branches with git clean -dfx as the dist folders are ignored by Git. make kind/local-dev-logging This will create a standalone OpenDistro for Elasticsearch cluster in your local Docker, and configure Lagoon to dispatch all logs (Lagoon and project) to it, using the configuration in lagoon-logging . make kind/retest # OR make kind/retest TESTS = '[features-kubernetes]' This will re-run a suite of tests (defined in the TESTS variable) against the existing cluster. It will re-push the images needed for tests (tests, local-git, and the data-watcher-pusher). You can specify tests to run by passing the TESTS variable inline. If updating a test configuration, the tests image will need to be rebuilt and pushed, e.g rm build/tests && make build/tests && make kind/push-images IMAGES='tests' && make kind/retest TESTS='[api]' make kind/push-images # OR make kind/push-images IMAGES = 'tests local-git' This will push all the images up to the image registry. Specifying IMAGES will tag and push specific images. make kind/clean This will remove the KinD Lagoon cluster from your local Docker.","title":"Interact with your local Lagoon cluster"},{"location":"contributing-to-lagoon/developing-lagoon/#ansible","text":"The Lagoon test uses Ansible to run the test suite. Each range of tests for a specific function has been split into its own routine. If you are performing development work locally, select which tests to run, and update the $TESTS variable in the Makefile to reduce the concurrent tests running. The configuration for these tests is held in three services: tests is the Ansible test services themselves. The local testing routine runs each individual test as a separate container within a test-suite pod. These are listed below. local-git is a Git server hosted in the cluster that holds the source files for the tests. Ansible pulls and pushes to this repository throughout the tests api-data-watcher-pusher is a set of GraphQL mutations that pre-populates local Lagoon with the necessary Kubernetes configuration, test user accounts and SSH keys, and the necessary groups and notifications. Note that this will wipe local projects and environments on each run. The individual routines relevant to Kubernetes are: active-standby-kubernetes runs tests to check active/standby in Kubernetes. api runs tests for the API - branch/PR deployment, promotion. bitbucket , gitlab and github run tests for the specific SCM providers. drupal-php74 runs a single-pod MariaDB, MariaDB DBaaS and a Drush-specific test for a Drupal 8/9 project ( drupal-php73 doesn't do the Drush test). drupal-postgres runs a single-pod PostgreSQL and a PostgreSQL DBaaS test for a Drupal 8 project. elasticsearch runs a simple NGINX proxy to an Elasticsearch single-pod. features-api-variables runs tests that utilize variables in Lagoon. features-kubernetes runs a range of standard Lagoon tests, specific to Kubernetes. features-kubernetes-2 runs more advanced kubernetes-specific tests - covering multi-project and subfolder configurations. nginx , node and python run basic tests against those project types. node-mongodb runs a single-pod MongoDB test and a MongoDB DBaaS test against a Node.js app.","title":"Ansible"},{"location":"contributing-to-lagoon/developing-lagoon/#local-development","text":"Most services are written in Node.js . As many of these services share similar Node.js code and Node.js packages, we're using a feature of Yarn , called Yarn workspaces . Yarn workspaces need a package.json in the project's root directory that defines the workspaces. The development of the services can happen directly within Docker. Each container for each service is set up in a way that its source code is mounted into the running container ( see docker-compose.yml ). Node.js itself is watching the code via nodemon , and restarts the Node.js process automatically on a change.","title":"Local Development"},{"location":"contributing-to-lagoon/developing-lagoon/#lagoon-commons","text":"The services not only share many Node.js packages, but also share actual custom code. This code is within node-packages/lagoon-commons . It will be automatically symlinked by Yarn workspaces. Additionally, the nodemon of the services is set up in a way that it checks for changes in node-packages and will restart the node process automatically.","title":"lagoon-commons"},{"location":"contributing-to-lagoon/developing-lagoon/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"contributing-to-lagoon/developing-lagoon/#i-cant-build-a-docker-image-for-any-nodejs-based-service","text":"Rebuild the images via: make clean make build","title":"\u26a0I can't build a docker image for any Node.js based service"},{"location":"contributing-to-lagoon/developing-lagoon/#i-get-errors-about-missing-node_modules-content-when-i-try-to-build-run-a-nodejs-based-image","text":"Make sure to run yarn in Lagoon's root directory, since some services have common dependencies managed by yarn workspaces.","title":"\u26a0 I get errors about missing node_modules content when I try to build / run a Node.js based image"},{"location":"contributing-to-lagoon/developing-lagoon/#i-get-an-error-resolving-the-nipio-domains","text":"Error response from daemon: Get https://registry.172.18.0.2.nip.io:32080/v2/: dial tcp: lookup registry.172.18.0.2.nip.io: no such host This can happen if your local resolver filters private IPs from results. You can work around this by editing /etc/resolv.conf and adding a line like nameserver 8.8.8.8 at the top to use a public resolver that doesn't filter results.","title":"\u26a0 I get an error resolving the nip.io domains"},{"location":"contributing-to-lagoon/developing-lagoon/#example-workflows","text":"Here are some development scenarios and useful workflows for getting things done.","title":"Example workflows"},{"location":"contributing-to-lagoon/developing-lagoon/#editing-kubectl-build-deploy-dind","text":"This example shows a workflow for editing the Lagoon deploy logic.","title":"Editing kubectl-build-deploy-dind"},{"location":"contributing-to-lagoon/developing-lagoon/#edit-kubectl-build-deploy-dind","text":"In this example we want to add some functionality to the Lagoon deploy logic in the kubectl-build-deploy-dind image. Start a local KinD cluster with Lagoon installed from locally built images, and smoke-test it by running a single test suite: make -j8 kind/test TESTS = '[features-api-variables]' Edit images/kubectl-build-deploy-dind/build-deploy-docker-compose.sh . --- a/images/kubectl-build-deploy-dind/build-deploy-docker-compose.sh +++ b/images/kubectl-build-deploy-dind/build-deploy-docker-compose.sh @@ -1,5 +1,7 @@ #!/bin/bash +echo HELLO WORLD + function cronScheduleMoreOftenThan30Minutes() { #takes a unexpanded cron schedule, returns 0 if it's more often that 30 minutes MINUTE=$(echo $1 | (read -a ARRAY; echo ${ARRAY[0]}) ) Now rebuild the kubectl-build-deploy-dind image with the edits included. rm build/kubectl-build-deploy-dind make -j8 build/kubectl-build-deploy-dind Push the newly built image into the cluster registry. It will now be used for future deploys. make kind/push-images IMAGES = kubectl-build-deploy-dind Rerun the tests. make kind/retest TESTS = '[features-api-variables]' See the edits have been applied. $ kubectl -n ci-features-api-variables-control-k8s-lagoon-api-variables logs lagoon-build-lat2b | grep -A2 build-deploy-docker-compose.sh + . /kubectl-build-deploy/build-deploy-docker-compose.sh ++ echo HELLO WORLD HELLO WORLD","title":"Edit kubectl-build-deploy-dind"},{"location":"contributing-to-lagoon/developing-lagoon/#add-tests","text":"Repeat the first step above. Edit tests/tests/features-api-variables.yaml and add a test case. Rebuild the tests image. rm build/tests make -j8 build/tests Push the new tests image into the cluster registry. make kind/push-images IMAGES = tests Rerun the tests. make kind/retest TESTS = '[features-api-variables]'","title":"Add tests"},{"location":"contributing-to-lagoon/documentation/","text":"Contributing to Lagoon documentation # We really value anything that you can offer us! We've made building and viewing the documentation really straightforward, and the team is always ready to help out with reviews or pointers. We use mkdocs with the excellent Material theme. Viewing and updating docs locally # From the root of the Lagoon repo (you'll need Docker), run: docker run --rm -it -p 127 .0.0.1:8000:8000 -v ${ PWD } :/docs squidfunk/mkdocs-material This will start a development server on http://127.0.0.1:8000 , configured to live-reload on any updates. The Docker image contains all the necessary extensions. Editing in the cloud # Each documentation page also has an \"edit\" pencil in the top right, that will take you to the correct page in the git repository. Feel free to contribute here too - you can always use the inbuilt github.dev web-based editor . It's got basic markdown previews, but none of the mkdocs loveliness How we deploy documentation # We use the Deploy MkDocs GitHub Action to build all main branch pushes, and trigger a deployment of the gh-pages branch.","title":"Documentation"},{"location":"contributing-to-lagoon/documentation/#contributing-to-lagoon-documentation","text":"We really value anything that you can offer us! We've made building and viewing the documentation really straightforward, and the team is always ready to help out with reviews or pointers. We use mkdocs with the excellent Material theme.","title":"Contributing to Lagoon documentation"},{"location":"contributing-to-lagoon/documentation/#viewing-and-updating-docs-locally","text":"From the root of the Lagoon repo (you'll need Docker), run: docker run --rm -it -p 127 .0.0.1:8000:8000 -v ${ PWD } :/docs squidfunk/mkdocs-material This will start a development server on http://127.0.0.1:8000 , configured to live-reload on any updates. The Docker image contains all the necessary extensions.","title":"Viewing and updating docs locally"},{"location":"contributing-to-lagoon/documentation/#editing-in-the-cloud","text":"Each documentation page also has an \"edit\" pencil in the top right, that will take you to the correct page in the git repository. Feel free to contribute here too - you can always use the inbuilt github.dev web-based editor . It's got basic markdown previews, but none of the mkdocs loveliness","title":"Editing in the cloud"},{"location":"contributing-to-lagoon/documentation/#how-we-deploy-documentation","text":"We use the Deploy MkDocs GitHub Action to build all main branch pushes, and trigger a deployment of the gh-pages branch.","title":"How we deploy documentation"},{"location":"contributing-to-lagoon/tests/","text":"Tests # All of our tests are written with Ansible and mostly follow this approach: They create a new Git repository. Add and commit some files from a list of files (in tests/files ) into this Git repository. Push this Git repository to a Git server (either locally or on GitHub). Send a trigger to a trigger service (for example a webhook to the webhook handler, which is the same as a real webhook that would be sent). Starts to monitor the URL at which the test would expect something to happen (like deploying a Node.js app that has the Git branch as an HTML text). Compares the result on the URL with the expected result. Lagoon is mostly tested in 3 different ways: 1. Locally # During local development, the best way to test is locally. All tests are started via make . Make will download and build all the required dependencies. make tests This will run all defined tests. If you only want to run a subset of the tests, run make tests-list to see all existing tests and run them individually. For example, make tests/node will run the Node.js Docker images tests. In order to actually see what is happening inside the microservices, we can use make logs : make logs Or only for a specific service: make logs service=webhook-handler 2. Automated integration testing # In order to test pull requests that are created against Lagoon, we have a fully automatic integration test running on a dedicated Jenkins instance: https://ci.lagoon.sh . It is defined inside the .Jenkinsfile , and runs automatically for every pull request that is opened. This will build all images, start a Kubernetes cluster and run a series of tests. The tests can be found here: https://ci.lagoon.sh/blue/organizations/jenkins/lagoon/activity","title":"Tests"},{"location":"contributing-to-lagoon/tests/#tests","text":"All of our tests are written with Ansible and mostly follow this approach: They create a new Git repository. Add and commit some files from a list of files (in tests/files ) into this Git repository. Push this Git repository to a Git server (either locally or on GitHub). Send a trigger to a trigger service (for example a webhook to the webhook handler, which is the same as a real webhook that would be sent). Starts to monitor the URL at which the test would expect something to happen (like deploying a Node.js app that has the Git branch as an HTML text). Compares the result on the URL with the expected result. Lagoon is mostly tested in 3 different ways:","title":"Tests"},{"location":"contributing-to-lagoon/tests/#1-locally","text":"During local development, the best way to test is locally. All tests are started via make . Make will download and build all the required dependencies. make tests This will run all defined tests. If you only want to run a subset of the tests, run make tests-list to see all existing tests and run them individually. For example, make tests/node will run the Node.js Docker images tests. In order to actually see what is happening inside the microservices, we can use make logs : make logs Or only for a specific service: make logs service=webhook-handler","title":"1. Locally"},{"location":"contributing-to-lagoon/tests/#2-automated-integration-testing","text":"In order to test pull requests that are created against Lagoon, we have a fully automatic integration test running on a dedicated Jenkins instance: https://ci.lagoon.sh . It is defined inside the .Jenkinsfile , and runs automatically for every pull request that is opened. This will build all images, start a Kubernetes cluster and run a series of tests. The tests can be found here: https://ci.lagoon.sh/blue/organizations/jenkins/lagoon/activity","title":"2. Automated integration testing"},{"location":"docker-images/commons/","text":"Commons # The Lagoon commons Docker image . Based on the official Alpine images . This image has no functionality itself, but is instead a base image, intended to be extended and utilised to build other images. All the alpine-based images in Lagoon inherit components from commons. Included tooling # docker-sleep - standardised one-hour sleep fix-permissions - automatically fixes permissions on a given directory to all group read-write wait-for - a small script to ensure that services are up and running in the correct order - based off https://github.com/eficode/wait-for entrypoint-readiness - checks to make sure that long-running entrypoints have completed entrypoints - a script to source all entrypoints under /lagoon/entrypoints/* in an alphabetical/numerical order Included entrypoints # The list of default entrypoints in this image is found at https://github.com/uselagoon/lagoon-images/tree/main/images/commons/lagoon/entrypoints. Subsequent downstream images will also contribute entrypoints under /lagoon that are run in the eventual image.","title":"Commons"},{"location":"docker-images/commons/#commons","text":"The Lagoon commons Docker image . Based on the official Alpine images . This image has no functionality itself, but is instead a base image, intended to be extended and utilised to build other images. All the alpine-based images in Lagoon inherit components from commons.","title":"Commons"},{"location":"docker-images/commons/#included-tooling","text":"docker-sleep - standardised one-hour sleep fix-permissions - automatically fixes permissions on a given directory to all group read-write wait-for - a small script to ensure that services are up and running in the correct order - based off https://github.com/eficode/wait-for entrypoint-readiness - checks to make sure that long-running entrypoints have completed entrypoints - a script to source all entrypoints under /lagoon/entrypoints/* in an alphabetical/numerical order","title":"Included tooling"},{"location":"docker-images/commons/#included-entrypoints","text":"The list of default entrypoints in this image is found at https://github.com/uselagoon/lagoon-images/tree/main/images/commons/lagoon/entrypoints. Subsequent downstream images will also contribute entrypoints under /lagoon that are run in the eventual image.","title":"Included entrypoints"},{"location":"docker-images/elasticsearch/","text":"Elasticsearch # Elasticsearch is a distributed, open source search and analytics engine for all types of data, including textual, numerical, geospatial, structured, and unstructured. from https://www.elastic.co/ Supported versions # 6 Dockerfile - uselagoon/elasticsearch-6 7 Dockerfile - uselagoon/elasticsearch-7 Environment Variables # Environment Variable Default Description ES_JAVA_OPTS -Xms400m -Xmx400m Sets the memory usage of the Elasticsearch container. Both values need be the same value or Elasticsearch will not start cleanly Known issues # On Linux-based systems, the start of the Elasticsearch container may fail due to a low vm.max_map_count setting. elasticsearch_1 | ERROR: [ 1 ] bootstrap checks failed elasticsearch_1 | [ 1 ] : max virtual memory areas vm.max_map_count [ 65530 ] is too low, increase to at least [ 262144 ] Solution to this issue can be found here .","title":"Elasticsearch"},{"location":"docker-images/elasticsearch/#elasticsearch","text":"Elasticsearch is a distributed, open source search and analytics engine for all types of data, including textual, numerical, geospatial, structured, and unstructured. from https://www.elastic.co/","title":"Elasticsearch"},{"location":"docker-images/elasticsearch/#supported-versions","text":"6 Dockerfile - uselagoon/elasticsearch-6 7 Dockerfile - uselagoon/elasticsearch-7","title":"Supported versions"},{"location":"docker-images/elasticsearch/#environment-variables","text":"Environment Variable Default Description ES_JAVA_OPTS -Xms400m -Xmx400m Sets the memory usage of the Elasticsearch container. Both values need be the same value or Elasticsearch will not start cleanly","title":"Environment Variables"},{"location":"docker-images/elasticsearch/#known-issues","text":"On Linux-based systems, the start of the Elasticsearch container may fail due to a low vm.max_map_count setting. elasticsearch_1 | ERROR: [ 1 ] bootstrap checks failed elasticsearch_1 | [ 1 ] : max virtual memory areas vm.max_map_count [ 65530 ] is too low, increase to at least [ 262144 ] Solution to this issue can be found here .","title":"Known issues"},{"location":"docker-images/mariadb/","text":"MariaDB # MariaDB is the open source successor to MySQL. The Lagoon MariaDB image Dockerfile . Based on the official packages mariadb and mariadb-client provided by the the upstream Alpine image. This Dockerfile is intended to be used to set up a standalone MariaDB database server. 10.4 Dockerfile (Alpine 3.12 Support until May 2022) - uselagoon/mariadb-10.4 10.5 Dockerfile (Alpine 3.14 Support until May 2023) - uselagoon/mariadb-10.5 10.6 Dockerfile (Alpine 3.16 Support until May 2024) - uselagoon/mariadb-10.6 Note: As these images are not built from the upstream MariaDB images, their support follows a different cycle - and will only receive updates as long as the underlying Alpine images receive support - see https://alpinelinux.org/releases/ for more information. In practice, most MariaDB users will only be running these containers locally - the production instances will use the Managed Cloud Databases provided by the DBaaS Operator Lagoon adaptions # The default exposed port of mariadb containers is port 3306 . To allow Lagoon to select the best way to run the mariadb container, use lagoon.type: mariadb - this allows DBaaS operator to provision a cloud database if available in the cluster. Use lagoon.type: mariadb-single to specifically request mariadb in a container. Persistent storage is always provisioned for mariadb containers at /var/lib/mysql. This image is prepared to be used on Lagoon. There are therefore some things already done: Folder permissions are automatically adapted with fix-permissions , so this image will work with a random user. readiness-probe.sh script to check when MariaDB container is ready. docker-compose.yml snippet # ```yaml title=\"docker-compose.yml snippet\" mariadb: image: uselagoon/mariadb-10.6-drupal:latest labels: # tells Lagoon this is a mariadb database lagoon.type: mariadb ports: # exposes the port 3306 with a random local port, find it with `docker-compose port mariadb 3306` - \"3306\" volumes: # mounts a named volume at the default path for mariadb - db:/var/lib/mysql ``` Included tools # mysqltuner.pl - Perl script useful for database parameter tuning. mysql-backup.sh - Script for automating the daily MySQL backups on development environment. pwgen - Utility to generate random and complex passwords. Included my.cnf configuration file # The image ships a default MariaDB configuration file, optimized to work on Lagoon. Some options are configurable via environments variables (see Environment Variables ). Environment Variables # Environment variables defined in MariaDB base image: Environment Variable Default Description MARIADB_DATABASE lagoon Database name created at startup. MARIADB_USER lagoon Default user created at startup. MARIADB_PASSWORD lagoon Password of default user created at startup. MARIADB_ROOT_PASSWORD Lag00n MariaDB root user's password. MARIADB_CHARSET utf8mb4 Set the server charset. MARIADB_COLLATION utf8mb4_bin Set server collation. MARIADB_MAX_ALLOWED_PACKET 64M Set the max_allowed_packet size. MARIADB_INNODB_BUFFER_POOL_SIZE 256M Set the MariaDB InnoDB buffer pool size. MARIADB_INNODB_BUFFER_POOL_INSTANCES 1 Number of InnoDB buffer pool instances. MARIADB_INNODB_LOG_FILE_SIZE 64M Size of InnoDB log file. MARIADB_LOG_SLOW empty Variable to control the save of slow queries. MARIADB_LOG_QUERIES empty Variable to control the save of ALL queries. BACKUPS_DIR /var/lib/mysql/backup Default path for databases backups. MARIADB_DATA_DIR /var/lib/mysql Path of the mariadb data dir, be careful, changing this can occur data loss! MARIADB_COPY_DATA_DIR_SOURCE unset Path which the entrypoint script of mariadb will use to copy into the defined MARIADB_DATA_DIR , this can be used for prepopulating the MariaDB with a database. The scripts expects actual MariaDB data files and not a sql file! Plus it only copies data if the destination does not already have a mysql datadir in it. If the LAGOON_ENVIRONMENT_TYPE variable is set to production , performances are set accordingly by using MARIADB_INNODB_BUFFER_POOL_SIZE=1024 and MARIADB_INNODB_LOG_FILE_SIZE=256 .","title":"MariaDB"},{"location":"docker-images/mariadb/#mariadb","text":"MariaDB is the open source successor to MySQL. The Lagoon MariaDB image Dockerfile . Based on the official packages mariadb and mariadb-client provided by the the upstream Alpine image. This Dockerfile is intended to be used to set up a standalone MariaDB database server. 10.4 Dockerfile (Alpine 3.12 Support until May 2022) - uselagoon/mariadb-10.4 10.5 Dockerfile (Alpine 3.14 Support until May 2023) - uselagoon/mariadb-10.5 10.6 Dockerfile (Alpine 3.16 Support until May 2024) - uselagoon/mariadb-10.6 Note: As these images are not built from the upstream MariaDB images, their support follows a different cycle - and will only receive updates as long as the underlying Alpine images receive support - see https://alpinelinux.org/releases/ for more information. In practice, most MariaDB users will only be running these containers locally - the production instances will use the Managed Cloud Databases provided by the DBaaS Operator","title":"MariaDB"},{"location":"docker-images/mariadb/#lagoon-adaptions","text":"The default exposed port of mariadb containers is port 3306 . To allow Lagoon to select the best way to run the mariadb container, use lagoon.type: mariadb - this allows DBaaS operator to provision a cloud database if available in the cluster. Use lagoon.type: mariadb-single to specifically request mariadb in a container. Persistent storage is always provisioned for mariadb containers at /var/lib/mysql. This image is prepared to be used on Lagoon. There are therefore some things already done: Folder permissions are automatically adapted with fix-permissions , so this image will work with a random user. readiness-probe.sh script to check when MariaDB container is ready.","title":"Lagoon adaptions"},{"location":"docker-images/mariadb/#docker-composeyml-snippet","text":"```yaml title=\"docker-compose.yml snippet\" mariadb: image: uselagoon/mariadb-10.6-drupal:latest labels: # tells Lagoon this is a mariadb database lagoon.type: mariadb ports: # exposes the port 3306 with a random local port, find it with `docker-compose port mariadb 3306` - \"3306\" volumes: # mounts a named volume at the default path for mariadb - db:/var/lib/mysql ```","title":"docker-compose.yml snippet"},{"location":"docker-images/mariadb/#included-tools","text":"mysqltuner.pl - Perl script useful for database parameter tuning. mysql-backup.sh - Script for automating the daily MySQL backups on development environment. pwgen - Utility to generate random and complex passwords.","title":"Included tools"},{"location":"docker-images/mariadb/#included-mycnf-configuration-file","text":"The image ships a default MariaDB configuration file, optimized to work on Lagoon. Some options are configurable via environments variables (see Environment Variables ).","title":"Included my.cnf configuration file"},{"location":"docker-images/mariadb/#environment-variables","text":"Environment variables defined in MariaDB base image: Environment Variable Default Description MARIADB_DATABASE lagoon Database name created at startup. MARIADB_USER lagoon Default user created at startup. MARIADB_PASSWORD lagoon Password of default user created at startup. MARIADB_ROOT_PASSWORD Lag00n MariaDB root user's password. MARIADB_CHARSET utf8mb4 Set the server charset. MARIADB_COLLATION utf8mb4_bin Set server collation. MARIADB_MAX_ALLOWED_PACKET 64M Set the max_allowed_packet size. MARIADB_INNODB_BUFFER_POOL_SIZE 256M Set the MariaDB InnoDB buffer pool size. MARIADB_INNODB_BUFFER_POOL_INSTANCES 1 Number of InnoDB buffer pool instances. MARIADB_INNODB_LOG_FILE_SIZE 64M Size of InnoDB log file. MARIADB_LOG_SLOW empty Variable to control the save of slow queries. MARIADB_LOG_QUERIES empty Variable to control the save of ALL queries. BACKUPS_DIR /var/lib/mysql/backup Default path for databases backups. MARIADB_DATA_DIR /var/lib/mysql Path of the mariadb data dir, be careful, changing this can occur data loss! MARIADB_COPY_DATA_DIR_SOURCE unset Path which the entrypoint script of mariadb will use to copy into the defined MARIADB_DATA_DIR , this can be used for prepopulating the MariaDB with a database. The scripts expects actual MariaDB data files and not a sql file! Plus it only copies data if the destination does not already have a mysql datadir in it. If the LAGOON_ENVIRONMENT_TYPE variable is set to production , performances are set accordingly by using MARIADB_INNODB_BUFFER_POOL_SIZE=1024 and MARIADB_INNODB_LOG_FILE_SIZE=256 .","title":"Environment Variables"},{"location":"docker-images/mongodb/","text":"MongoDB # MongoDB is a general purpose, document-based, distributed database built for modern application developers and for the cloud era. MongoDB is a document database, which means it stores data in JSON-like documents. from mongodb.com Lagoon MongoDB image Dockerfile . Based on the official package mongodb provided by the alpine:3.8 image. This Dockerfile is intended to be used to set up a standalone MongoDB database server. Lagoon adaptions # This image is prepared to be used on Lagoon. There are therefore some things already done: Folder permissions are automatically adapted with fix-permissions , so this image will work with a random user, and therefore also on Kubernetes or Openshift.","title":"MongoDB"},{"location":"docker-images/mongodb/#mongodb","text":"MongoDB is a general purpose, document-based, distributed database built for modern application developers and for the cloud era. MongoDB is a document database, which means it stores data in JSON-like documents. from mongodb.com Lagoon MongoDB image Dockerfile . Based on the official package mongodb provided by the alpine:3.8 image. This Dockerfile is intended to be used to set up a standalone MongoDB database server.","title":"MongoDB"},{"location":"docker-images/mongodb/#lagoon-adaptions","text":"This image is prepared to be used on Lagoon. There are therefore some things already done: Folder permissions are automatically adapted with fix-permissions , so this image will work with a random user, and therefore also on Kubernetes or Openshift.","title":"Lagoon adaptions"},{"location":"docker-images/nginx/","text":"NGINX # The Lagoon nginx image Dockerfile . Based on the official openresty/openresty images . This Dockerfile is intended to be used as a base for any web servers within Lagoon. Lagoon adaptions # The default exposed port of nginx containers is port 8080 . This image is prepared to be used on Lagoon. There are therefore some things already done: Folder permissions are automatically adapted with fix-permissions , so this image will work with a random user. The files within /etc/nginx/* are parsed through envplate with a container-entrypoint. Included NGINX configuration ( static-files.conf ) # Warning: By default NGINX only serves static files - this can be used for static sites that don't require a database or PHP components: for example, static site generators like Hugo , Jekyll or Gatsby . If you need PHP, have a look at the php-fpm image and use nginx and php-fpm in tandem. Build the content during the build process and inject it into the nginx container. Helpers # redirects-map.conf # In order to create redirects, we have redirects-map.conf in place. This helps you to redirect marketing domains to sub-sites or do non-www to www redirects. If you have a lot of redirects, we suggest having redirects-map.conf stored next to your code for easier maintainability. Note: If you only have a few redirects, there's a handy trick to create the redirects with a RUN command in your nginx.dockerfile . Here's an example showing how to redirect www.example.com to example.com and preserve the request: RUN echo \"~^www.example.com http://example.com\\$request_uri;\" >> /etc/nginx/redirects-map.conf To get more details about the various types of redirects that can be achieved, see the documentation within the redirects-map.conf directly. After you put the redirects-map.conf in place, you also need to include it in your nginx.dockerfile in order to get the configuration file into your build. nginx.dockerfile COPY redirects-map.conf /etc/nginx/redirects-map.conf Basic Authentication # If you want to protect your site via basic authentication, you can do this by defining the environment variables BASIC_AUTH_USERNAME and BASIC_AUTH_PASSWORD within your .lagoon.env.environment files. For further explanation on how to set up Environment Variables on Lagoon, check here . Environment Variables # Environment variables are meant to contain common information for the nginx container. Environment Variable Default Description BASIC_AUTH restricted By not setting BASIC_AUTH this will instruct Lagoon to automatically enable basic authentication if BASIC_AUTH_USERNAME and BASIC_AUTH_PASSWORD are set. To disable basic authentication even if BASIC_AUTH_USERNAME and BASIC_AUTH_PASSWORD are set, set BASIC_AUTH to off . BASIC_AUTH_USERNAME (not set) Username for basic authentication BASIC_AUTH_PASSWORD (not set) Password for basic authentication (unencrypted) FAST_HEALTH_CHECK (not set) If set to true this will redirect GET requests from certain user agents (StatusCake, Pingdom, Site25x7, Uptime, nagios) to the lightweight Lagoon service healthcheck.","title":"NGINX"},{"location":"docker-images/nginx/#nginx","text":"The Lagoon nginx image Dockerfile . Based on the official openresty/openresty images . This Dockerfile is intended to be used as a base for any web servers within Lagoon.","title":"NGINX"},{"location":"docker-images/nginx/#lagoon-adaptions","text":"The default exposed port of nginx containers is port 8080 . This image is prepared to be used on Lagoon. There are therefore some things already done: Folder permissions are automatically adapted with fix-permissions , so this image will work with a random user. The files within /etc/nginx/* are parsed through envplate with a container-entrypoint.","title":"Lagoon adaptions"},{"location":"docker-images/nginx/#included-nginx-configuration-static-filesconf","text":"Warning: By default NGINX only serves static files - this can be used for static sites that don't require a database or PHP components: for example, static site generators like Hugo , Jekyll or Gatsby . If you need PHP, have a look at the php-fpm image and use nginx and php-fpm in tandem. Build the content during the build process and inject it into the nginx container.","title":"Included NGINX configuration (static-files.conf)"},{"location":"docker-images/nginx/#helpers","text":"","title":"Helpers"},{"location":"docker-images/nginx/#redirects-mapconf","text":"In order to create redirects, we have redirects-map.conf in place. This helps you to redirect marketing domains to sub-sites or do non-www to www redirects. If you have a lot of redirects, we suggest having redirects-map.conf stored next to your code for easier maintainability. Note: If you only have a few redirects, there's a handy trick to create the redirects with a RUN command in your nginx.dockerfile . Here's an example showing how to redirect www.example.com to example.com and preserve the request: RUN echo \"~^www.example.com http://example.com\\$request_uri;\" >> /etc/nginx/redirects-map.conf To get more details about the various types of redirects that can be achieved, see the documentation within the redirects-map.conf directly. After you put the redirects-map.conf in place, you also need to include it in your nginx.dockerfile in order to get the configuration file into your build. nginx.dockerfile COPY redirects-map.conf /etc/nginx/redirects-map.conf","title":"redirects-map.conf"},{"location":"docker-images/nginx/#basic-authentication","text":"If you want to protect your site via basic authentication, you can do this by defining the environment variables BASIC_AUTH_USERNAME and BASIC_AUTH_PASSWORD within your .lagoon.env.environment files. For further explanation on how to set up Environment Variables on Lagoon, check here .","title":"Basic Authentication"},{"location":"docker-images/nginx/#environment-variables","text":"Environment variables are meant to contain common information for the nginx container. Environment Variable Default Description BASIC_AUTH restricted By not setting BASIC_AUTH this will instruct Lagoon to automatically enable basic authentication if BASIC_AUTH_USERNAME and BASIC_AUTH_PASSWORD are set. To disable basic authentication even if BASIC_AUTH_USERNAME and BASIC_AUTH_PASSWORD are set, set BASIC_AUTH to off . BASIC_AUTH_USERNAME (not set) Username for basic authentication BASIC_AUTH_PASSWORD (not set) Password for basic authentication (unencrypted) FAST_HEALTH_CHECK (not set) If set to true this will redirect GET requests from certain user agents (StatusCake, Pingdom, Site25x7, Uptime, nagios) to the lightweight Lagoon service healthcheck.","title":"Environment Variables"},{"location":"docker-images/nodejs/","text":"Node.js # The Lagoon node Docker image . Based on the official Node Alpine images . Supported Versions # We ship 2 versions of Node.js images: the normal node:version image and the node:version-builder . The builder variant of those images comes with additional tooling that is needed when you build Node.js apps (such as the build libraries, npm and yarn). For a full list check out their Dockerfile . 12 (available for compatibility, no longer officially supported) - uselagoon/node-12 14 Dockerfile (Security Support until 30 April 2023) - uselagoon/node-14 16 Dockerfile (Security Support until 11 September 2023) - uselagoon/node-16 18 Dockerfile (Security Support until 30 April 2025) - uselagoon/node-18 Note: We stop updating EOL Node.js images usually with the Lagoon release that comes after the officially communicated EOL date: https://nodejs.org/en/about/releases/ . Lagoon adaptions # The default exposed port of node containers is port 3000 . Persistent storage is configurable in Lagoon, using the lagoon.type: node-persistent . See the docs for more info Use the following labels in your docker-compose.yml file to configure it: lagoon.persistent = use this to define the path in the container to use as persistent storage - e.g. /app/files lagoon.persistent.size = this to tell Lagoon how much storage to assign this path If you have multiple services that share the same storage, use this lagoon.persistent.name = (optional) use this to tell Lagoon to use the storage defined in another named service docker-compose.yml snippet # ```yaml title=\"docker-compose.yml snippet\" node: build: # this configures a build from a Dockerfile in the root folder context: . dockerfile: Dockerfile labels: # tells Lagoon this is a node service, configured with 500MB of persistent storage at /app/files lagoon.type: node-persistent lagoon.persistent: /app/files lagoon.persistent.size: 500Mi ports: # local development only # this exposes the port 3000 with a random local port - find it with docker-compose port node 3000 - \"3000\" volumes: # local development only # mounts a named volume (files) at the defined path for this service to replicate production - files:/app/files ``` Environment Variables # Environment variables are meant to contain common information for the PHP container. Environment Variable Default Description LAGOON_LOCALDEV_HTTP_PORT 3000 tells the local development environment on which port we are running","title":"Node.js"},{"location":"docker-images/nodejs/#nodejs","text":"The Lagoon node Docker image . Based on the official Node Alpine images .","title":"Node.js"},{"location":"docker-images/nodejs/#supported-versions","text":"We ship 2 versions of Node.js images: the normal node:version image and the node:version-builder . The builder variant of those images comes with additional tooling that is needed when you build Node.js apps (such as the build libraries, npm and yarn). For a full list check out their Dockerfile . 12 (available for compatibility, no longer officially supported) - uselagoon/node-12 14 Dockerfile (Security Support until 30 April 2023) - uselagoon/node-14 16 Dockerfile (Security Support until 11 September 2023) - uselagoon/node-16 18 Dockerfile (Security Support until 30 April 2025) - uselagoon/node-18 Note: We stop updating EOL Node.js images usually with the Lagoon release that comes after the officially communicated EOL date: https://nodejs.org/en/about/releases/ .","title":"Supported Versions"},{"location":"docker-images/nodejs/#lagoon-adaptions","text":"The default exposed port of node containers is port 3000 . Persistent storage is configurable in Lagoon, using the lagoon.type: node-persistent . See the docs for more info Use the following labels in your docker-compose.yml file to configure it: lagoon.persistent = use this to define the path in the container to use as persistent storage - e.g. /app/files lagoon.persistent.size = this to tell Lagoon how much storage to assign this path If you have multiple services that share the same storage, use this lagoon.persistent.name = (optional) use this to tell Lagoon to use the storage defined in another named service","title":"Lagoon adaptions"},{"location":"docker-images/nodejs/#docker-composeyml-snippet","text":"```yaml title=\"docker-compose.yml snippet\" node: build: # this configures a build from a Dockerfile in the root folder context: . dockerfile: Dockerfile labels: # tells Lagoon this is a node service, configured with 500MB of persistent storage at /app/files lagoon.type: node-persistent lagoon.persistent: /app/files lagoon.persistent.size: 500Mi ports: # local development only # this exposes the port 3000 with a random local port - find it with docker-compose port node 3000 - \"3000\" volumes: # local development only # mounts a named volume (files) at the defined path for this service to replicate production - files:/app/files ```","title":"docker-compose.yml snippet"},{"location":"docker-images/nodejs/#environment-variables","text":"Environment variables are meant to contain common information for the PHP container. Environment Variable Default Description LAGOON_LOCALDEV_HTTP_PORT 3000 tells the local development environment on which port we are running","title":"Environment Variables"},{"location":"docker-images/php-cli/","text":"PHP-CLI # The Lagoon php-cli Docker image . Based on Lagoon php-fpm image , it has all the needed command line tools for daily operations. Containers (or pods) started from cli images are responsible for building code for Composer or Node.js based projects. The image also contains database cli s for both MariaDB and PostgreSQL. Note: This Dockerfile is intended to be used as a base for any cli needs within Lagoon. Supported versions # 7.3 (available for compatibility, no longer officially supported) 7.4 Dockerfile - uselagoon/php-7.4-cli 8.0 Dockerfile - uselagoon/php-8.0-cli 8.1 Dockerfile - uselagoon/php-8.1-cli All PHP versions use their own Dockerfiles. Lagoon adaptions # This image is prepared to be used on Lagoon. There are therefore some things already done: Folder permissions are automatically adapted with fix-permissions , so this image will work with a random user. COMPOSER_ALLOW_SUPERUSER=1 removes warning about use of Composer as root. 80-shell-timeout.sh script checks if containers are running in a Kubernetes environment and then set a 10 minutes timeout to idle cli pods. cli containers use an SSH key injected by Lagoon or defined into SSH_PRIVATE_KEY environment variable. Included cli tools # The included cli tools are: composer version 1.9.0 (changeable via COMPOSER_VERSION and COMPOSER_HASH_SHA256 ) node.js verison 17 (as of Mar 2022) npm yarn mariadb-client postgresql-client Change Node.js Version # By default this image ships with the nodejs-current package (v17 as of Mar 2022). If you need another version you can remove the current version and install the one of your choice. For example, to install Node.js 16, modify your dockerfile to include: RUN apk del nodejs-current \\ && apk add --no-cache nodejs=~16 Environment variables # Environment variables allow some configuration to be customised in a repeatable way. Name Default Description MARIADB_MAX_ALLOWED_PACKET 64M Controls the max allowed packet for the MySql client. Changing an environment variable # Environment variables can be changed in the docker-compose.yml file. x-environment: &default-environment MARIADB_MAX_ALLOWED_PACKET: 128M service: cli: environment: << : *default-environment","title":"PHP-CLI"},{"location":"docker-images/php-cli/#php-cli","text":"The Lagoon php-cli Docker image . Based on Lagoon php-fpm image , it has all the needed command line tools for daily operations. Containers (or pods) started from cli images are responsible for building code for Composer or Node.js based projects. The image also contains database cli s for both MariaDB and PostgreSQL. Note: This Dockerfile is intended to be used as a base for any cli needs within Lagoon.","title":"PHP-CLI"},{"location":"docker-images/php-cli/#supported-versions","text":"7.3 (available for compatibility, no longer officially supported) 7.4 Dockerfile - uselagoon/php-7.4-cli 8.0 Dockerfile - uselagoon/php-8.0-cli 8.1 Dockerfile - uselagoon/php-8.1-cli All PHP versions use their own Dockerfiles.","title":"Supported versions"},{"location":"docker-images/php-cli/#lagoon-adaptions","text":"This image is prepared to be used on Lagoon. There are therefore some things already done: Folder permissions are automatically adapted with fix-permissions , so this image will work with a random user. COMPOSER_ALLOW_SUPERUSER=1 removes warning about use of Composer as root. 80-shell-timeout.sh script checks if containers are running in a Kubernetes environment and then set a 10 minutes timeout to idle cli pods. cli containers use an SSH key injected by Lagoon or defined into SSH_PRIVATE_KEY environment variable.","title":"Lagoon adaptions"},{"location":"docker-images/php-cli/#included-cli-tools","text":"The included cli tools are: composer version 1.9.0 (changeable via COMPOSER_VERSION and COMPOSER_HASH_SHA256 ) node.js verison 17 (as of Mar 2022) npm yarn mariadb-client postgresql-client","title":"Included cli tools"},{"location":"docker-images/php-cli/#change-nodejs-version","text":"By default this image ships with the nodejs-current package (v17 as of Mar 2022). If you need another version you can remove the current version and install the one of your choice. For example, to install Node.js 16, modify your dockerfile to include: RUN apk del nodejs-current \\ && apk add --no-cache nodejs=~16","title":"Change Node.js Version"},{"location":"docker-images/php-cli/#environment-variables","text":"Environment variables allow some configuration to be customised in a repeatable way. Name Default Description MARIADB_MAX_ALLOWED_PACKET 64M Controls the max allowed packet for the MySql client.","title":"Environment variables"},{"location":"docker-images/php-cli/#changing-an-environment-variable","text":"Environment variables can be changed in the docker-compose.yml file. x-environment: &default-environment MARIADB_MAX_ALLOWED_PACKET: 128M service: cli: environment: << : *default-environment","title":"Changing an environment variable"},{"location":"docker-images/php-fpm/","text":"PHP-FPM # The Lagoon php-fpm Docker image . Based on the official PHP Alpine images . PHP-FPM (FastCGI Process Manager) is an alternative PHP FastCGI implementation with some additional features useful for sites of any size, especially busier sites. from https://php-fpm.org/ FastCGI is a way of having server scripts execute time-consuming code just once instead of every time the script is loaded, reducing overhead. Note: This Dockerfile is intended to be used as a base for any PHP needs within Lagoon. This image itself does not create a web server, rather a php-fpm fastcgi listener. You may need to adapt the php-fpm pool config. Supported versions # 7.3 (available for compatibility, no longer officially supported) - uselagoon/php-7.3-fpm 7.4 Dockerfile (Security Support until 28 November 2022) - uselagoon/php-7.4-fpm 8.0 Dockerfile (Security Support until 26 November 2023) - uselagoon/php-8.0-fpm 8.1 Dockerfile (Security Support until 25 November 2024) - uselagoon/php-8.1-fpm All PHP versions use their own Dockerfiles. Note: We stop updating End of Life (EOL) PHP images usually with the Lagoon release that comes after the officially communicated EOL date: https://www.php.net/supported-versions.php . Previous published versions will remain available. Lagoon adaptions # This image is prepared to be used on Lagoon. There are therefore some things are already done: Folder permissions are automatically adapted with fix-permissions , so this image will work with a random user. The /usr/local/etc/php/php.ini and /usr/local/etc/php-fpm.conf , plus all files within /usr/local/etc/php-fpm.d/ , are parsed through envplate with a container-entrypoint. See the Dockerfile for installed PHP extensions. To install further extensions, extend your Dockerfile from this image. Install extensions according to the docs, under the heading How to install more PHP extensions. Included PHP config # The included PHP config contains sensible values that will make the creation of PHP pools config easier. Here is a list of some of these. Check /usr/local/etc/php.ini , /usr/local/etc/php-fpm.conf for all of them: Value Details max_execution_time = 900 Changeable via PHP_MAX_EXECUTION_TIME . realpath_cache_size = 256k For handling big PHP projects. memory_limit = 400M For big PHP projects (changeable via PHP_MEMORY_LIMIT ). opcache.memory_consumption = 265 For big PHP projects. opcache.enable_file_override = 1 and opcache.huge_code_pages = 1 For faster PHP. display_errors = Off and display_startup_errors = Off For sensible production values (changeable via PHP_DISPLAY_ERRORS and PHP_DISPLAY_STARTUP_ERRORS ). upload_max_filesize = 2048M For big file uploads. apc.shm_size = 32m and apc.enabled = 1 Changeable via PHP_APC_SHM_SIZE and PHP_APC_ENABLED . Also, php-fpm error logging happens in stderr . \ud83d\udca1 If you don't like any of these configs, you have three possibilities: If they are changeable via environment variables, use environment variables (this is the preferred method, see table of environment variables below ). Create your own fpm-pool config and set via php_admin_value and php_admin_flag . Learn more about them in this documentation for Running PHP as an Apache module . This documentation refers to Apache, but it is also the case for php-fpm ). Important: If you want to provide your own php-fpm pool, overwrite the file /usr/local/etc/php-fpm.d/www.conf with your own config, or rename this file if you want it to have another name. If you don't do that, the provided pool will be started! PHP values with the PHP_INI_SYSTEM changeable mode cannot be changed via an fpm-pool config. They need to be changed either via already provided environment variables or: Provide your own php.ini or php-fpm.conf file (this is the least preferred method). default fpm-pool # This image is shipped with an fpm-pool config ( php-fpm.d/www.conf ) that creates an fpm-pool and listens on port 9000. This is because we try to provide an image which already covers most needs for PHP, so you don't need to create your own. You are welcome to do so if you like, though! Here a short description of what this file does: Listens on port 9000 via IPv4 and IPv6. Uses the pm dynamic and creates between 2-50 children. Re-spawns php-fpm pool children after 500 requests to prevent memory leaks. Replies with pong when making a fastcgi request to /ping (good for automated testing to check if the pool started). catch_workers_output = yes to see PHP errors. clear_env = no to be able to inject PHP environment variables via regular Docker environment variables. Environment Variables # Environment variables are meant to contain common information for the PHP container. Environment Variable Default Description NEWRELIC_ENABLED false Enable NewRelic performance monitoring, needs NEWRELIC_LICENSE be configured. NEWRELIC_LICENSE (not set) NewRelic license to be used, Important: NEWRELIC_ENABLED needs to be set to true in order for NewRelic to be enabled. NEWRELIC_BROWSER_MONITORING_ENABLED true This enables auto-insertion of the JavaScript fragments for NewRelic browser monitoring, Important: NEWRELIC_ENABLED needs to be set to true in order for NewRelic to be enabled. PHP_APC_ENABLED 1 Can be set to 0 to disable APC. See php.net . PHP_APC_SHM_SIZE 32m The size of each shared memory segment given. See php.net . PHP_DISPLAY_ERRORS Off This determines whether errors should be printed to the screen as part of the output or if they should be hidden from the user. See php.net . PHP_DISPLAY_STARTUP_ERRORS Off Even when PHP_DISPLAY_ERRORS is on, errors that occur during PHP's startup sequence are not displayed. It's strongly recommended to keep it off, except for debugging. See php.net . PHP_ERROR_REPORTING Production: E_ALL & ~E_DEPRECATED & ~E_STRICT Development: E_ALL & ~E_DEPRECATED & ~E_STRICT & ~E_NOTICE The desired logging level you'd like PHP to use. See php.net . PHP_FPM_PM_MAX_CHILDREN 50 The the maximum number of child processes. See php.net . PHP_FPM_PM_MAX_REQUESTS 500 The number of requests each child process should execute before re-spawning. See php.net . PHP_FPM_PM_MAX_SPARE_SERVERS 2 The desired maximum number of idle server processes. See php.net . PHP_FPM_PM_MIN_SPARE_SERVERS 2 The desired minimum number of idle server processes. See php.net . PHP_FPM_PM_PROCESS_IDLE_TIMEOUT 60s The number of seconds after which an idle process will be killed. See php.net . PHP_FPM_PM_START_SERVERS 2 The number of child processes created on startup. See php.net . PHP_MAX_EXECUTION_TIME 900 Maximum execution time of each script, in seconds. See php.net . PHP_MAX_FILE_UPLOADS 20 The maximum number of files allowed to be uploaded simultaneously. See php.net . PHP_MAX_INPUT_VARS 2000 How many input variables will be accepted. See php.net . PHP_MEMORY_LIMIT 400M Maximum amount of memory a script may consume. See php.net . XDEBUG_ENABLE (not set) Used to enable xdebug extension. BLACKFIRE_ENABLED (not set) Used to enable blackfire extension with setting variable to TRUE or true BLACKFIRE_SERVER_ID (not set) Set to Blackfire Server ID provided by Blackfire.io. Needs BLACKFIRE_ENABLED set to true BLACKFIRE_SERVER_TOKEN (not set) Set to Blackfire Server Token provided by Blackfire.io. Needs BLACKFIRE_ENABLED set to true BLACKFIRE_LOG_LEVEL 3 Change the log level of the blackfire agent. By default set to 3 , available values: log verbosity level (4: debug, 3: info, 2: warning, 1: error) See blackfire.io .","title":"PHP-FPM"},{"location":"docker-images/php-fpm/#php-fpm","text":"The Lagoon php-fpm Docker image . Based on the official PHP Alpine images . PHP-FPM (FastCGI Process Manager) is an alternative PHP FastCGI implementation with some additional features useful for sites of any size, especially busier sites. from https://php-fpm.org/ FastCGI is a way of having server scripts execute time-consuming code just once instead of every time the script is loaded, reducing overhead. Note: This Dockerfile is intended to be used as a base for any PHP needs within Lagoon. This image itself does not create a web server, rather a php-fpm fastcgi listener. You may need to adapt the php-fpm pool config.","title":"PHP-FPM"},{"location":"docker-images/php-fpm/#supported-versions","text":"7.3 (available for compatibility, no longer officially supported) - uselagoon/php-7.3-fpm 7.4 Dockerfile (Security Support until 28 November 2022) - uselagoon/php-7.4-fpm 8.0 Dockerfile (Security Support until 26 November 2023) - uselagoon/php-8.0-fpm 8.1 Dockerfile (Security Support until 25 November 2024) - uselagoon/php-8.1-fpm All PHP versions use their own Dockerfiles. Note: We stop updating End of Life (EOL) PHP images usually with the Lagoon release that comes after the officially communicated EOL date: https://www.php.net/supported-versions.php . Previous published versions will remain available.","title":"Supported versions"},{"location":"docker-images/php-fpm/#lagoon-adaptions","text":"This image is prepared to be used on Lagoon. There are therefore some things are already done: Folder permissions are automatically adapted with fix-permissions , so this image will work with a random user. The /usr/local/etc/php/php.ini and /usr/local/etc/php-fpm.conf , plus all files within /usr/local/etc/php-fpm.d/ , are parsed through envplate with a container-entrypoint. See the Dockerfile for installed PHP extensions. To install further extensions, extend your Dockerfile from this image. Install extensions according to the docs, under the heading How to install more PHP extensions.","title":"Lagoon adaptions"},{"location":"docker-images/php-fpm/#included-php-config","text":"The included PHP config contains sensible values that will make the creation of PHP pools config easier. Here is a list of some of these. Check /usr/local/etc/php.ini , /usr/local/etc/php-fpm.conf for all of them: Value Details max_execution_time = 900 Changeable via PHP_MAX_EXECUTION_TIME . realpath_cache_size = 256k For handling big PHP projects. memory_limit = 400M For big PHP projects (changeable via PHP_MEMORY_LIMIT ). opcache.memory_consumption = 265 For big PHP projects. opcache.enable_file_override = 1 and opcache.huge_code_pages = 1 For faster PHP. display_errors = Off and display_startup_errors = Off For sensible production values (changeable via PHP_DISPLAY_ERRORS and PHP_DISPLAY_STARTUP_ERRORS ). upload_max_filesize = 2048M For big file uploads. apc.shm_size = 32m and apc.enabled = 1 Changeable via PHP_APC_SHM_SIZE and PHP_APC_ENABLED . Also, php-fpm error logging happens in stderr . \ud83d\udca1 If you don't like any of these configs, you have three possibilities: If they are changeable via environment variables, use environment variables (this is the preferred method, see table of environment variables below ). Create your own fpm-pool config and set via php_admin_value and php_admin_flag . Learn more about them in this documentation for Running PHP as an Apache module . This documentation refers to Apache, but it is also the case for php-fpm ). Important: If you want to provide your own php-fpm pool, overwrite the file /usr/local/etc/php-fpm.d/www.conf with your own config, or rename this file if you want it to have another name. If you don't do that, the provided pool will be started! PHP values with the PHP_INI_SYSTEM changeable mode cannot be changed via an fpm-pool config. They need to be changed either via already provided environment variables or: Provide your own php.ini or php-fpm.conf file (this is the least preferred method).","title":"Included PHP config"},{"location":"docker-images/php-fpm/#default-fpm-pool","text":"This image is shipped with an fpm-pool config ( php-fpm.d/www.conf ) that creates an fpm-pool and listens on port 9000. This is because we try to provide an image which already covers most needs for PHP, so you don't need to create your own. You are welcome to do so if you like, though! Here a short description of what this file does: Listens on port 9000 via IPv4 and IPv6. Uses the pm dynamic and creates between 2-50 children. Re-spawns php-fpm pool children after 500 requests to prevent memory leaks. Replies with pong when making a fastcgi request to /ping (good for automated testing to check if the pool started). catch_workers_output = yes to see PHP errors. clear_env = no to be able to inject PHP environment variables via regular Docker environment variables.","title":"default fpm-pool"},{"location":"docker-images/php-fpm/#environment-variables","text":"Environment variables are meant to contain common information for the PHP container. Environment Variable Default Description NEWRELIC_ENABLED false Enable NewRelic performance monitoring, needs NEWRELIC_LICENSE be configured. NEWRELIC_LICENSE (not set) NewRelic license to be used, Important: NEWRELIC_ENABLED needs to be set to true in order for NewRelic to be enabled. NEWRELIC_BROWSER_MONITORING_ENABLED true This enables auto-insertion of the JavaScript fragments for NewRelic browser monitoring, Important: NEWRELIC_ENABLED needs to be set to true in order for NewRelic to be enabled. PHP_APC_ENABLED 1 Can be set to 0 to disable APC. See php.net . PHP_APC_SHM_SIZE 32m The size of each shared memory segment given. See php.net . PHP_DISPLAY_ERRORS Off This determines whether errors should be printed to the screen as part of the output or if they should be hidden from the user. See php.net . PHP_DISPLAY_STARTUP_ERRORS Off Even when PHP_DISPLAY_ERRORS is on, errors that occur during PHP's startup sequence are not displayed. It's strongly recommended to keep it off, except for debugging. See php.net . PHP_ERROR_REPORTING Production: E_ALL & ~E_DEPRECATED & ~E_STRICT Development: E_ALL & ~E_DEPRECATED & ~E_STRICT & ~E_NOTICE The desired logging level you'd like PHP to use. See php.net . PHP_FPM_PM_MAX_CHILDREN 50 The the maximum number of child processes. See php.net . PHP_FPM_PM_MAX_REQUESTS 500 The number of requests each child process should execute before re-spawning. See php.net . PHP_FPM_PM_MAX_SPARE_SERVERS 2 The desired maximum number of idle server processes. See php.net . PHP_FPM_PM_MIN_SPARE_SERVERS 2 The desired minimum number of idle server processes. See php.net . PHP_FPM_PM_PROCESS_IDLE_TIMEOUT 60s The number of seconds after which an idle process will be killed. See php.net . PHP_FPM_PM_START_SERVERS 2 The number of child processes created on startup. See php.net . PHP_MAX_EXECUTION_TIME 900 Maximum execution time of each script, in seconds. See php.net . PHP_MAX_FILE_UPLOADS 20 The maximum number of files allowed to be uploaded simultaneously. See php.net . PHP_MAX_INPUT_VARS 2000 How many input variables will be accepted. See php.net . PHP_MEMORY_LIMIT 400M Maximum amount of memory a script may consume. See php.net . XDEBUG_ENABLE (not set) Used to enable xdebug extension. BLACKFIRE_ENABLED (not set) Used to enable blackfire extension with setting variable to TRUE or true BLACKFIRE_SERVER_ID (not set) Set to Blackfire Server ID provided by Blackfire.io. Needs BLACKFIRE_ENABLED set to true BLACKFIRE_SERVER_TOKEN (not set) Set to Blackfire Server Token provided by Blackfire.io. Needs BLACKFIRE_ENABLED set to true BLACKFIRE_LOG_LEVEL 3 Change the log level of the blackfire agent. By default set to 3 , available values: log verbosity level (4: debug, 3: info, 2: warning, 1: error) See blackfire.io .","title":"Environment Variables"},{"location":"docker-images/postgres/","text":"PostgreSQL # The Lagoon PostgreSQL Docker image . Based on the official PostgreSQL Alpine images . Supported versions # 11 Dockerfile (Security Support until November 2023) - uselagoon/postgres-11 12 Dockerfile (Security Support until November 2024) - uselagoon/postgres-12 13 Dockerfile (Security Support until November 2025) - uselagoon/postgres-13 14 Dockerfile (Security Support until November 2026) - uselagoon/postgres-14 Note: We stop updating EOL PostgreSQL images usually with the Lagoon release that comes after the officially communicated EOL date: https://www.postgresql.org/support/versioning Lagoon adaptions # The default exposed port of postgres containers is port 5432 . To allow Lagoon to select the best way to run the postgres container, use lagoon.type: postgres - this allows DBaaS operator to provision a cloud database if available in the cluster. Use lagoon.type: postgres-single to specifically request postgres in a container. Persistent storage is always provisioned for postgres containers at /var/lib/postgresql/data. docker-compose.yml snippet # ```yaml title=\"docker-compose.yml snippet\" postgres: image: uselagoon/postgres-14-drupal:latest labels: # tells Lagoon this is a postgres database lagoon.type: postgres ports: # exposes the port 5432 with a random local port, find it with `docker-compose port postgres 5432` - \"5432\" volumes: # mounts a named volume at the default path for postgres - db:/var/lib/postgresql/data ``` Tips & Tricks # If you have SQL statements that need to be run immediately after container startup to initialize the database, you can place those .sql files in the container's docker-entrypoint-initdb.d directory. Any .sql files contained in that directory are run automatically at startup, as part of bringing the PostgreSQL container up. Note: Take note that these scripts are only run if the container is started with an empty database.","title":"PostgreSQL"},{"location":"docker-images/postgres/#postgresql","text":"The Lagoon PostgreSQL Docker image . Based on the official PostgreSQL Alpine images .","title":"PostgreSQL"},{"location":"docker-images/postgres/#supported-versions","text":"11 Dockerfile (Security Support until November 2023) - uselagoon/postgres-11 12 Dockerfile (Security Support until November 2024) - uselagoon/postgres-12 13 Dockerfile (Security Support until November 2025) - uselagoon/postgres-13 14 Dockerfile (Security Support until November 2026) - uselagoon/postgres-14 Note: We stop updating EOL PostgreSQL images usually with the Lagoon release that comes after the officially communicated EOL date: https://www.postgresql.org/support/versioning","title":"Supported versions"},{"location":"docker-images/postgres/#lagoon-adaptions","text":"The default exposed port of postgres containers is port 5432 . To allow Lagoon to select the best way to run the postgres container, use lagoon.type: postgres - this allows DBaaS operator to provision a cloud database if available in the cluster. Use lagoon.type: postgres-single to specifically request postgres in a container. Persistent storage is always provisioned for postgres containers at /var/lib/postgresql/data.","title":"Lagoon adaptions"},{"location":"docker-images/postgres/#docker-composeyml-snippet","text":"```yaml title=\"docker-compose.yml snippet\" postgres: image: uselagoon/postgres-14-drupal:latest labels: # tells Lagoon this is a postgres database lagoon.type: postgres ports: # exposes the port 5432 with a random local port, find it with `docker-compose port postgres 5432` - \"5432\" volumes: # mounts a named volume at the default path for postgres - db:/var/lib/postgresql/data ```","title":"docker-compose.yml snippet"},{"location":"docker-images/postgres/#tips-tricks","text":"If you have SQL statements that need to be run immediately after container startup to initialize the database, you can place those .sql files in the container's docker-entrypoint-initdb.d directory. Any .sql files contained in that directory are run automatically at startup, as part of bringing the PostgreSQL container up. Note: Take note that these scripts are only run if the container is started with an empty database.","title":"Tips &amp; Tricks"},{"location":"docker-images/python/","text":"Python # The Lagoon python Docker image . Based on the official Python Alpine images . Supported Versions # 2.7 (available for compatibility, no longer officially supported) - uselagoon/python-2.7 3.7 Dockerfile (Security Support until July 2023) - uselagoon/python-3.7 3.8 Dockerfile (Security Support until October 2024) - uselagoon/python-3.8 3.9 Dockerfile (Security Support until October 2025) - uselagoon/python-3.9 Note: We stop updating and publishing EOL Python images usually with the Lagoon release that comes after the officially communicated EOL date: https://devguide.python.org/versions/#versions . Previous published versions will remain available. Lagoon adaptions # The default exposed port of python containers is port 8800 . Persistent storage is configurable in Lagoon, using the lagoon.type: python-persistent . See the docs for more info Use the following labels in your docker-compose.yml file to configure it: lagoon.persistent = use this to define the path in the container to use as persistent storage - e.g. /app/files lagoon.persistent.size = this to tell Lagoon how much storage to assign this path If you have multiple services that share the same storage, use this lagoon.persistent.name = (optional) use this to tell Lagoon to use the storage defined in another named service docker-compose.yml snippet # ```yaml title=\"docker-compose.yml snippet\" python: build: # this configures a build from a Dockerfile in the root folder context: . dockerfile: Dockerfile labels: # tells Lagoon this is a python service, configured with 500MB of persistent storage at /app/files lagoon.type: python-persistent lagoon.persistent: /app/files lagoon.persistent.size: 500Mi ports: # local development only # this exposes the port 8800 with a random local port - find it with docker-compose port python 8800 - \"8800\" volumes: # local development only # mounts a named volume (files) at the defined path for this service to replicate production - files:/app/files ``` Environment Variables # Environment variables are meant to contain common information for the PHP container. Environment Variable Default Description LAGOON_LOCALDEV_HTTP_PORT 3000 tells the local development environment on which port we are running","title":"Python"},{"location":"docker-images/python/#python","text":"The Lagoon python Docker image . Based on the official Python Alpine images .","title":"Python"},{"location":"docker-images/python/#supported-versions","text":"2.7 (available for compatibility, no longer officially supported) - uselagoon/python-2.7 3.7 Dockerfile (Security Support until July 2023) - uselagoon/python-3.7 3.8 Dockerfile (Security Support until October 2024) - uselagoon/python-3.8 3.9 Dockerfile (Security Support until October 2025) - uselagoon/python-3.9 Note: We stop updating and publishing EOL Python images usually with the Lagoon release that comes after the officially communicated EOL date: https://devguide.python.org/versions/#versions . Previous published versions will remain available.","title":"Supported Versions"},{"location":"docker-images/python/#lagoon-adaptions","text":"The default exposed port of python containers is port 8800 . Persistent storage is configurable in Lagoon, using the lagoon.type: python-persistent . See the docs for more info Use the following labels in your docker-compose.yml file to configure it: lagoon.persistent = use this to define the path in the container to use as persistent storage - e.g. /app/files lagoon.persistent.size = this to tell Lagoon how much storage to assign this path If you have multiple services that share the same storage, use this lagoon.persistent.name = (optional) use this to tell Lagoon to use the storage defined in another named service","title":"Lagoon adaptions"},{"location":"docker-images/python/#docker-composeyml-snippet","text":"```yaml title=\"docker-compose.yml snippet\" python: build: # this configures a build from a Dockerfile in the root folder context: . dockerfile: Dockerfile labels: # tells Lagoon this is a python service, configured with 500MB of persistent storage at /app/files lagoon.type: python-persistent lagoon.persistent: /app/files lagoon.persistent.size: 500Mi ports: # local development only # this exposes the port 8800 with a random local port - find it with docker-compose port python 8800 - \"8800\" volumes: # local development only # mounts a named volume (files) at the defined path for this service to replicate production - files:/app/files ```","title":"docker-compose.yml snippet"},{"location":"docker-images/python/#environment-variables","text":"Environment variables are meant to contain common information for the PHP container. Environment Variable Default Description LAGOON_LOCALDEV_HTTP_PORT 3000 tells the local development environment on which port we are running","title":"Environment Variables"},{"location":"docker-images/rabbitmq/","text":"RabbitMQ # The Lagoon RabbitMQ Dockerfile with management plugin installed. Based on the official rabbitmq:3-management image at docker-hub . This Dockerfile is intended to be used to set up a standalone RabbitMQ queue broker, as well as a base image to set up a cluster with high availability queue support by default ( Mirrored queues ). By default, the RabbitMQ broker is started as single node. If you want to start a cluster, you need to use the rabbitmq-cluster Docker image, based on rabbitmq image plus the rabbitmq_peer_discovery_k8s plugin. Lagoon adaptions # This image is prepared to be used on Lagoon. There are therefore some things already done: Folder permissions are automatically adapted with fix-permissions , so this image will work with a random user. The file /etc/rabbitmq/definitions.json is parsed through envplate with a container-entrypoint. Included RabbitMQ default schema (definitions.json) # To enable the support for Mirrored Queues, at least one policy must exist. In the definitions.json schema file, minimal entities are defined to make the container run: virtualhost ( vhost ), username , and password to access management UI, permissions , and policies . By default, a policy called lagoon-ha is created at startup, but it is not active because it doesn't match any queue's name pattern (see default Environment Variables ). definitions.json \"policies\" : [ { \"vhost\" : \"${RABBITMQ_DEFAULT_VHOST}\" , \"name\" : \"lagoon-ha\" , \"pattern\" : \"${RABBITMQ_DEFAULT_HA_PATTERN}\" , \"definition\" : { \"ha-mode\" : \"exactly\" , \"ha-params\" : 2 , \"ha-sync-mode\" : \"automatic\" , \"ha-sync-batch-size\" : 5 }} ] By default, the ha-mode is set to exactly which controls the exact number of mirroring nodes for a queue (mirrors). The number of nodes is controller by ha-params . For further information and custom configuration, please refer to official RabbitMQ documentation . Environment Variables # Environment variables defined in RabbitMQ base image: Environment Variable Default Description RABBITMQ_DEFAULT_USER guest Username for management UI access. RABBITMQ_DEFAULT_PASS guest Password for management UI access. RABBITMQ_DEFAULT_VHOST / RabbitMQ main virtualhost. RABBITMQ_DEFAULT_HA_PATTERN ^$ Regular expression to match for mirrored queues.","title":"RabbitMQ"},{"location":"docker-images/rabbitmq/#rabbitmq","text":"The Lagoon RabbitMQ Dockerfile with management plugin installed. Based on the official rabbitmq:3-management image at docker-hub . This Dockerfile is intended to be used to set up a standalone RabbitMQ queue broker, as well as a base image to set up a cluster with high availability queue support by default ( Mirrored queues ). By default, the RabbitMQ broker is started as single node. If you want to start a cluster, you need to use the rabbitmq-cluster Docker image, based on rabbitmq image plus the rabbitmq_peer_discovery_k8s plugin.","title":"RabbitMQ"},{"location":"docker-images/rabbitmq/#lagoon-adaptions","text":"This image is prepared to be used on Lagoon. There are therefore some things already done: Folder permissions are automatically adapted with fix-permissions , so this image will work with a random user. The file /etc/rabbitmq/definitions.json is parsed through envplate with a container-entrypoint.","title":"Lagoon adaptions"},{"location":"docker-images/rabbitmq/#included-rabbitmq-default-schema-definitionsjson","text":"To enable the support for Mirrored Queues, at least one policy must exist. In the definitions.json schema file, minimal entities are defined to make the container run: virtualhost ( vhost ), username , and password to access management UI, permissions , and policies . By default, a policy called lagoon-ha is created at startup, but it is not active because it doesn't match any queue's name pattern (see default Environment Variables ). definitions.json \"policies\" : [ { \"vhost\" : \"${RABBITMQ_DEFAULT_VHOST}\" , \"name\" : \"lagoon-ha\" , \"pattern\" : \"${RABBITMQ_DEFAULT_HA_PATTERN}\" , \"definition\" : { \"ha-mode\" : \"exactly\" , \"ha-params\" : 2 , \"ha-sync-mode\" : \"automatic\" , \"ha-sync-batch-size\" : 5 }} ] By default, the ha-mode is set to exactly which controls the exact number of mirroring nodes for a queue (mirrors). The number of nodes is controller by ha-params . For further information and custom configuration, please refer to official RabbitMQ documentation .","title":"Included RabbitMQ default schema (definitions.json)"},{"location":"docker-images/rabbitmq/#environment-variables","text":"Environment variables defined in RabbitMQ base image: Environment Variable Default Description RABBITMQ_DEFAULT_USER guest Username for management UI access. RABBITMQ_DEFAULT_PASS guest Password for management UI access. RABBITMQ_DEFAULT_VHOST / RabbitMQ main virtualhost. RABBITMQ_DEFAULT_HA_PATTERN ^$ Regular expression to match for mirrored queues.","title":"Environment Variables"},{"location":"docker-images/redis/","text":"Redis # Lagoon Redis image Dockerfile , based on offical redis:alpine image . This Dockerfile is intended to be used to set up a standalone Redis ephemeral server by default. Supported versions # 5 Dockerfile - uselagoon/redis-5 or uselagoon/redis-5-persistent 6 Dockerfile - uselagoon/redis-6 or uselagoon/redis-6-persistent Usage # There are 2 different flavors of Redis Images: Ephemeral and Persistent . Ephemeral # The ephemeral image is intended to be used as an in-memory cache for applications and will not retain data across container restarts. When being used as an in-memory (RAM) cache, the first thing you might want to tune if you have large caches is to adapt the MAXMEMORY variable. This variable controls the maximum amount of memory (RAM) which redis will use to store cached items. Persistent # The persistent Redis image will persist data across container restarts and can be used for queues or application data that will need persistence. We don't typically suggest using a persistent redis for in-memory cache scenarios as this might have unintended side-effects on your application while a Redis container is restarting and loading data from disk. Lagoon adaptions # This image is prepared to be used on Lagoon. There are therefore some things already done: Folder permissions are automatically adapted with fix-permissions so this image will work with a random user. The files within /etc/redis/* are templated using envplate via a container-entrypoint. Included redis.conf configuration file # The image ships a default Redis configuration file, optimized to work on Lagoon. Environment Variables # Some options in this default configuration are configurable via runtime environment variables . Environment Variable Default Description DATABASES -1 Default number of databases created at startup LOGLEVEL notice Define the level of logs MAXMEMORY 100mb Maximum amount of memory MAXMEMORYPOLICY allkeys-lru The policy to use when evicting keys if redis reaches its maximum memory usage REDIS_PASSWORD disabled Enables authentication feature Custom configuration # By building on the base image you can include custom configuration. See https://raw.githubusercontent.com/antirez/redis/4.0/redis.conf for full documentation of the redis configuration file. Redis-persistent # Based on the Lagoon redis image , the Lagoon redis-persistent Docker image is intended for use when the Redis service must be utilized in persistent mode (ie. with a persistent volume where keys will be saved to disk). It differs from redis only with the FLAVOR environment variable, which will use the respective Redis configuration according to the version of redis in use. Troubleshooting # The Lagoon redis images all come pre-loaded with the redis-cli command, which allows for querying the redis service for information and setting config values dynamically. To use this utility, you can simply SSH into your redis pod by using the instructions [here] (../using-lagoon-advanced/ssh.md) with redis as the pod value then run it from the terminal once you've connected. Maximum Memory Policy # By default, the Lagoon redis images are set to use the allkeys-lru policy. This policy will alow ANY keys stored in redis to be evicted if/when the redis service hits its maxmemory limit according to when the key was least recently used. For typical installations, this is the ideal configuration, as Drupal may not set a TTL value for each key cached in redis. If the maxmemory-policy is set to something like volatile-lru and Drupal doesn't provide these TTL tags, this would result in the redis container filling up, being totally unable to evict ANY keys, and ceasing to accept new cache keys at all. More information on redis' maxmemory policies can be found in redis' official documentation . Danger Proceed with caution: Chaging this setting can lead to redis becoming completely full and cause outages as a result. Tuning redis' maxmemory value # Finding the optimal amount of memory to give redis can be quite the difficult task. Before attempting to tune your redis cache's memory size, it is prudent to let it run normally for as long as practical, with at least a day of typical usage being the ideal minimum timeframe. There are a few high level things you can look at when tuning these memory values: The first thing to check is the percentage of memory in use by redis currently. If this percentage is less than 50% , you might consider lowering the maxmemory value by 25%. If this percentage is between 50% and 75% , things are running just fine. If this value is greater than 75% , then it's worth looking at other variables to see if maxmemory needs to be increased. If you find that your redis' memory usage percentage is high, the next thing to look at is the number of key evictions. A large number of key evictions and a memory usage greater than 95% is a fairly good indicator that your redis needs a higher maxmemory setting. If the number of key evictions doesn't seem high and typical response times are reasonable, this is simply indicative of redis doing its job and managing its allocated memory as expected. Example commands # The following commands can be used to view information about the redis service: View all info about the redis service: redis-cli info View service memory information: redis-cli info memory View service keyspace information: redis-cli info keyspace View service statistics: redis-cli info stats It is also possible to set values for the redis service dynamically without a restart of the redis service. It is important to note that these dynamically set values will not persist if the pod is restarted (which can happen as a result of a deployment, maintenance, or even just being shuffled from one node to another). Set maxmemory config value dynamically to 500mb : config set maxmemory 500mb Set maxmemory-policy config value dynamically to volatile-lru : config set maxmemory-policy volatile-lru","title":"Redis"},{"location":"docker-images/redis/#redis","text":"Lagoon Redis image Dockerfile , based on offical redis:alpine image . This Dockerfile is intended to be used to set up a standalone Redis ephemeral server by default.","title":"Redis"},{"location":"docker-images/redis/#supported-versions","text":"5 Dockerfile - uselagoon/redis-5 or uselagoon/redis-5-persistent 6 Dockerfile - uselagoon/redis-6 or uselagoon/redis-6-persistent","title":"Supported versions"},{"location":"docker-images/redis/#usage","text":"There are 2 different flavors of Redis Images: Ephemeral and Persistent .","title":"Usage"},{"location":"docker-images/redis/#ephemeral","text":"The ephemeral image is intended to be used as an in-memory cache for applications and will not retain data across container restarts. When being used as an in-memory (RAM) cache, the first thing you might want to tune if you have large caches is to adapt the MAXMEMORY variable. This variable controls the maximum amount of memory (RAM) which redis will use to store cached items.","title":"Ephemeral"},{"location":"docker-images/redis/#persistent","text":"The persistent Redis image will persist data across container restarts and can be used for queues or application data that will need persistence. We don't typically suggest using a persistent redis for in-memory cache scenarios as this might have unintended side-effects on your application while a Redis container is restarting and loading data from disk.","title":"Persistent"},{"location":"docker-images/redis/#lagoon-adaptions","text":"This image is prepared to be used on Lagoon. There are therefore some things already done: Folder permissions are automatically adapted with fix-permissions so this image will work with a random user. The files within /etc/redis/* are templated using envplate via a container-entrypoint.","title":"Lagoon adaptions"},{"location":"docker-images/redis/#included-redisconf-configuration-file","text":"The image ships a default Redis configuration file, optimized to work on Lagoon.","title":"Included redis.conf configuration file"},{"location":"docker-images/redis/#environment-variables","text":"Some options in this default configuration are configurable via runtime environment variables . Environment Variable Default Description DATABASES -1 Default number of databases created at startup LOGLEVEL notice Define the level of logs MAXMEMORY 100mb Maximum amount of memory MAXMEMORYPOLICY allkeys-lru The policy to use when evicting keys if redis reaches its maximum memory usage REDIS_PASSWORD disabled Enables authentication feature","title":"Environment Variables"},{"location":"docker-images/redis/#custom-configuration","text":"By building on the base image you can include custom configuration. See https://raw.githubusercontent.com/antirez/redis/4.0/redis.conf for full documentation of the redis configuration file.","title":"Custom configuration"},{"location":"docker-images/redis/#redis-persistent","text":"Based on the Lagoon redis image , the Lagoon redis-persistent Docker image is intended for use when the Redis service must be utilized in persistent mode (ie. with a persistent volume where keys will be saved to disk). It differs from redis only with the FLAVOR environment variable, which will use the respective Redis configuration according to the version of redis in use.","title":"Redis-persistent"},{"location":"docker-images/redis/#troubleshooting","text":"The Lagoon redis images all come pre-loaded with the redis-cli command, which allows for querying the redis service for information and setting config values dynamically. To use this utility, you can simply SSH into your redis pod by using the instructions [here] (../using-lagoon-advanced/ssh.md) with redis as the pod value then run it from the terminal once you've connected.","title":"Troubleshooting"},{"location":"docker-images/redis/#maximum-memory-policy","text":"By default, the Lagoon redis images are set to use the allkeys-lru policy. This policy will alow ANY keys stored in redis to be evicted if/when the redis service hits its maxmemory limit according to when the key was least recently used. For typical installations, this is the ideal configuration, as Drupal may not set a TTL value for each key cached in redis. If the maxmemory-policy is set to something like volatile-lru and Drupal doesn't provide these TTL tags, this would result in the redis container filling up, being totally unable to evict ANY keys, and ceasing to accept new cache keys at all. More information on redis' maxmemory policies can be found in redis' official documentation . Danger Proceed with caution: Chaging this setting can lead to redis becoming completely full and cause outages as a result.","title":"Maximum Memory Policy"},{"location":"docker-images/redis/#tuning-redis-maxmemory-value","text":"Finding the optimal amount of memory to give redis can be quite the difficult task. Before attempting to tune your redis cache's memory size, it is prudent to let it run normally for as long as practical, with at least a day of typical usage being the ideal minimum timeframe. There are a few high level things you can look at when tuning these memory values: The first thing to check is the percentage of memory in use by redis currently. If this percentage is less than 50% , you might consider lowering the maxmemory value by 25%. If this percentage is between 50% and 75% , things are running just fine. If this value is greater than 75% , then it's worth looking at other variables to see if maxmemory needs to be increased. If you find that your redis' memory usage percentage is high, the next thing to look at is the number of key evictions. A large number of key evictions and a memory usage greater than 95% is a fairly good indicator that your redis needs a higher maxmemory setting. If the number of key evictions doesn't seem high and typical response times are reasonable, this is simply indicative of redis doing its job and managing its allocated memory as expected.","title":"Tuning redis' maxmemory value"},{"location":"docker-images/redis/#example-commands","text":"The following commands can be used to view information about the redis service: View all info about the redis service: redis-cli info View service memory information: redis-cli info memory View service keyspace information: redis-cli info keyspace View service statistics: redis-cli info stats It is also possible to set values for the redis service dynamically without a restart of the redis service. It is important to note that these dynamically set values will not persist if the pod is restarted (which can happen as a result of a deployment, maintenance, or even just being shuffled from one node to another). Set maxmemory config value dynamically to 500mb : config set maxmemory 500mb Set maxmemory-policy config value dynamically to volatile-lru : config set maxmemory-policy volatile-lru","title":"Example commands"},{"location":"docker-images/ruby/","text":"Node.js # The Lagoon ruby Docker image . Based on the official Python Alpine images . Supported Versions # 3.0 Dockerfile (Security Support until March 2024) - uselagoon/ruby-3.0 3.1 Dockerfile (Security Support until March 2025) - uselagoon/ruby-3.1 Note: We stop updating and publishing EOL Ruby images usually with the Lagoon release that comes after the officially communicated EOL date: https://www.ruby-lang.org/en/downloads/releases/ . Previous versions will remain available. Lagoon adaptions # The default exposed port of ruby containers is port 3000 . Lagoon has no \"pre-defined\" type for Ruby services, they should be configured with the lagoon.type: generic and a port set with lagoon.port: 3000 docker-compose.yml snippet # ```yaml title=\"docker-compose.yml snippet\" ruby: build: # this configures a build from a Dockerfile in the root folder context: . dockerfile: Dockerfile labels: # tells Lagoon this is a generic service, configured to expose port 3000 lagoon.type: generic lagoon.port: 3000 ports: # local development only # this exposes the port 3000 with a random local port - find it with docker-compose port ruby 3000 - \"3000\" ``` Environment Variables # Environment variables are meant to contain common information for the PHP container. Environment Variable Default Description LAGOON_LOCALDEV_HTTP_PORT 3000 tells the local development environment on which port we are running","title":"Ruby"},{"location":"docker-images/ruby/#nodejs","text":"The Lagoon ruby Docker image . Based on the official Python Alpine images .","title":"Node.js"},{"location":"docker-images/ruby/#supported-versions","text":"3.0 Dockerfile (Security Support until March 2024) - uselagoon/ruby-3.0 3.1 Dockerfile (Security Support until March 2025) - uselagoon/ruby-3.1 Note: We stop updating and publishing EOL Ruby images usually with the Lagoon release that comes after the officially communicated EOL date: https://www.ruby-lang.org/en/downloads/releases/ . Previous versions will remain available.","title":"Supported Versions"},{"location":"docker-images/ruby/#lagoon-adaptions","text":"The default exposed port of ruby containers is port 3000 . Lagoon has no \"pre-defined\" type for Ruby services, they should be configured with the lagoon.type: generic and a port set with lagoon.port: 3000","title":"Lagoon adaptions"},{"location":"docker-images/ruby/#docker-composeyml-snippet","text":"```yaml title=\"docker-compose.yml snippet\" ruby: build: # this configures a build from a Dockerfile in the root folder context: . dockerfile: Dockerfile labels: # tells Lagoon this is a generic service, configured to expose port 3000 lagoon.type: generic lagoon.port: 3000 ports: # local development only # this exposes the port 3000 with a random local port - find it with docker-compose port ruby 3000 - \"3000\" ```","title":"docker-compose.yml snippet"},{"location":"docker-images/ruby/#environment-variables","text":"Environment variables are meant to contain common information for the PHP container. Environment Variable Default Description LAGOON_LOCALDEV_HTTP_PORT 3000 tells the local development environment on which port we are running","title":"Environment Variables"},{"location":"docker-images/solr/","text":"Solr # The Lagoon Solr image Dockerfile . Based on the official solr:<version>-alpine images . This Dockerfile is intended to be used to set up a standalone Solr server with an initial core mycore . Supported Versions # 5.5 (available for compatibility, no longer officially supported) 6.6 (available for compatibility, no longer officially supported) 7.7 Dockerfile (no longer actively supported upstream) - uselagoon/solr-7.7 7 Dockerfile - uselagoon/solr-7 8 Dockerfile - uselagoon/solr-8 Lagoon adaptions # This image is prepared to be used on Lagoon. There are therefore some things already done: Folder permissions are automatically adapted with fix-permissions , so this image will work with a random user. 10-solr-port.sh script to fix and check Solr port. 20-solr-datadir.sh script to check if Solr config is compliant for Lagoon. This sets directory paths, and configures the correct lock type. Environment Variables # Environment variables defined in Solr base image. Environment Variable Default Description SOLR_JAVA_MEM 512M Default Java HEAP size (ie. SOLR_JAVA_MEM=\"-Xms10g -Xmx10g\" ). SOLR_DATA_DIR /var/solr Path of the solr data dir, be careful, changing this can occur data loss! SOLR_COPY_DATA_DIR_SOURCE unset Path which the entrypoint script of solr will use to copy into the defined SOLR_DATA_DIR , this can be used for prepopulating the Solr with a core. The scripts expects actual Solr data files! Plus it only copies data if the destination does not already have a solr core in it.","title":"Solr"},{"location":"docker-images/solr/#solr","text":"The Lagoon Solr image Dockerfile . Based on the official solr:<version>-alpine images . This Dockerfile is intended to be used to set up a standalone Solr server with an initial core mycore .","title":"Solr"},{"location":"docker-images/solr/#supported-versions","text":"5.5 (available for compatibility, no longer officially supported) 6.6 (available for compatibility, no longer officially supported) 7.7 Dockerfile (no longer actively supported upstream) - uselagoon/solr-7.7 7 Dockerfile - uselagoon/solr-7 8 Dockerfile - uselagoon/solr-8","title":"Supported Versions"},{"location":"docker-images/solr/#lagoon-adaptions","text":"This image is prepared to be used on Lagoon. There are therefore some things already done: Folder permissions are automatically adapted with fix-permissions , so this image will work with a random user. 10-solr-port.sh script to fix and check Solr port. 20-solr-datadir.sh script to check if Solr config is compliant for Lagoon. This sets directory paths, and configures the correct lock type.","title":"Lagoon adaptions"},{"location":"docker-images/solr/#environment-variables","text":"Environment variables defined in Solr base image. Environment Variable Default Description SOLR_JAVA_MEM 512M Default Java HEAP size (ie. SOLR_JAVA_MEM=\"-Xms10g -Xmx10g\" ). SOLR_DATA_DIR /var/solr Path of the solr data dir, be careful, changing this can occur data loss! SOLR_COPY_DATA_DIR_SOURCE unset Path which the entrypoint script of solr will use to copy into the defined SOLR_DATA_DIR , this can be used for prepopulating the Solr with a core. The scripts expects actual Solr data files! Plus it only copies data if the destination does not already have a solr core in it.","title":"Environment Variables"},{"location":"docker-images/varnish/","text":"Varnish # The Lagoon Varnish image Dockerfile . Based on the official varnish package provided by alpine:3.7 image. By default, vmod-dynamic and vmod-bodyaccess modules are installed. Lagoon adaptions # This image is prepared to be used on Lagoon. There are therefore some things already done: Folder permissions are automatically adapted with fix-permissions , so this image will work with a random user. Included varnish modules # vbox-dynamic - Dynamic backends from DNS lookups and service discovery from SRV records. vbox-bodyaccess - Varnish vmod that lets you access the request body. Included default.vcl configuration file # The image ships a default vcl configuration file, optimized to work on Lagoon. Some options are configurable via environments variables (see Environment Variables ). Environment Variables # Environment variables defined in Varnish base image Environment Variable Default Description VARNISH_BACKEND_HOST NGINX Default backend host. VARNISH_BACKEND_PORT 8080 Default listening varnish port. VARNISH_SECRET lagoon_default_secret Varnish secret used to connect to management. LIBVMOD_DYNAMIC_VERSION 5.2 Default version of vmod-dynamic module. LIBVMOD_BODYACCESS_VERSION 5.0 Default version of vmod-bodyaccess module. HTTP_RESP_HDR_LEN 8k Maximum length of any HTTP backend response header. HTTP_RESP_SIZE 32k Maximum number of bytes of HTTP backend response we will deal with. NUKE_LIMIT 150 Maximum number of objects we attempt to nuke in order to make space for an object body. CACHE_TYPE malloc Type of varnish cache. CACHE_SIZE 100M Cache size. LISTEN 8080 Default backend server port. MANAGEMENT_LISTEN 6082 Default management listening port.","title":"Varnish"},{"location":"docker-images/varnish/#varnish","text":"The Lagoon Varnish image Dockerfile . Based on the official varnish package provided by alpine:3.7 image. By default, vmod-dynamic and vmod-bodyaccess modules are installed.","title":"Varnish"},{"location":"docker-images/varnish/#lagoon-adaptions","text":"This image is prepared to be used on Lagoon. There are therefore some things already done: Folder permissions are automatically adapted with fix-permissions , so this image will work with a random user.","title":"Lagoon adaptions"},{"location":"docker-images/varnish/#included-varnish-modules","text":"vbox-dynamic - Dynamic backends from DNS lookups and service discovery from SRV records. vbox-bodyaccess - Varnish vmod that lets you access the request body.","title":"Included varnish modules"},{"location":"docker-images/varnish/#included-defaultvcl-configuration-file","text":"The image ships a default vcl configuration file, optimized to work on Lagoon. Some options are configurable via environments variables (see Environment Variables ).","title":"Included default.vcl configuration file"},{"location":"docker-images/varnish/#environment-variables","text":"Environment variables defined in Varnish base image Environment Variable Default Description VARNISH_BACKEND_HOST NGINX Default backend host. VARNISH_BACKEND_PORT 8080 Default listening varnish port. VARNISH_SECRET lagoon_default_secret Varnish secret used to connect to management. LIBVMOD_DYNAMIC_VERSION 5.2 Default version of vmod-dynamic module. LIBVMOD_BODYACCESS_VERSION 5.0 Default version of vmod-bodyaccess module. HTTP_RESP_HDR_LEN 8k Maximum length of any HTTP backend response header. HTTP_RESP_SIZE 32k Maximum number of bytes of HTTP backend response we will deal with. NUKE_LIMIT 150 Maximum number of objects we attempt to nuke in order to make space for an object body. CACHE_TYPE malloc Type of varnish cache. CACHE_SIZE 100M Cache size. LISTEN 8080 Default backend server port. MANAGEMENT_LISTEN 6082 Default management listening port.","title":"Environment Variables"},{"location":"drupal/","text":"Drupal on Lagoon # Lagoon was built to host Drupal sites (no, seriously, it was - at least initially!) In this section you'll find more information on the various services that have been customised for use with Drupal. drupal_integrations Drupal scaffolding package # The drupal_integrations package, available on pacakagist extends Drupal's core-composer-scaffold for use on Lagoon. It also provides additional Drush command drush la to retreive the Drush aliases for your Lagoon project. lagoon-logs Drupal module # The lagoon_logs module, availalble on drupal.org provides zero-configuration logging for Drupal on Lagoon.","title":"Overview"},{"location":"drupal/#drupal-on-lagoon","text":"Lagoon was built to host Drupal sites (no, seriously, it was - at least initially!) In this section you'll find more information on the various services that have been customised for use with Drupal.","title":"Drupal on Lagoon"},{"location":"drupal/#drupal_integrations-drupal-scaffolding-package","text":"The drupal_integrations package, available on pacakagist extends Drupal's core-composer-scaffold for use on Lagoon. It also provides additional Drush command drush la to retreive the Drush aliases for your Lagoon project.","title":"drupal_integrations Drupal scaffolding package"},{"location":"drupal/#lagoon-logs-drupal-module","text":"The lagoon_logs module, availalble on drupal.org provides zero-configuration logging for Drupal on Lagoon.","title":"lagoon-logs Drupal module"},{"location":"drupal/drush-9/","text":"Drush 9 # Aliases # Unfortunately, Drush 9 does not provide the ability to inject dynamic site aliases like Drush 8 did. We are working with the Drush team to implement this again. In the meantime, we have a workaround that allows you to use Drush 9 with Lagoon. Basic Idea # Drush 9 provides a new command, drush site:alias-convert , which can convert Drush 8-style site aliases over to the Drush 9 YAML site alias style. This will create a on- time export of the site aliases currently existing in Lagoon, and save them in /app/drush/sites . These are then used when running a command like drush sa . Preparation # In order to be able to use drush site:alias-convert , you need to do the following: Rename the aliases.drushrc.php inside the drush folder to lagoon.aliases.drushrc.php . Generate Site Aliases # You can now convert your Drush aliases by running the following command in your project using the cli container: docker-compose exec cli drush site:alias-convert /app/drush/sites --yes It's good practice to commit the resulting YAML files into your Git repository, so that they are in place for your fellow developers. Use Site Aliases # In Drush 9, all site aliases are prefixed with a group. In our case, this is lagoon . You can show all site aliases with their prefix via: drush sa --format=list and to use them: drush @lagoon.main ssh Update Site Aliases # If a new environment in Lagoon has been created, you can run drush site:alias-convert to update the site aliases file. If running this command does not update lagoon.site.yml , try deleting lagoon.site.yml first, and then re-run drush site:alias-convert . Drush rsync from local to remote environments # If you would like to sync files from a local environment to a remote environment, you need to pass additional parameters: drush rsync @self:%files @lagoon.main:%files -- --omit-dir-times --no-perms --no-group --no-owner --chmod=ugo=rwX This also applies to syncing one remote environment to another, if you're not using the Lagoon tasks UI to copy files between environments. For example, if you wanted to sync the files from @lagoon.main to @lagoon.dev , and ran drush rsync @lagoon.main @lagoon.dev locally, without the extra parameters, you would probably run into a \"Cannot specify two remote aliases\" error. To resolve this, you would first need to SSH into your destination environment drush @lagoon.dev ssh , and then execute the rsync command with parameters similar to the above: drush rsync @lagoon.main:%files @self:%files -- --omit-dir-times --no-perms --no-group --no-owner --chmod=ugo=rwX This is not necessary if you rsync from a remote to a local environment. Also, we're working with the Drush maintainers to find a way to inject this automatically.","title":"Drush 9"},{"location":"drupal/drush-9/#drush-9","text":"","title":"Drush 9"},{"location":"drupal/drush-9/#aliases","text":"Unfortunately, Drush 9 does not provide the ability to inject dynamic site aliases like Drush 8 did. We are working with the Drush team to implement this again. In the meantime, we have a workaround that allows you to use Drush 9 with Lagoon.","title":"Aliases"},{"location":"drupal/drush-9/#basic-idea","text":"Drush 9 provides a new command, drush site:alias-convert , which can convert Drush 8-style site aliases over to the Drush 9 YAML site alias style. This will create a on- time export of the site aliases currently existing in Lagoon, and save them in /app/drush/sites . These are then used when running a command like drush sa .","title":"Basic Idea"},{"location":"drupal/drush-9/#preparation","text":"In order to be able to use drush site:alias-convert , you need to do the following: Rename the aliases.drushrc.php inside the drush folder to lagoon.aliases.drushrc.php .","title":"Preparation"},{"location":"drupal/drush-9/#generate-site-aliases","text":"You can now convert your Drush aliases by running the following command in your project using the cli container: docker-compose exec cli drush site:alias-convert /app/drush/sites --yes It's good practice to commit the resulting YAML files into your Git repository, so that they are in place for your fellow developers.","title":"Generate Site Aliases"},{"location":"drupal/drush-9/#use-site-aliases","text":"In Drush 9, all site aliases are prefixed with a group. In our case, this is lagoon . You can show all site aliases with their prefix via: drush sa --format=list and to use them: drush @lagoon.main ssh","title":"Use Site Aliases"},{"location":"drupal/drush-9/#update-site-aliases","text":"If a new environment in Lagoon has been created, you can run drush site:alias-convert to update the site aliases file. If running this command does not update lagoon.site.yml , try deleting lagoon.site.yml first, and then re-run drush site:alias-convert .","title":"Update Site Aliases"},{"location":"drupal/drush-9/#drush-rsync-from-local-to-remote-environments","text":"If you would like to sync files from a local environment to a remote environment, you need to pass additional parameters: drush rsync @self:%files @lagoon.main:%files -- --omit-dir-times --no-perms --no-group --no-owner --chmod=ugo=rwX This also applies to syncing one remote environment to another, if you're not using the Lagoon tasks UI to copy files between environments. For example, if you wanted to sync the files from @lagoon.main to @lagoon.dev , and ran drush rsync @lagoon.main @lagoon.dev locally, without the extra parameters, you would probably run into a \"Cannot specify two remote aliases\" error. To resolve this, you would first need to SSH into your destination environment drush @lagoon.dev ssh , and then execute the rsync command with parameters similar to the above: drush rsync @lagoon.main:%files @self:%files -- --omit-dir-times --no-perms --no-group --no-owner --chmod=ugo=rwX This is not necessary if you rsync from a remote to a local environment. Also, we're working with the Drush maintainers to find a way to inject this automatically.","title":"Drush rsync from local to remote environments"},{"location":"drupal/first-deployment-of-drupal/","text":"First Deployment of Drupal # 1. Make sure you are all set # In order to make your first deployment a successful one, please make sure that your Drupal Project is Lagoonized and you have set up the project in Lagoon. If not, don't worry! Follow the Step-by-Step Guide which show you how this works. 2. Push # With Lagoon, you create a new deployment by pushing into a branch that is configured to be deployed. If you don't have any new code to push, don't worry, you can run git commit --allow-empty -m \"go, go! Power Rangers!\" git push This will trigger a push, and the Git hosting will inform Lagoon about this push via the configured webhook. If all is correct, you will see a notification in your configured chat system (this is configured by your friendly Lagoon administrator): This tells you that Lagoon has just started to deploy your code. Depending on the size of the codebase and amount of containers, this will take a couple of seconds. Just relax. If you'd like to know what's happening now, check out the Build and Deploy Process of Lagoon . You can also check your Lagoon UI to see the progress of any deployment (your Lagoon administrator has the info). 3. A fail # Depending on the post-rollout tasks defined in .lagoon.yml , you might have run some tasks like drush updb or drush cr . These Drush tasks depend on a database existing within the environment, which obviously does not exist yet. Let's fix that! Keep reading. 4. Synchronize local database to the remote Lagoon environment # With full Drush site alias support in Lagoon, you can synchronize a local database with the remote Lagoon environment. Warning: You may have to tell pygmy about your public keys before the next step. If you get an error like Permission denied (publickey) , check out the documentation here: pygmy - adding ssh keys First let's make sure that you can see the Drush site aliases: drush sa This should return your just deployed environment (let's assume you just pushed into develop ): [ drupal-example ] cli-drupal:/app$ drush sa @develop @self default With this we can now synchronize the local database (which is represented in Drush via the site alias @self ) with the remote one ( @develop ): drush sql-sync @self @develop You should see something like: [drupal-example]cli-drupal:/app$ drush sql-sync @self @develop You will destroy data in ssh.lagoon.amazeeio.cloud/drupal and replace with data from drupal. Do you really want to continue? (y/n): y Starting to dump database on Source. [ok] Database dump saved to /home/drush-backups/drupal/20180227075813/drupal_20180227_075815.sql.gz [success] Starting to discover temporary files directory on Destination. [ok] You will delete files in drupal-example-develop@ssh.lagoon.amazeeio.cloud:/tmp/drupal_20180227_075815.sql.gz and replace with data from /home/drush-backups/drupal/20180227075813/drupal_20180227_075815.sql.gz Do you really want to continue? (y/n): y Copying dump file from Source to Destination. [ok] Starting to import dump file onto Destination database. Now let's try another deployment, again an empty push: git commit --allow-empty -m \"go, go! Power Rangers!\" git push This time all should be green: Click on the links in the notification, and you should see your Drupal site loaded in all its beauty! It will probably not have images yet, which we will handle in Step 6 . If it is still failing, check the logs link for more information. 5. Synchronize local files to the remote Lagoon environment # You probably guessed it: we can do it with Drush: drush rsync @self:%files @develop:%files It should show you something like: [drupal-example]cli-drupal:/app$ drush rsync @self:%files @develop:%files You will delete files in drupal-example-develop@ssh.lagoon.amazeeio.cloud:/app/web/sites/default/files and replace with data from /app/web/sites/default/files/ Do you really want to continue? (y/n): y In some cases, though, it might not look correct, like here: [drupal-example]cli-drupal:/app$ drush rsync @self:%files @develop:%files You will delete files in drupal-example-develop@ssh.lagoon.amazeeio.cloud:'/app/web/%files' and replace with data from '/app/web/%files'/ Do you really want to continue? (y/n): The reason for that is that the Drupal cannot resolve the path of the files directory. This most probably has to do that the Drupal is not fully configured or has a missing database. For a workaround you can use drush rsync @self:sites/default/files @develop:sites/default/files , but we suggest that you actually check your local and remote Drupal (you can test with drush status to see if the files directory is correctly configured). 6. It's done # As soon as Lagoon is done building and deploying it will send a second notification to the chat system, like so: This tells you: Which project has been deployed. Which branch and Git SHA has been deployed. A link to the full logs of the build and deployment. Links to all routes (URLs) where the environment can be reached. That's it! We hope that wasn't too hard - making devOps accessible is what we are striving for. But wait, how about other branches or the production environment? # That's the beauty of Lagoon: it's exactly the same: Push the branch name you defined to be your production branch and that one will be deployed. Failure? Don't worry. # Did the deployment fail? Oh no! But we're here to help: Click on the logs link in the error notification. It will tell you where in the deployment process the failure happened. If you can't figure it out, ask your Lagoon administrator, they are here to help!","title":"First Deployment of Drupal"},{"location":"drupal/first-deployment-of-drupal/#first-deployment-of-drupal","text":"","title":"First Deployment of Drupal"},{"location":"drupal/first-deployment-of-drupal/#1-make-sure-you-are-all-set","text":"In order to make your first deployment a successful one, please make sure that your Drupal Project is Lagoonized and you have set up the project in Lagoon. If not, don't worry! Follow the Step-by-Step Guide which show you how this works.","title":"1. Make sure you are all set"},{"location":"drupal/first-deployment-of-drupal/#2-push","text":"With Lagoon, you create a new deployment by pushing into a branch that is configured to be deployed. If you don't have any new code to push, don't worry, you can run git commit --allow-empty -m \"go, go! Power Rangers!\" git push This will trigger a push, and the Git hosting will inform Lagoon about this push via the configured webhook. If all is correct, you will see a notification in your configured chat system (this is configured by your friendly Lagoon administrator): This tells you that Lagoon has just started to deploy your code. Depending on the size of the codebase and amount of containers, this will take a couple of seconds. Just relax. If you'd like to know what's happening now, check out the Build and Deploy Process of Lagoon . You can also check your Lagoon UI to see the progress of any deployment (your Lagoon administrator has the info).","title":"2. Push"},{"location":"drupal/first-deployment-of-drupal/#3-a-fail","text":"Depending on the post-rollout tasks defined in .lagoon.yml , you might have run some tasks like drush updb or drush cr . These Drush tasks depend on a database existing within the environment, which obviously does not exist yet. Let's fix that! Keep reading.","title":"3. A fail"},{"location":"drupal/first-deployment-of-drupal/#4-synchronize-local-database-to-the-remote-lagoon-environment","text":"With full Drush site alias support in Lagoon, you can synchronize a local database with the remote Lagoon environment. Warning: You may have to tell pygmy about your public keys before the next step. If you get an error like Permission denied (publickey) , check out the documentation here: pygmy - adding ssh keys First let's make sure that you can see the Drush site aliases: drush sa This should return your just deployed environment (let's assume you just pushed into develop ): [ drupal-example ] cli-drupal:/app$ drush sa @develop @self default With this we can now synchronize the local database (which is represented in Drush via the site alias @self ) with the remote one ( @develop ): drush sql-sync @self @develop You should see something like: [drupal-example]cli-drupal:/app$ drush sql-sync @self @develop You will destroy data in ssh.lagoon.amazeeio.cloud/drupal and replace with data from drupal. Do you really want to continue? (y/n): y Starting to dump database on Source. [ok] Database dump saved to /home/drush-backups/drupal/20180227075813/drupal_20180227_075815.sql.gz [success] Starting to discover temporary files directory on Destination. [ok] You will delete files in drupal-example-develop@ssh.lagoon.amazeeio.cloud:/tmp/drupal_20180227_075815.sql.gz and replace with data from /home/drush-backups/drupal/20180227075813/drupal_20180227_075815.sql.gz Do you really want to continue? (y/n): y Copying dump file from Source to Destination. [ok] Starting to import dump file onto Destination database. Now let's try another deployment, again an empty push: git commit --allow-empty -m \"go, go! Power Rangers!\" git push This time all should be green: Click on the links in the notification, and you should see your Drupal site loaded in all its beauty! It will probably not have images yet, which we will handle in Step 6 . If it is still failing, check the logs link for more information.","title":"4. Synchronize local database to the remote Lagoon environment"},{"location":"drupal/first-deployment-of-drupal/#5-synchronize-local-files-to-the-remote-lagoon-environment","text":"You probably guessed it: we can do it with Drush: drush rsync @self:%files @develop:%files It should show you something like: [drupal-example]cli-drupal:/app$ drush rsync @self:%files @develop:%files You will delete files in drupal-example-develop@ssh.lagoon.amazeeio.cloud:/app/web/sites/default/files and replace with data from /app/web/sites/default/files/ Do you really want to continue? (y/n): y In some cases, though, it might not look correct, like here: [drupal-example]cli-drupal:/app$ drush rsync @self:%files @develop:%files You will delete files in drupal-example-develop@ssh.lagoon.amazeeio.cloud:'/app/web/%files' and replace with data from '/app/web/%files'/ Do you really want to continue? (y/n): The reason for that is that the Drupal cannot resolve the path of the files directory. This most probably has to do that the Drupal is not fully configured or has a missing database. For a workaround you can use drush rsync @self:sites/default/files @develop:sites/default/files , but we suggest that you actually check your local and remote Drupal (you can test with drush status to see if the files directory is correctly configured).","title":"5. Synchronize local files to the remote Lagoon environment"},{"location":"drupal/first-deployment-of-drupal/#6-its-done","text":"As soon as Lagoon is done building and deploying it will send a second notification to the chat system, like so: This tells you: Which project has been deployed. Which branch and Git SHA has been deployed. A link to the full logs of the build and deployment. Links to all routes (URLs) where the environment can be reached. That's it! We hope that wasn't too hard - making devOps accessible is what we are striving for.","title":"6. It's done"},{"location":"drupal/first-deployment-of-drupal/#but-wait-how-about-other-branches-or-the-production-environment","text":"That's the beauty of Lagoon: it's exactly the same: Push the branch name you defined to be your production branch and that one will be deployed.","title":"But wait, how about other branches or the production environment?"},{"location":"drupal/first-deployment-of-drupal/#failure-dont-worry","text":"Did the deployment fail? Oh no! But we're here to help: Click on the logs link in the error notification. It will tell you where in the deployment process the failure happened. If you can't figure it out, ask your Lagoon administrator, they are here to help!","title":"Failure? Don't worry."},{"location":"drupal/integrate-drupal-and-fastly/","text":"Integrate Drupal & Fastly # Prerequisites # A Drupal 7 , 8 or 9 site A Fastly service ID A Fastly API token with the permission to purge Drupal 8 or 9 with cache tag purging # Use Composer to get the latest version of the module: composer require drupal/fastly drupal/http_cache_control drupal/purge You will need to enable the following modules: fastly fastlypurger http_cache_control (2.x) purge purge_ui (technically optional, but this is really handy to have enabled on production) purge_processor_lateruntime purge_processor_cron purge_queuer_coretags purge_drush (useful for purge via Drush, here is a list of commands ) Configure the Fastly module in Drupal # Configure the Fastly service ID and API token. You can use runtime environment variables, or you can edit the settings form found at /admin/config/services/fastly : FASTLY_API_TOKEN FASTLY_API_SERVICE A site ID is required, the module will generate one for you when you first install it. The idea behind the site ID is that it is a unique string which is appended as a cache tag on all requests. Thus, you are able to purge a single site from Fastly, even though multiple sites may flow through the same service in Fastly. Set the purge options # Cache tag hash length: 4 Purge method: Use soft purge A 4 character cache tag is plenty for most sites, a 5 character cache tag is likely better for sites with millions of entities (to reduce cache tag collisions). Soft purging should be used, this means the item in Fastly is marked as stale, rather than being purged so that it can be used in the event the origin is down (with the feature 'serve while stale'). Set the Stale Content Options # Set the options to what makes sense for your site. Minimum 1 hour ( 3600 ), maximum 1 week 604800 ). Generally something like the following will be fine: Stale while revalidate - on, 14440 seconds Stale if error - on, 604800 seconds Optionally configure the webhooks (so you can ping Slack for instance when a cache purge is sent). Configure the Purge module # Visit the purge page /admin/config/development/performance/purge Set up the following options: Cache Invalidation Drupal Origin: Tag Fastly: E, Tag, URL Queue Queuers: Core tags queuer, Purge block(s) Queue: Database Processors: Core processor, Late runtime processor, Purge block(s) What this means is that we will be using Drupal's built in core tag queuer (add tags to the queue), the queue will be stored in the database (default), and the queue will be processed by Cron processor Late runtime processor In order for the cron processor to run, you need to ensure that cron is running on your site. Ideally every minute. You can manually run it in your cli pod, to ensure that purge_processor_cron_cron() is being executed without errors. [drupal8]production@cli-drupal:/app$ drush cron -v ... [notice] Starting execution of purge_processor_cron_cron(), execution of node_cron() took 21.16ms. The Late runtime processor will run in hook_exit() for every page load, this can be useful to process the purges nearly as quickly as they come into the queue. By having both, you guarantee that purges happen as soon as possible. Optimal Cache Header Setup # Out of the box, Drupal does not have the power to set different cache lifetimes in the browser vs in Fastly. So if you do set long cache lifetimes in Drupal, often end users will not see them if their browser has cached the page. If you install the 2.x version of the HTTP Cache Control module, this will give you a lot more flexibility on what caches and for how long. For most sites, a sensible default could be Shared cache maximum age : 1 month Browser cache maximum age : 10 minutes 404 cache maximum age: 15 minutes 302 cache maximum age: 1 hour 301 cache maximum age: 1 hour 5xx cache maximum age: no cache * Note : this relies on your site having accurate cache tags represented for all the content that exists on the page. Viewing caching headers using cURL # Use this function (works in Linux and Mac OSX) function curlf() { curl -sLIXGET -H 'Fastly-Debug:1' \"$@\" | grep -iE 'X-Cache|Cache-Control|Set-Cookie|X-Varnish|X-Hits|Vary|Fastly-Debug|X-Served|surrogate-control|surrogate-key' } $ curlf https://www.example-site-fastly.com cache-control: max-age=601, public, s-maxage=2764800 surrogate-control: max-age=2764800, public, stale-while-revalidate=3600, stale-if-error=3600 fastly-debug-path: (D cache-wlg10427-WLG 1612906144) (F cache-wlg10426-WLG 1612906141) (D cache-fra19179-FRA 1612906141) (F cache-fra19122-FRA 1612906141) fastly-debug-ttl: (H cache-wlg10427-WLG - - 3) (M cache-fra19179-FRA - - 0) fastly-debug-digest: 1118d9fefc8a514ca49d49cb6ece04649e1acf1663398212650bb462ba84c381 x-served-by: cache-fra19179-FRA, cache-wlg10427-WLG x-cache: MISS, HIT x-cache-hits: 0, 1 vary: Cookie, Accept-Encoding From the above headers we can see that: The HTML page is cacheable Browsers will cache the page for 601 seconds Fastly will cache the page for 32 days ( 2764800 seconds) Tiered caching is in effect (edge PoP in Wellington, and shield PoP in France) The HTML page was a cache hit at the edge PoP Sending manual purge requests to Fastly # If you ever want to remove a specific page from cache manually, there are ways to do this. For a single page, you do not need any authentication: curl -Ssi -XPURGE -H 'Fastly-Soft-Purge:1' https://www.example.com/subpage For cache tags, you need to supply your API token for authentication: curl -XPOST -H \"Fastly-Key:<Fastly API Key>\" https://api.fastly.com/service/<serviceID>/purge/<surrogatekey> You can always find what your site ID cache tag is by using PHP php > var_dump(substr(base64_encode(md5('bananasite', true)), 0, 4)); string(4) \"DTRk\" So you can purge your entire site from Fastly fairly easily. True client IPs # We configure Fastly to send the actual client IP back on the HTTP header True-Client-IP , you can make Drupal respect this header with the following changes in settings.php : $settings['reverse_proxy'] = TRUE; $settings['reverse_proxy_header'] = 'HTTP_TRUE_CLIENT_IP'; Drush integration # fastly: fastly:purge:all (fpall) Purge whole service. fastly:purge:key (fpkey) Purge cache by key. fastly:purge:url (fpurl) Purge cache by Url. Drupal 7 with URL based purging # Download and install the Fastly Drupal module . Configure the Fastly service ID and API token. Optionally configure the webhooks (so you can ping Slack for instance when a cache purge is sent) Only URL based purging can be done in Drupal 7 (simple purging). Alter Drupal's client IP in settings.php : $conf['reverse_proxy_header'] = 'HTTP_TRUE_CLIENT_IP';","title":"Integrate Drupal & Fastly"},{"location":"drupal/integrate-drupal-and-fastly/#integrate-drupal-fastly","text":"","title":"Integrate Drupal &amp; Fastly"},{"location":"drupal/integrate-drupal-and-fastly/#prerequisites","text":"A Drupal 7 , 8 or 9 site A Fastly service ID A Fastly API token with the permission to purge","title":"Prerequisites"},{"location":"drupal/integrate-drupal-and-fastly/#drupal-8-or-9-with-cache-tag-purging","text":"Use Composer to get the latest version of the module: composer require drupal/fastly drupal/http_cache_control drupal/purge You will need to enable the following modules: fastly fastlypurger http_cache_control (2.x) purge purge_ui (technically optional, but this is really handy to have enabled on production) purge_processor_lateruntime purge_processor_cron purge_queuer_coretags purge_drush (useful for purge via Drush, here is a list of commands )","title":"Drupal 8 or 9 with cache tag purging"},{"location":"drupal/integrate-drupal-and-fastly/#configure-the-fastly-module-in-drupal","text":"Configure the Fastly service ID and API token. You can use runtime environment variables, or you can edit the settings form found at /admin/config/services/fastly : FASTLY_API_TOKEN FASTLY_API_SERVICE A site ID is required, the module will generate one for you when you first install it. The idea behind the site ID is that it is a unique string which is appended as a cache tag on all requests. Thus, you are able to purge a single site from Fastly, even though multiple sites may flow through the same service in Fastly.","title":"Configure the Fastly module in Drupal"},{"location":"drupal/integrate-drupal-and-fastly/#set-the-purge-options","text":"Cache tag hash length: 4 Purge method: Use soft purge A 4 character cache tag is plenty for most sites, a 5 character cache tag is likely better for sites with millions of entities (to reduce cache tag collisions). Soft purging should be used, this means the item in Fastly is marked as stale, rather than being purged so that it can be used in the event the origin is down (with the feature 'serve while stale').","title":"Set the purge options"},{"location":"drupal/integrate-drupal-and-fastly/#set-the-stale-content-options","text":"Set the options to what makes sense for your site. Minimum 1 hour ( 3600 ), maximum 1 week 604800 ). Generally something like the following will be fine: Stale while revalidate - on, 14440 seconds Stale if error - on, 604800 seconds Optionally configure the webhooks (so you can ping Slack for instance when a cache purge is sent).","title":"Set the Stale Content Options"},{"location":"drupal/integrate-drupal-and-fastly/#configure-the-purge-module","text":"Visit the purge page /admin/config/development/performance/purge Set up the following options: Cache Invalidation Drupal Origin: Tag Fastly: E, Tag, URL Queue Queuers: Core tags queuer, Purge block(s) Queue: Database Processors: Core processor, Late runtime processor, Purge block(s) What this means is that we will be using Drupal's built in core tag queuer (add tags to the queue), the queue will be stored in the database (default), and the queue will be processed by Cron processor Late runtime processor In order for the cron processor to run, you need to ensure that cron is running on your site. Ideally every minute. You can manually run it in your cli pod, to ensure that purge_processor_cron_cron() is being executed without errors. [drupal8]production@cli-drupal:/app$ drush cron -v ... [notice] Starting execution of purge_processor_cron_cron(), execution of node_cron() took 21.16ms. The Late runtime processor will run in hook_exit() for every page load, this can be useful to process the purges nearly as quickly as they come into the queue. By having both, you guarantee that purges happen as soon as possible.","title":"Configure the Purge module"},{"location":"drupal/integrate-drupal-and-fastly/#optimal-cache-header-setup","text":"Out of the box, Drupal does not have the power to set different cache lifetimes in the browser vs in Fastly. So if you do set long cache lifetimes in Drupal, often end users will not see them if their browser has cached the page. If you install the 2.x version of the HTTP Cache Control module, this will give you a lot more flexibility on what caches and for how long. For most sites, a sensible default could be Shared cache maximum age : 1 month Browser cache maximum age : 10 minutes 404 cache maximum age: 15 minutes 302 cache maximum age: 1 hour 301 cache maximum age: 1 hour 5xx cache maximum age: no cache * Note : this relies on your site having accurate cache tags represented for all the content that exists on the page.","title":"Optimal Cache Header Setup"},{"location":"drupal/integrate-drupal-and-fastly/#viewing-caching-headers-using-curl","text":"Use this function (works in Linux and Mac OSX) function curlf() { curl -sLIXGET -H 'Fastly-Debug:1' \"$@\" | grep -iE 'X-Cache|Cache-Control|Set-Cookie|X-Varnish|X-Hits|Vary|Fastly-Debug|X-Served|surrogate-control|surrogate-key' } $ curlf https://www.example-site-fastly.com cache-control: max-age=601, public, s-maxage=2764800 surrogate-control: max-age=2764800, public, stale-while-revalidate=3600, stale-if-error=3600 fastly-debug-path: (D cache-wlg10427-WLG 1612906144) (F cache-wlg10426-WLG 1612906141) (D cache-fra19179-FRA 1612906141) (F cache-fra19122-FRA 1612906141) fastly-debug-ttl: (H cache-wlg10427-WLG - - 3) (M cache-fra19179-FRA - - 0) fastly-debug-digest: 1118d9fefc8a514ca49d49cb6ece04649e1acf1663398212650bb462ba84c381 x-served-by: cache-fra19179-FRA, cache-wlg10427-WLG x-cache: MISS, HIT x-cache-hits: 0, 1 vary: Cookie, Accept-Encoding From the above headers we can see that: The HTML page is cacheable Browsers will cache the page for 601 seconds Fastly will cache the page for 32 days ( 2764800 seconds) Tiered caching is in effect (edge PoP in Wellington, and shield PoP in France) The HTML page was a cache hit at the edge PoP","title":"Viewing caching headers using cURL"},{"location":"drupal/integrate-drupal-and-fastly/#sending-manual-purge-requests-to-fastly","text":"If you ever want to remove a specific page from cache manually, there are ways to do this. For a single page, you do not need any authentication: curl -Ssi -XPURGE -H 'Fastly-Soft-Purge:1' https://www.example.com/subpage For cache tags, you need to supply your API token for authentication: curl -XPOST -H \"Fastly-Key:<Fastly API Key>\" https://api.fastly.com/service/<serviceID>/purge/<surrogatekey> You can always find what your site ID cache tag is by using PHP php > var_dump(substr(base64_encode(md5('bananasite', true)), 0, 4)); string(4) \"DTRk\" So you can purge your entire site from Fastly fairly easily.","title":"Sending manual purge requests to Fastly"},{"location":"drupal/integrate-drupal-and-fastly/#true-client-ips","text":"We configure Fastly to send the actual client IP back on the HTTP header True-Client-IP , you can make Drupal respect this header with the following changes in settings.php : $settings['reverse_proxy'] = TRUE; $settings['reverse_proxy_header'] = 'HTTP_TRUE_CLIENT_IP';","title":"True client IPs"},{"location":"drupal/integrate-drupal-and-fastly/#drush-integration","text":"fastly: fastly:purge:all (fpall) Purge whole service. fastly:purge:key (fpkey) Purge cache by key. fastly:purge:url (fpurl) Purge cache by Url.","title":"Drush integration"},{"location":"drupal/integrate-drupal-and-fastly/#drupal-7-with-url-based-purging","text":"Download and install the Fastly Drupal module . Configure the Fastly service ID and API token. Optionally configure the webhooks (so you can ping Slack for instance when a cache purge is sent) Only URL based purging can be done in Drupal 7 (simple purging). Alter Drupal's client IP in settings.php : $conf['reverse_proxy_header'] = 'HTTP_TRUE_CLIENT_IP';","title":"Drupal 7 with URL based purging"},{"location":"drupal/phpunit-and-phpstorm/","text":"PHPUnit and PhpStorm # Note: This document assumes the following: You are using Docker. You are using a standard Amazee/Lagoon project with a docker-compose.yml file. You are on a Mac - it should work for other operating systems but folder structure and some configuration settings may be different. Configuring the project # Duplicate* the /core/phpunit.xml.dist file to /core/phpunit.xml Edit* /core/phpunit.xml and fill in the following variables: SIMPLETEST_DB : mysql://drupal:drupal@mariadb:3306/drupal#db SIMPLETEST_BASE_URL : <PROJECT_URL> Configuring PhpStorm # Set Up Docker # In PhpStorm, go to File > Settings > Build, Execution, Deployment > Docker Click: + Select*: Docker for Mac Set Up CLI interpreter # Add a new CLI interpreter: In PhpStorm, go to File > Settings > Languages & Frameworks > PHP Click ... and then + Next select: Add a new CLI interpreter from Docker, vagrant... Use the following configurations: Server: <DOCKER> Configuration file(s): ./docker-compose.yml Service: cli Lifecycle: Connect to existing container ('docker-compose exec') Path mappings: Local path: <ROOT_PATH> Remote path*: /app Set Up Remote Interpreter # Add Remote Interpreter: In PhpStorm, go to File > Settings > Languages & Frameworks > PHP > Test Frameworks Click + and select PHPUnit by Remote Interpreter Use the following configurations: CLI Interpreter: <CLI_INTERPRETER> Path mappings*: <PROJECT_ROOT> -> /app PHPUnit: Use Composer autoloader Path to script*: /app/vendor/autoload.php Default configuration file*: /app/web/core/phpunit.xml Setup/Configure Runner Template # Configure runner: In PhpStorm, go to Run > Edit Configurations... > Templates > PHPUnit Use the following configurations: Test scope: Defined in the configuration file Interpreter: <CLI_INTERPRETER> * If you are not on a Mac, this may vary. Final checks # Some final checks to run before you run a test! You have the project up and running: $ docker-compose up -d The project is working without any errors, visit the site just to make sure it all works as expected - this is not 100% necessary, but nice to know it is working normally. We should be ready to run some tests! Ready to Run # Now you have the above configuration set up it should be as straightforward as going to the test you want to run and pressing the green arrow! Once you press this PhpStorm will use docker to enter the cli container than start running PHPUnit based upon the config, exciting right?","title":"PHPUnit and PhpStorm"},{"location":"drupal/phpunit-and-phpstorm/#phpunit-and-phpstorm","text":"Note: This document assumes the following: You are using Docker. You are using a standard Amazee/Lagoon project with a docker-compose.yml file. You are on a Mac - it should work for other operating systems but folder structure and some configuration settings may be different.","title":"PHPUnit and PhpStorm"},{"location":"drupal/phpunit-and-phpstorm/#configuring-the-project","text":"Duplicate* the /core/phpunit.xml.dist file to /core/phpunit.xml Edit* /core/phpunit.xml and fill in the following variables: SIMPLETEST_DB : mysql://drupal:drupal@mariadb:3306/drupal#db SIMPLETEST_BASE_URL : <PROJECT_URL>","title":"Configuring the project"},{"location":"drupal/phpunit-and-phpstorm/#configuring-phpstorm","text":"","title":"Configuring PhpStorm"},{"location":"drupal/phpunit-and-phpstorm/#set-up-docker","text":"In PhpStorm, go to File > Settings > Build, Execution, Deployment > Docker Click: + Select*: Docker for Mac","title":"Set Up Docker"},{"location":"drupal/phpunit-and-phpstorm/#set-up-cli-interpreter","text":"Add a new CLI interpreter: In PhpStorm, go to File > Settings > Languages & Frameworks > PHP Click ... and then + Next select: Add a new CLI interpreter from Docker, vagrant... Use the following configurations: Server: <DOCKER> Configuration file(s): ./docker-compose.yml Service: cli Lifecycle: Connect to existing container ('docker-compose exec') Path mappings: Local path: <ROOT_PATH> Remote path*: /app","title":"Set Up CLI interpreter"},{"location":"drupal/phpunit-and-phpstorm/#set-up-remote-interpreter","text":"Add Remote Interpreter: In PhpStorm, go to File > Settings > Languages & Frameworks > PHP > Test Frameworks Click + and select PHPUnit by Remote Interpreter Use the following configurations: CLI Interpreter: <CLI_INTERPRETER> Path mappings*: <PROJECT_ROOT> -> /app PHPUnit: Use Composer autoloader Path to script*: /app/vendor/autoload.php Default configuration file*: /app/web/core/phpunit.xml","title":"Set Up Remote Interpreter"},{"location":"drupal/phpunit-and-phpstorm/#setupconfigure-runner-template","text":"Configure runner: In PhpStorm, go to Run > Edit Configurations... > Templates > PHPUnit Use the following configurations: Test scope: Defined in the configuration file Interpreter: <CLI_INTERPRETER> * If you are not on a Mac, this may vary.","title":"Setup/Configure Runner Template "},{"location":"drupal/phpunit-and-phpstorm/#final-checks","text":"Some final checks to run before you run a test! You have the project up and running: $ docker-compose up -d The project is working without any errors, visit the site just to make sure it all works as expected - this is not 100% necessary, but nice to know it is working normally. We should be ready to run some tests!","title":"Final checks"},{"location":"drupal/phpunit-and-phpstorm/#ready-to-run","text":"Now you have the above configuration set up it should be as straightforward as going to the test you want to run and pressing the green arrow! Once you press this PhpStorm will use docker to enter the cli container than start running PHPUnit based upon the config, exciting right?","title":"Ready to Run"},{"location":"drupal/step-by-step-getting-drupal-ready-to-run-on-lagoon/","text":"Step by Step: Getting Drupal ready to run on Lagoon # 1. Lagoon Drupal Setting Files # In order for Drupal to work with Lagoon, we need to teach Drupal about Lagoon and Lagoon about Drupal. This happens by copying specific YAML and PHP files into your Git repository. If you're working on a Drupal project, you can check out one of the various Drupal example projects in our examples repository . We have Drupal 8 and 9 and some variants of each depending on your needs, such as database types. Clone the repo that best suits your needs to get started! Here is a summary of the Lagoon- and Drupal-specific files you will find: .lagoon.yml - The main file that will be used by Lagoon to understand what should be deployed and many more things. This file has some sensible Drupal defaults. If you would like to edit or modify, please check the documentation for .lagoon.yml . docker-compose.yml , .dockerignore , and *.dockerfile (or Dockerfile ) - These files are used to run your local Drupal development environment, they tell Docker which services to start and how to build them. They contain sensible defaults and many commented lines. We hope that it's well-commented enough to be self-describing. If you would like to find out more, see documentation for docker-compose.yml . sites/default/* - These .php and .yml files tell Drupal how to communicate with Lagoon containers both locally and in production. They also provide a straightforward system for specific overrides in development and production environments. Unlike other Drupal hosting systems, Lagoon never ever injects Drupal settings files into your Drupal. Therefore, you can edit them however you like. Like all other files, they contain sensible defaults and some commented parts. drush/aliases.drushrc.php - These files are specific to Drush and tell Drush how to talk to the Lagoon GraphQL API in order to learn about all site aliases there are. drush/drushrc.php - Some sensible defaults for Drush commands. Update your .gitignore Settings # Don't forget to make sure your .gitignore will allow you to commit the settings files. Drupal is shipped with sites/*/settings*.php and sites/*/services*.yml in .gitignore . Remove that, as with Lagoon we don't ever have sensitive information in the Git repository. Note about WEBROOT in Drupal 8 # Unfortunately the Drupal community has not decided on a standardized WEBROOT folder name. Some projects put Drupal within web , and others within docroot or somewhere else. The Lagoon Drupal settings files assume that your Drupal is within web , but if this is different for your Drupal, please adapt the files accordingly. Note about composer.json # If you installed Drupal via composer, please check your composer.json and make sure that the name is NOT drupal/drupal , as this could confuse Drush and other tools of the Drupal universe, just rename it to something like myproject/drupal 2. Customise docker-compose.yml # Don't forget to customize the values in lagoon-project & LAGOON_ROUTE with your site-specific name & the URL you'd like to access the site with. Here's an example: docker-compose.yml x-environment : &default-environment LAGOON_PROJECT : *lagoon-project # Route that should be used locally. If you are using pygmy, this route *must* end with .docker.amazee.io. LAGOON_ROUTE : http://drupal-example.docker.amazee.io 3. Build Images # First, we need to build the defined images: docker-compose build This will tell docker-compose to build the Docker images for all containers that have a build: definition in the docker-compose.yml . Usually for Drupal this is the case for the cli , nginx and php images. We do this because we want to run specific build commands (like composer install ) or inject specific environment variables (like WEBROOT ) into the images. Usually, building is not necessary every time you edit your Drupal code (as the code is mounted into the containers from your host), but rebuilding does not hurt. Plus, Lagoon will build the exact same Docker images during a deploy, so you can check that your build will also work during a deployment by just running docker-compose build again. 4. Start Containers # Now that the images are built, we can start the containers: docker-compose up -d This will bring up all containers. After the command is done, you can check with docker-compose ps to ensure that they are all fully up and have not crashed. If there is a problem, check the logs with docker-compose logs -f [servicename] . 5. Rerun composer install (for Composer projects only) # In a local development environment, you probably want all dependencies downloaded and installed, so connect to the cli container and run composer install : docker-compose exec cli bash composer install This might sound weird, as there was already a composer install executed during the build step, so let us explain: In order to be able to edit files on the host and have them immediately available in the container, the default docker-composer.yml mounts the whole folder into the the containers (this happens with .:/app:delegated in the volumes section). This also means that all dependencies installed during the Docker build are overwritten with the files on the host. Locally, you probably want dependencies defined as require-dev in composer.json to exist as well, while on a production deployment they would just use unnecessary space. So we run composer install --no-dev in the Dockerfile and composer install manually. If everything went well, open the LAGOON_ROUTE defined in docker-compose.yml (for example http://drupal.docker.amazee.io ) and you should be greeted by a nice Drupal error. Don't worry - that's ok right now, most important is that it tries to load a Drupal site. If you get a 500 or similar error, make sure everything loaded properly with Composer. 6. Check Status and Install Drupal # Finally it's time to install Drupal, but just before that we want to make sure everything works. We suggest using Drush for that: docker-compose exec cli bash drush status This should return something like: [ drupal-example ] cli-drupal:/app$ drush status [ notice ] Missing database table: key_value Drupal version : 8 .6.1 Site URI : http://drupal.docker.amazee.io Database driver : mysql Database hostname : mariadb Database port : 3306 Database username : drupal Database name : drupal PHP binary : /usr/local/bin/php PHP config : /usr/local/etc/php/php.ini PHP OS : Linux Drush script : /app/vendor/drush/drush/drush Drush version : 9 .4.0 Drush temp : /tmp Drush configs : /home/.drush/drush.yml /app/vendor/drush/drush/drush.yml Drupal root : /app/web Site path : sites/default Warning: You may have to tell pygmy about your public key before the next step. If you get an error like Permission denied (publickey) , check out the documentation here: pygmy - adding ssh keys Now it is time to install Drupal (if instead you would like to import an existing SQL file, please skip to step 7 , but we suggest you start with a clean Drupal installation in the beginning to be sure everything works). drush site-install This should output something like: [ drupal-example ] cli-drupal:/app$ drush site-install You are about to DROP all tables in your 'drupal' database. Do you want to continue ? ( y/n ) : y Starting Drupal installation. This takes a while . Consider using the --notify global option. Installation complete. User name: admin User password: a7kZJekcqh Congratulations, you installed Drupal! Now you can visit the URL defined in LAGOON_ROUTE and you should see a fresh and clean installed Drupal site - Congrats! 7. Import existing Database Dump # If you already have an existing Drupal site, you probably want to import its database over to your local site. There are many different ways to create a database dump. If your current hosting provider has Drush installed, you can use the following: drush sql-dump --result-file = dump.sql Database dump saved to dump.sql Now you have a dump.sql file that contains your whole database. Copy this file into your Git repository and connect to the cli , and you should see the file in there: [ drupal-example ] cli-drupal:/app$ ls -l dump.sql -rw-r--r-- 1 root root 5281 Dec 19 12 :46 dump.sql Now you can drop the current database, and then import the dump. drush sql-drop drush sql-cli < dump.sql Verify that everything works with visiting the URL of your project. You should have a functional copy of your Drupal site! 8. Drupal files directory # A Drupal site also needs the files directory. As the whole folder is mounted into the Docker containers, add the files into the correct folder (probably web/sites/default/files , sites/default/files or something similar). Remember what you've set as your WEBROOT - it may not be the same for all projects . 9. Done # You are done with your local setup. The Lagoon team wishes happy Drupaling!","title":"Step by Step - Getting Drupal ready to run on Lagoon"},{"location":"drupal/step-by-step-getting-drupal-ready-to-run-on-lagoon/#step-by-step-getting-drupal-ready-to-run-on-lagoon","text":"","title":"Step by Step: Getting Drupal ready to run on Lagoon"},{"location":"drupal/step-by-step-getting-drupal-ready-to-run-on-lagoon/#1-lagoon-drupal-setting-files","text":"In order for Drupal to work with Lagoon, we need to teach Drupal about Lagoon and Lagoon about Drupal. This happens by copying specific YAML and PHP files into your Git repository. If you're working on a Drupal project, you can check out one of the various Drupal example projects in our examples repository . We have Drupal 8 and 9 and some variants of each depending on your needs, such as database types. Clone the repo that best suits your needs to get started! Here is a summary of the Lagoon- and Drupal-specific files you will find: .lagoon.yml - The main file that will be used by Lagoon to understand what should be deployed and many more things. This file has some sensible Drupal defaults. If you would like to edit or modify, please check the documentation for .lagoon.yml . docker-compose.yml , .dockerignore , and *.dockerfile (or Dockerfile ) - These files are used to run your local Drupal development environment, they tell Docker which services to start and how to build them. They contain sensible defaults and many commented lines. We hope that it's well-commented enough to be self-describing. If you would like to find out more, see documentation for docker-compose.yml . sites/default/* - These .php and .yml files tell Drupal how to communicate with Lagoon containers both locally and in production. They also provide a straightforward system for specific overrides in development and production environments. Unlike other Drupal hosting systems, Lagoon never ever injects Drupal settings files into your Drupal. Therefore, you can edit them however you like. Like all other files, they contain sensible defaults and some commented parts. drush/aliases.drushrc.php - These files are specific to Drush and tell Drush how to talk to the Lagoon GraphQL API in order to learn about all site aliases there are. drush/drushrc.php - Some sensible defaults for Drush commands.","title":"1. Lagoon Drupal Setting Files"},{"location":"drupal/step-by-step-getting-drupal-ready-to-run-on-lagoon/#update-your-gitignore-settings","text":"Don't forget to make sure your .gitignore will allow you to commit the settings files. Drupal is shipped with sites/*/settings*.php and sites/*/services*.yml in .gitignore . Remove that, as with Lagoon we don't ever have sensitive information in the Git repository.","title":"Update your .gitignore Settings"},{"location":"drupal/step-by-step-getting-drupal-ready-to-run-on-lagoon/#note-about-webroot-in-drupal-8","text":"Unfortunately the Drupal community has not decided on a standardized WEBROOT folder name. Some projects put Drupal within web , and others within docroot or somewhere else. The Lagoon Drupal settings files assume that your Drupal is within web , but if this is different for your Drupal, please adapt the files accordingly.","title":"Note about WEBROOT in Drupal 8"},{"location":"drupal/step-by-step-getting-drupal-ready-to-run-on-lagoon/#note-about-composerjson","text":"If you installed Drupal via composer, please check your composer.json and make sure that the name is NOT drupal/drupal , as this could confuse Drush and other tools of the Drupal universe, just rename it to something like myproject/drupal","title":"Note about composer.json"},{"location":"drupal/step-by-step-getting-drupal-ready-to-run-on-lagoon/#2-customise-docker-composeyml","text":"Don't forget to customize the values in lagoon-project & LAGOON_ROUTE with your site-specific name & the URL you'd like to access the site with. Here's an example: docker-compose.yml x-environment : &default-environment LAGOON_PROJECT : *lagoon-project # Route that should be used locally. If you are using pygmy, this route *must* end with .docker.amazee.io. LAGOON_ROUTE : http://drupal-example.docker.amazee.io","title":"2. Customise docker-compose.yml"},{"location":"drupal/step-by-step-getting-drupal-ready-to-run-on-lagoon/#3-build-images","text":"First, we need to build the defined images: docker-compose build This will tell docker-compose to build the Docker images for all containers that have a build: definition in the docker-compose.yml . Usually for Drupal this is the case for the cli , nginx and php images. We do this because we want to run specific build commands (like composer install ) or inject specific environment variables (like WEBROOT ) into the images. Usually, building is not necessary every time you edit your Drupal code (as the code is mounted into the containers from your host), but rebuilding does not hurt. Plus, Lagoon will build the exact same Docker images during a deploy, so you can check that your build will also work during a deployment by just running docker-compose build again.","title":"3. Build Images"},{"location":"drupal/step-by-step-getting-drupal-ready-to-run-on-lagoon/#4-start-containers","text":"Now that the images are built, we can start the containers: docker-compose up -d This will bring up all containers. After the command is done, you can check with docker-compose ps to ensure that they are all fully up and have not crashed. If there is a problem, check the logs with docker-compose logs -f [servicename] .","title":"4. Start Containers"},{"location":"drupal/step-by-step-getting-drupal-ready-to-run-on-lagoon/#5-rerun-composer-install-for-composer-projects-only","text":"In a local development environment, you probably want all dependencies downloaded and installed, so connect to the cli container and run composer install : docker-compose exec cli bash composer install This might sound weird, as there was already a composer install executed during the build step, so let us explain: In order to be able to edit files on the host and have them immediately available in the container, the default docker-composer.yml mounts the whole folder into the the containers (this happens with .:/app:delegated in the volumes section). This also means that all dependencies installed during the Docker build are overwritten with the files on the host. Locally, you probably want dependencies defined as require-dev in composer.json to exist as well, while on a production deployment they would just use unnecessary space. So we run composer install --no-dev in the Dockerfile and composer install manually. If everything went well, open the LAGOON_ROUTE defined in docker-compose.yml (for example http://drupal.docker.amazee.io ) and you should be greeted by a nice Drupal error. Don't worry - that's ok right now, most important is that it tries to load a Drupal site. If you get a 500 or similar error, make sure everything loaded properly with Composer.","title":"5. Rerun composer install (for Composer projects only)"},{"location":"drupal/step-by-step-getting-drupal-ready-to-run-on-lagoon/#6-check-status-and-install-drupal","text":"Finally it's time to install Drupal, but just before that we want to make sure everything works. We suggest using Drush for that: docker-compose exec cli bash drush status This should return something like: [ drupal-example ] cli-drupal:/app$ drush status [ notice ] Missing database table: key_value Drupal version : 8 .6.1 Site URI : http://drupal.docker.amazee.io Database driver : mysql Database hostname : mariadb Database port : 3306 Database username : drupal Database name : drupal PHP binary : /usr/local/bin/php PHP config : /usr/local/etc/php/php.ini PHP OS : Linux Drush script : /app/vendor/drush/drush/drush Drush version : 9 .4.0 Drush temp : /tmp Drush configs : /home/.drush/drush.yml /app/vendor/drush/drush/drush.yml Drupal root : /app/web Site path : sites/default Warning: You may have to tell pygmy about your public key before the next step. If you get an error like Permission denied (publickey) , check out the documentation here: pygmy - adding ssh keys Now it is time to install Drupal (if instead you would like to import an existing SQL file, please skip to step 7 , but we suggest you start with a clean Drupal installation in the beginning to be sure everything works). drush site-install This should output something like: [ drupal-example ] cli-drupal:/app$ drush site-install You are about to DROP all tables in your 'drupal' database. Do you want to continue ? ( y/n ) : y Starting Drupal installation. This takes a while . Consider using the --notify global option. Installation complete. User name: admin User password: a7kZJekcqh Congratulations, you installed Drupal! Now you can visit the URL defined in LAGOON_ROUTE and you should see a fresh and clean installed Drupal site - Congrats!","title":"6. Check Status and Install Drupal"},{"location":"drupal/step-by-step-getting-drupal-ready-to-run-on-lagoon/#7-import-existing-database-dump","text":"If you already have an existing Drupal site, you probably want to import its database over to your local site. There are many different ways to create a database dump. If your current hosting provider has Drush installed, you can use the following: drush sql-dump --result-file = dump.sql Database dump saved to dump.sql Now you have a dump.sql file that contains your whole database. Copy this file into your Git repository and connect to the cli , and you should see the file in there: [ drupal-example ] cli-drupal:/app$ ls -l dump.sql -rw-r--r-- 1 root root 5281 Dec 19 12 :46 dump.sql Now you can drop the current database, and then import the dump. drush sql-drop drush sql-cli < dump.sql Verify that everything works with visiting the URL of your project. You should have a functional copy of your Drupal site!","title":"7. Import existing Database Dump"},{"location":"drupal/step-by-step-getting-drupal-ready-to-run-on-lagoon/#8-drupal-files-directory","text":"A Drupal site also needs the files directory. As the whole folder is mounted into the Docker containers, add the files into the correct folder (probably web/sites/default/files , sites/default/files or something similar). Remember what you've set as your WEBROOT - it may not be the same for all projects .","title":"8. Drupal files directory"},{"location":"drupal/step-by-step-getting-drupal-ready-to-run-on-lagoon/#9-done","text":"You are done with your local setup. The Lagoon team wishes happy Drupaling!","title":"9. Done"},{"location":"drupal/subfolders/","text":"Subfolders # An example could be: www.example.com points to one Drupal site, while www.example.com/blog loads a blog built in another Drupal. It would be possible to run both Drupals in a single Git repository and deploy it as a whole, but this workflow might not fit every team, and having separate Git repositories fits some situations better. Modifications of root application # The root application (in this example, the Drupal site for www.example.com ), needs a couple of Nginx configs that will configure NGINX to be a reverse proxy to the subfolder applications: location_prepend.conf # Create a file called location_prepend.conf in the root of your Drupal installation: location_prepend.conf resolver 8.8.8.8 valid=30s; location ~ ^/subfolder { # If $http_x_forwarded_proto is empty (If it is not set from an upstream reverseproxy). # Aet it to the current scheme. set_if_empty $http_x_forwarded_proto $scheme; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-Proto $http_x_forwarded_proto; proxy_set_header X-Lagoon-Forwarded-Host $host; # Will be used by downstream to know the original host. proxy_set_header X-REVERSEPROXY $hostname; proxy_set_header FORWARDED \"\"; # Unset FORWARDED because drupal8 gives errors if it is set. proxy_set_header Proxy \"\"; # Unset Proxy because drupal8 gives errors if it is set. proxy_ssl_server_name on; # Nginx needs a variable set in order for the DNS resolution to work correctly. set $subfolder_drupal_host \"https://nginx-lagoonproject-${LAGOON_GIT_SAFE_BRANCH}.clustername.com:443\"; # LAGOON_GIT_SAFE_BRANCH variable will be replaced during docker entrypoint. proxy_pass $subfolder_drupal_host; proxy_set_header Host $proxy_host; # $proxy_host will be automatically generated by Nginx based on proxy_pass (it needs to be without scheme and port). expires off; # make sure we honor cache headers from the proxy and not overwrite them Replace the following strings: /subfolder with the name of the subfolder you want to use. For example, /blog . nginx with the service that you want to point too in the subfolder project. lagoonproject with the Lagoon projectname of the subfolder project. NGINX Dockerfile # Add the following to your NGINX Dockerfile ( nginx.dockerfile or Dockerfile.nginx ): nginx.dockerfile COPY location_prepend.conf /etc/nginx/conf.d/drupal/location_prepend.conf RUN fix-permissions /etc/nginx/conf.d/drupal/* Modifications of subfolder application # Like the root application, we also need to teach the subfolder application (in this example, the Drupal installation for www.example.com/blog ), that it is running under a subfolder. To do this, we create two files: location_drupal_append_subfolder.conf # Create a file called location_drupal_append_subfolder.conf in the root of your subfolder Drupal installation: location_drupal_append_subfolder.conf # When injecting a script name that is prefixed with `subfolder`, Drupal will # render all URLs with `subfolder` prefixed fastcgi_param SCRIPT_NAME /subfolder/index.php; # If we are running via a reverse proxy, we inject the original HOST URL # into PHP. With this Drupal will render all URLs with the original HOST URL, # and not the current used HOST. # We first set the HOST to the regular host variable. fastcgi_param HTTP_HOST $http_host; # Then we overwrite it with `X-Lagoon-Forwarded-Host` if it exists. fastcgi_param HTTP_HOST $http_x_lagoon_forwarded_host if_not_empty; Replace /subfolder with the name of the subfolder you want to use. For example, /blog . server_prepend_subfolder.conf # Create a file called server_prepend_subfolder.conf in the root of your subfolder Drupal installation: server_prepend_subfolder.conf # Check for redirects before we do the internal Nginx rewrites. # This is done because the internal Nginx rewrites uses `last`, # which instructs Nginx to not check for rewrites anymore (and # `if` is part of the redirect module). include /etc/nginx/helpers/010_redirects.conf; # This is an internal Nginx rewrite, it removes `/subfolder/` # from the requests so that Nginx handles the request as it would # have been `/` from the beginning. # The `last` flag is also important. It will cause Nginx not to # execute any more rewrites, because it would redirect forever # with the rewrites below. rewrite ^/subfolder/(.*) /$1 last; # Make sure redirects are NOT absolute, to ensure Nginx does not # overwrite the host of the URL - which could be something other than # what Nginx currently thinks it is serving. absolute_redirect off; # If a request just has `/subfolder` we 301 redirect to `/subfolder/` # (Drupal really likes a trailing slash) rewrite ^/subfolder /subfolder/ permanent; # Any other request we prefix 301 redirect with `/subfolder/` rewrite ^\\/(.*) /subfolder/$1 permanent; Replace /subfolder with the name of the subfolder you want to use. For example, /blog . Nginx Dockerfile # We also need to modify the NGINX Dockerfile. Add the following to your NGINX Dockerfile ( nginx.dockerfile or Dockerfile.nginx ): nginx.dockerfile COPY location_drupal_append_subfolder.conf /etc/nginx/conf.d/drupal/location_drupal_append_subfolder.conf COPY server_prepend_subfolder.conf /etc/nginx/conf.d/drupal/server_prepend_subfolder.conf RUN fix-permissions /etc/nginx/conf.d/drupal/*","title":"Subfolders"},{"location":"drupal/subfolders/#subfolders","text":"An example could be: www.example.com points to one Drupal site, while www.example.com/blog loads a blog built in another Drupal. It would be possible to run both Drupals in a single Git repository and deploy it as a whole, but this workflow might not fit every team, and having separate Git repositories fits some situations better.","title":"Subfolders"},{"location":"drupal/subfolders/#modifications-of-root-application","text":"The root application (in this example, the Drupal site for www.example.com ), needs a couple of Nginx configs that will configure NGINX to be a reverse proxy to the subfolder applications:","title":"Modifications of root application"},{"location":"drupal/subfolders/#location_prependconf","text":"Create a file called location_prepend.conf in the root of your Drupal installation: location_prepend.conf resolver 8.8.8.8 valid=30s; location ~ ^/subfolder { # If $http_x_forwarded_proto is empty (If it is not set from an upstream reverseproxy). # Aet it to the current scheme. set_if_empty $http_x_forwarded_proto $scheme; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-Proto $http_x_forwarded_proto; proxy_set_header X-Lagoon-Forwarded-Host $host; # Will be used by downstream to know the original host. proxy_set_header X-REVERSEPROXY $hostname; proxy_set_header FORWARDED \"\"; # Unset FORWARDED because drupal8 gives errors if it is set. proxy_set_header Proxy \"\"; # Unset Proxy because drupal8 gives errors if it is set. proxy_ssl_server_name on; # Nginx needs a variable set in order for the DNS resolution to work correctly. set $subfolder_drupal_host \"https://nginx-lagoonproject-${LAGOON_GIT_SAFE_BRANCH}.clustername.com:443\"; # LAGOON_GIT_SAFE_BRANCH variable will be replaced during docker entrypoint. proxy_pass $subfolder_drupal_host; proxy_set_header Host $proxy_host; # $proxy_host will be automatically generated by Nginx based on proxy_pass (it needs to be without scheme and port). expires off; # make sure we honor cache headers from the proxy and not overwrite them Replace the following strings: /subfolder with the name of the subfolder you want to use. For example, /blog . nginx with the service that you want to point too in the subfolder project. lagoonproject with the Lagoon projectname of the subfolder project.","title":"location_prepend.conf"},{"location":"drupal/subfolders/#nginx-dockerfile","text":"Add the following to your NGINX Dockerfile ( nginx.dockerfile or Dockerfile.nginx ): nginx.dockerfile COPY location_prepend.conf /etc/nginx/conf.d/drupal/location_prepend.conf RUN fix-permissions /etc/nginx/conf.d/drupal/*","title":"NGINX Dockerfile"},{"location":"drupal/subfolders/#modifications-of-subfolder-application","text":"Like the root application, we also need to teach the subfolder application (in this example, the Drupal installation for www.example.com/blog ), that it is running under a subfolder. To do this, we create two files:","title":"Modifications of subfolder application"},{"location":"drupal/subfolders/#location_drupal_append_subfolderconf","text":"Create a file called location_drupal_append_subfolder.conf in the root of your subfolder Drupal installation: location_drupal_append_subfolder.conf # When injecting a script name that is prefixed with `subfolder`, Drupal will # render all URLs with `subfolder` prefixed fastcgi_param SCRIPT_NAME /subfolder/index.php; # If we are running via a reverse proxy, we inject the original HOST URL # into PHP. With this Drupal will render all URLs with the original HOST URL, # and not the current used HOST. # We first set the HOST to the regular host variable. fastcgi_param HTTP_HOST $http_host; # Then we overwrite it with `X-Lagoon-Forwarded-Host` if it exists. fastcgi_param HTTP_HOST $http_x_lagoon_forwarded_host if_not_empty; Replace /subfolder with the name of the subfolder you want to use. For example, /blog .","title":"location_drupal_append_subfolder.conf"},{"location":"drupal/subfolders/#server_prepend_subfolderconf","text":"Create a file called server_prepend_subfolder.conf in the root of your subfolder Drupal installation: server_prepend_subfolder.conf # Check for redirects before we do the internal Nginx rewrites. # This is done because the internal Nginx rewrites uses `last`, # which instructs Nginx to not check for rewrites anymore (and # `if` is part of the redirect module). include /etc/nginx/helpers/010_redirects.conf; # This is an internal Nginx rewrite, it removes `/subfolder/` # from the requests so that Nginx handles the request as it would # have been `/` from the beginning. # The `last` flag is also important. It will cause Nginx not to # execute any more rewrites, because it would redirect forever # with the rewrites below. rewrite ^/subfolder/(.*) /$1 last; # Make sure redirects are NOT absolute, to ensure Nginx does not # overwrite the host of the URL - which could be something other than # what Nginx currently thinks it is serving. absolute_redirect off; # If a request just has `/subfolder` we 301 redirect to `/subfolder/` # (Drupal really likes a trailing slash) rewrite ^/subfolder /subfolder/ permanent; # Any other request we prefix 301 redirect with `/subfolder/` rewrite ^\\/(.*) /subfolder/$1 permanent; Replace /subfolder with the name of the subfolder you want to use. For example, /blog .","title":"server_prepend_subfolder.conf"},{"location":"drupal/subfolders/#nginx-dockerfile_1","text":"We also need to modify the NGINX Dockerfile. Add the following to your NGINX Dockerfile ( nginx.dockerfile or Dockerfile.nginx ): nginx.dockerfile COPY location_drupal_append_subfolder.conf /etc/nginx/conf.d/drupal/location_drupal_append_subfolder.conf COPY server_prepend_subfolder.conf /etc/nginx/conf.d/drupal/server_prepend_subfolder.conf RUN fix-permissions /etc/nginx/conf.d/drupal/*","title":"Nginx Dockerfile"},{"location":"drupal/services/","text":"Services # MariaDB is the open-source successor to MySQL # Learn about MariaDB with Drupal Documentation on the MariaDB-Drupal image. Documentation on the plain MariaDB image (the MariaDB-Drupal image is built on this). Redis is a fast, open-source, in-memory key-value data store for use as a database, cache, message broker, and queue # Learn about Redis with Drupal. Documentation on the Redis-persistent image. Solr is an open-source search platform # Learn about Solr with Drupal. Documentation on the Solr-Drupal image. Documentation on the plain Solr image (the Solr-Drupal image is built on this). Varnish is a powerful, open-source HTTP engine and reverse HTTP proxy that helps to speed up your website # Learn about Varnish with Drupal Documentation on the Varnish-Drupal image. Documentation on the plain Varnish image (the Varnish-Drupal image is built on this).","title":"Overview"},{"location":"drupal/services/#services","text":"","title":"Services"},{"location":"drupal/services/#mariadb-is-the-open-source-successor-to-mysql","text":"Learn about MariaDB with Drupal Documentation on the MariaDB-Drupal image. Documentation on the plain MariaDB image (the MariaDB-Drupal image is built on this).","title":"MariaDB is the open-source successor to MySQL"},{"location":"drupal/services/#redis-is-a-fast-open-source-in-memory-key-value-data-store-for-use-as-a-database-cache-message-broker-and-queue","text":"Learn about Redis with Drupal. Documentation on the Redis-persistent image.","title":"Redis is a fast, open-source, in-memory key-value data store for use as a database, cache, message broker, and queue"},{"location":"drupal/services/#solr-is-an-open-source-search-platform","text":"Learn about Solr with Drupal. Documentation on the Solr-Drupal image. Documentation on the plain Solr image (the Solr-Drupal image is built on this).","title":"Solr is an open-source search platform"},{"location":"drupal/services/#varnish-is-a-powerful-open-source-http-engine-and-reverse-http-proxy-that-helps-to-speed-up-your-website","text":"Learn about Varnish with Drupal Documentation on the Varnish-Drupal image. Documentation on the plain Varnish image (the Varnish-Drupal image is built on this).","title":"Varnish is a powerful, open-source HTTP engine and reverse HTTP proxy that helps to speed up your website"},{"location":"drupal/services/mariadb/","text":"MariaDB-Drupal # The Lagoon mariadb-drupal Docker image Dockerfile is a customized mariadb image to use within Drupal projects in Lagoon. It differs from the mariadb image only for initial database setup, made by some environment variables: Environment Variable Default Description MARIADB_DATABASE drupal Drupal database created at startup. MARIADB_USER drupal Default user created at startup. MARIADB_PASSWORD drupal Password of default user created at startup. If the LAGOON_ENVIRONMENT_TYPE variable is set to production , performances are set accordingly by using MARIADB_INNODB_BUFFER_POOL_SIZE=1024 and MARIADB_INNODB_LOG_FILE_SIZE=256 . Additional MariaDB Logging # During the course of development, it may be necessary to enable either query logging or slow query logging. To do so, set the environment variables MARIADB_LOG_SLOW or MARIADB_LOG_QUERIES . This can be done in docker-compose.yml . Connecting to MySQL container from the host # If you would like to connect to your MySQL database inside the Docker container with an external tool like Sequel Pro , MySQL Workbench , HeidiSQL , DBeaver , plain old mysql-cli or anything else, here's how to get the IP and port info. Get published MySQL port from the container # By default, Docker assigns a randomly published port for MySQL during each container start. This is done to prevent port collisions. To get the published port via docker : Run: docker port [container_name] . $ docker port drupal_example_mariadb_1 3306/tcp -> 0.0.0.0:32797 Or via docker-compose inside a Drupal repository: Run: docker-compose port [service_name] [interal_port] . $ docker-compose port mariab 3306 0.0.0.0:32797 Setting a static port (not recommended) # During development, if you are using an external database tool, it may become cumbersome to continually check and set the MySQL connection port. To set a static port, edit your service definition in your docker-compose.yml . docker-compose.yml mariadb : ... ports : - \"33772:3306\" # Exposes port 3306 with a 33772 on the host port. Note by doing this you are responsible for managing port collisions`. Warning: By setting a static port you become responsible for managing port collisions. Connect to MySQL # Now you can use these details to connect to whatever database management tool you'd like. Linux OS X IP/Host IP from container docker.amazee.io Port Published port from container Published port from container Username drupal drupal Password drupal drupal Database drupal drupal","title":"MariaDB"},{"location":"drupal/services/mariadb/#mariadb-drupal","text":"The Lagoon mariadb-drupal Docker image Dockerfile is a customized mariadb image to use within Drupal projects in Lagoon. It differs from the mariadb image only for initial database setup, made by some environment variables: Environment Variable Default Description MARIADB_DATABASE drupal Drupal database created at startup. MARIADB_USER drupal Default user created at startup. MARIADB_PASSWORD drupal Password of default user created at startup. If the LAGOON_ENVIRONMENT_TYPE variable is set to production , performances are set accordingly by using MARIADB_INNODB_BUFFER_POOL_SIZE=1024 and MARIADB_INNODB_LOG_FILE_SIZE=256 .","title":"MariaDB-Drupal"},{"location":"drupal/services/mariadb/#additional-mariadb-logging","text":"During the course of development, it may be necessary to enable either query logging or slow query logging. To do so, set the environment variables MARIADB_LOG_SLOW or MARIADB_LOG_QUERIES . This can be done in docker-compose.yml .","title":"Additional MariaDB Logging"},{"location":"drupal/services/mariadb/#connecting-to-mysql-container-from-the-host","text":"If you would like to connect to your MySQL database inside the Docker container with an external tool like Sequel Pro , MySQL Workbench , HeidiSQL , DBeaver , plain old mysql-cli or anything else, here's how to get the IP and port info.","title":"Connecting to MySQL container from the host"},{"location":"drupal/services/mariadb/#get-published-mysql-port-from-the-container","text":"By default, Docker assigns a randomly published port for MySQL during each container start. This is done to prevent port collisions. To get the published port via docker : Run: docker port [container_name] . $ docker port drupal_example_mariadb_1 3306/tcp -> 0.0.0.0:32797 Or via docker-compose inside a Drupal repository: Run: docker-compose port [service_name] [interal_port] . $ docker-compose port mariab 3306 0.0.0.0:32797","title":"Get published MySQL port from the container"},{"location":"drupal/services/mariadb/#setting-a-static-port-not-recommended","text":"During development, if you are using an external database tool, it may become cumbersome to continually check and set the MySQL connection port. To set a static port, edit your service definition in your docker-compose.yml . docker-compose.yml mariadb : ... ports : - \"33772:3306\" # Exposes port 3306 with a 33772 on the host port. Note by doing this you are responsible for managing port collisions`. Warning: By setting a static port you become responsible for managing port collisions.","title":"Setting a static port (not recommended)"},{"location":"drupal/services/mariadb/#connect-to-mysql","text":"Now you can use these details to connect to whatever database management tool you'd like. Linux OS X IP/Host IP from container docker.amazee.io Port Published port from container Published port from container Username drupal drupal Password drupal drupal Database drupal drupal","title":"Connect to MySQL"},{"location":"drupal/services/nginx/","text":"NGINX-Drupal # The Lagoon nginx-drupal Docker image . Optimized to work with Drupal. Based on Lagoon nginx image . Lagoon adaptions # This image is prepared to be used on Lagoon. There are therefore some things already done: Folder permissions are automatically adapted with fix-permissions , so this image will work with a random user. To keep drupal.conf 's configuration file as clean and customizable as possible, we added include directives in the main sections of the file: server , location / , location @drupal and location @php . Further information in the section Drupal.conf customization . Included Drupal configuration ( drupal.conf ) # The image includes a full NGINX working configuration for Drupal 7, 8 and 9. It includes some extra functionalities like: Support for humanstxt Drupal module . Support for robotstxt Drupal module . Disallow access to vagrant directory for local development. Drupal.conf customization # The drupal.conf file is a customized version of the nginx configuration file, optimized for Drupal. Customers have different ways of customizing it: Modifying it (hard to support in case of errors). Using built-in customization through *.conf files. The drupal.conf file is divided into several sections. The sections we've included in our customizations are: server location / location @drupal location @php . For each of this section, there are two includes: *_prepend.conf *_append.conf Here what the location @drupal section looks like: drupal.conf location @drupal { include /etc/nginx/conf.d/drupal/location_drupal_prepend*.conf ; include /etc/nginx/fastcgi.conf ; fastcgi_param SCRIPT_NAME /index.php ; fastcgi_param SCRIPT_FILENAME $realpath_root /index.php ; fastcgi_pass ${ NGINX_FASTCGI_PASS :- php } :9000 ; include /etc/nginx/conf.d/drupal/location_drupal_append*.conf ; } This configuration allows customers to create files called location_drupal_prepend.conf and location_drupal_append.conf , where they can put all the configuration they want to insert before and after the other statements. Those files, once created, MUST exist in the nginx container, so add them to Dockerfile.nginx like so: dockerfile.nginx COPY location_drupal_prepend.conf /etc/nginx/conf.d/drupal/location_drupal_prepend.conf RUN fix-permissions /etc/nginx/conf.d/drupal/location_drupal_prepend.conf Drupal Core Statistics Module Configuration # If you're using the core Statistics module, you may run into an issue that needs a quick configuration change. With the default NGINX configuration, the request to the tracking endpoint /core/modules/statistics/statistics.php is denied (404). This is related to the default Nginx configuration: drupal.conf location ~* ^.+\\.php$ { try_files /dev/null @drupal; } To fix the issue, we instead define a specific location rule and inject this as a location prepend configuration: drupal.conf ## Allow access to to the statistics endpoint. location ~* ^(/core/modules/statistics/statistics.php) { try_files /dev/null @php; } And copy this during the NGINX container build: dockerfile.nginx # Add specific Drupal statistics module NGINX configuration. COPY .lagoon/nginx/location_prepend_allow_statistics.conf /etc/nginx/conf.d/drupal/location_prepend_allow_statistics.conf","title":"NGINX"},{"location":"drupal/services/nginx/#nginx-drupal","text":"The Lagoon nginx-drupal Docker image . Optimized to work with Drupal. Based on Lagoon nginx image .","title":"NGINX-Drupal"},{"location":"drupal/services/nginx/#lagoon-adaptions","text":"This image is prepared to be used on Lagoon. There are therefore some things already done: Folder permissions are automatically adapted with fix-permissions , so this image will work with a random user. To keep drupal.conf 's configuration file as clean and customizable as possible, we added include directives in the main sections of the file: server , location / , location @drupal and location @php . Further information in the section Drupal.conf customization .","title":"Lagoon adaptions"},{"location":"drupal/services/nginx/#included-drupal-configuration-drupalconf","text":"The image includes a full NGINX working configuration for Drupal 7, 8 and 9. It includes some extra functionalities like: Support for humanstxt Drupal module . Support for robotstxt Drupal module . Disallow access to vagrant directory for local development.","title":"Included Drupal configuration (drupal.conf)"},{"location":"drupal/services/nginx/#drupalconf-customization","text":"The drupal.conf file is a customized version of the nginx configuration file, optimized for Drupal. Customers have different ways of customizing it: Modifying it (hard to support in case of errors). Using built-in customization through *.conf files. The drupal.conf file is divided into several sections. The sections we've included in our customizations are: server location / location @drupal location @php . For each of this section, there are two includes: *_prepend.conf *_append.conf Here what the location @drupal section looks like: drupal.conf location @drupal { include /etc/nginx/conf.d/drupal/location_drupal_prepend*.conf ; include /etc/nginx/fastcgi.conf ; fastcgi_param SCRIPT_NAME /index.php ; fastcgi_param SCRIPT_FILENAME $realpath_root /index.php ; fastcgi_pass ${ NGINX_FASTCGI_PASS :- php } :9000 ; include /etc/nginx/conf.d/drupal/location_drupal_append*.conf ; } This configuration allows customers to create files called location_drupal_prepend.conf and location_drupal_append.conf , where they can put all the configuration they want to insert before and after the other statements. Those files, once created, MUST exist in the nginx container, so add them to Dockerfile.nginx like so: dockerfile.nginx COPY location_drupal_prepend.conf /etc/nginx/conf.d/drupal/location_drupal_prepend.conf RUN fix-permissions /etc/nginx/conf.d/drupal/location_drupal_prepend.conf","title":"Drupal.conf customization"},{"location":"drupal/services/nginx/#drupal-core-statistics-module-configuration","text":"If you're using the core Statistics module, you may run into an issue that needs a quick configuration change. With the default NGINX configuration, the request to the tracking endpoint /core/modules/statistics/statistics.php is denied (404). This is related to the default Nginx configuration: drupal.conf location ~* ^.+\\.php$ { try_files /dev/null @drupal; } To fix the issue, we instead define a specific location rule and inject this as a location prepend configuration: drupal.conf ## Allow access to to the statistics endpoint. location ~* ^(/core/modules/statistics/statistics.php) { try_files /dev/null @php; } And copy this during the NGINX container build: dockerfile.nginx # Add specific Drupal statistics module NGINX configuration. COPY .lagoon/nginx/location_prepend_allow_statistics.conf /etc/nginx/conf.d/drupal/location_prepend_allow_statistics.conf","title":"Drupal Core Statistics Module Configuration"},{"location":"drupal/services/php-cli/","text":"PHP-CLI-Drupal # The Lagoon php-cli-drupal Docker image is optimized to work with Drupal. It is based on the Lagoon php-cli image , and has all the command line tools needed for the daily maintenance of a Drupal website: drush drupal console drush launcher (which will fallback to Drush 8 if there is no site installed Drush found) Supported versions # 7.3 (available for compatibility, no longer officially supported) 7.4 Dockerfile - uselagoon/php-7.4-cli-drupal 8.0 Dockerfile - uselagoon/php-8.0-cli-drupal 8.1 Dockerfile - uselagoon/php-8.1-cli-drupal All PHP versions use their own Dockerfiles. Lagoon adaptions # This image is prepared to be used on Lagoon. There are therefore some things already done: Folder permissions are automatically adapted with fix-permissions , so this image will work with a random user.","title":"PHP-cli"},{"location":"drupal/services/php-cli/#php-cli-drupal","text":"The Lagoon php-cli-drupal Docker image is optimized to work with Drupal. It is based on the Lagoon php-cli image , and has all the command line tools needed for the daily maintenance of a Drupal website: drush drupal console drush launcher (which will fallback to Drush 8 if there is no site installed Drush found)","title":"PHP-CLI-Drupal"},{"location":"drupal/services/php-cli/#supported-versions","text":"7.3 (available for compatibility, no longer officially supported) 7.4 Dockerfile - uselagoon/php-7.4-cli-drupal 8.0 Dockerfile - uselagoon/php-8.0-cli-drupal 8.1 Dockerfile - uselagoon/php-8.1-cli-drupal All PHP versions use their own Dockerfiles.","title":"Supported versions"},{"location":"drupal/services/php-cli/#lagoon-adaptions","text":"This image is prepared to be used on Lagoon. There are therefore some things already done: Folder permissions are automatically adapted with fix-permissions , so this image will work with a random user.","title":"Lagoon adaptions"},{"location":"drupal/services/redis/","text":"Redis # We recommend using Redis for internal caching. Add the Redis service to docker-compose.yaml . docker-compose.yml redis : image : uselagoon/redis-5 labels : lagoon.type : redis << : *default-user # Uses the defined user from top. environment : << : *default-environment Also, to configure Redis, add the following to your settings.php . Drupal 7 # settings.php if(getenv('LAGOON')){ $conf['redis_client_interface'] = 'PhpRedis'; $conf['redis_client_host'] = 'redis'; $conf['lock_inc'] = 'sites/all/modules/contrib/redis/redis.lock.inc'; $conf['path_inc'] = 'sites/all/modules/contrib/redis/redis.path.inc'; $conf['cache_backends'][] = 'sites/all/modules/contrib/redis/redis.autoload.inc'; $conf['cache_default_class'] = 'Redis_Cache'; $conf['cache_class_cache_form'] = 'DrupalDatabaseCache'; $conf['cache_class_cache_field'] = 'DrupalDatabaseCache'; } Depending on file system structure, the module paths may need to be updated. Drupal 8 # The Drupal 8 config is largely stock. Notably, Redis is disabled while Drupal is being installed. settings.php if (getenv('LAGOON')){ $settings['redis.connection']['interface'] = 'PhpRedis'; $settings['redis.connection']['host'] = getenv('REDIS_HOST') ?: 'redis'; $settings['redis.connection']['port'] = getenv('REDIS_SERVICE_PORT') ?: '6379'; $settings['cache_prefix']['default'] = getenv('LAGOON_PROJECT') . '_' . getenv('LAGOON_GIT_SAFE_BRANCH'); // Do not set the cache during installations of Drupal. if (!drupal_installation_attempted() && extension_loaded('redis')) { $settings['cache']['default'] = 'cache.backend.redis'; // And allows to use it without the Redis module being enabled. $class_loader->addPsr4('Drupal\\\\redis\\\\', 'modules/contrib/redis/src'); $settings['bootstrap_container_definition'] = [ 'parameters' => [], 'services' => [ 'redis.factory' => [ 'class' => 'Drupal\\redis\\ClientFactory', ], 'cache.backend.redis' => [ 'class' => 'Drupal\\redis\\Cache\\CacheBackendFactory', 'arguments' => ['@redis.factory', '@cache_tags_provider.container', '@serialization.phpserialize'], ], 'cache.container' => [ 'class' => '\\Drupal\\redis\\Cache\\PhpRedis', 'factory' => ['@cache.backend.redis', 'get'], 'arguments' => ['container'], ], 'cache_tags_provider.container' => [ 'class' => 'Drupal\\redis\\Cache\\RedisCacheTagsChecksum', 'arguments' => ['@redis.factory'], ], 'serialization.phpserialize' => [ 'class' => 'Drupal\\Component\\Serialization\\PhpSerialize', ], ], ]; } } Persistent # Redis can also be configured as a persistent backend. docker-compose.yml redis : image : uselagoon/redis-5-persistent labels : lagoon.type : redis-persistent environment : << : *default-environment Environment Variables # Environment variables are meant to store some common information about Redis. Environment Variable Default Description LOGLEVEL notice Redis loglevel DATABASES 1 Number of databases MAXMEMORY 100mb Maximum memory usage of Redis Redis Failover # Here is a snippet to implement a Redis failover in case of the Redis container not being available (for example, during maintenance) The following is inserted into Drupal 7's active settings.php file. settings.php if (getenv('LAGOON')) { $contrib_path = is_dir('sites/all/modules/contrib') ? 'sites/all/modules/contrib' : 'sites/all/modules'; $redis = DRUPAL_ROOT . '/sites/all/modules/contrib/redis'; if (file_exists(\"$redis/redis.module\")) { require_once \"$redis/redis.module\"; $conf['redis_client_host'] = getenv('REDIS_HOST') ?: 'redis'; $conf['redis_client_port'] = getenv('REDIS_SERVICE_PORT') ?: 6379; $conf['cache_prefix'] = getenv('REDIS_CACHE_PREFIX') ?: getenv('LAGOON_PROJECT') . '_' . getenv('LAGOON_GIT_SAFE_BRANCH'); try { // Ensure that there is a connection to redis. $client = Redis_Client::getClient(); $response = $client->ping(); if (!strpos($response, 'PONG')) { throw new Exception('Invalid redis response.'); } $conf['redis_client_interface'] = 'PhpRedis'; $conf['lock_inc'] = $contrib_path . '/redis/redis.lock.inc'; $conf['path_inc'] = $contrib_path . '/redis/redis.path.inc'; $conf['cache_backends'][] = $contrib_path . '/redis/redis.autoload.inc'; $conf['cache_default_class'] = 'Redis_Cache'; } catch (\\Exception $e) { // Redis is not available for this request we should not configure the // redis backend and ensure no cache is used. This will retry next // request. if (!class_exists('DrupalFakeCache')) { $conf['cache_backends'][] = 'includes/cache-install.inc'; } $conf['cache_default_class'] = 'DrupalFakeCache'; } } }","title":"Redis"},{"location":"drupal/services/redis/#redis","text":"We recommend using Redis for internal caching. Add the Redis service to docker-compose.yaml . docker-compose.yml redis : image : uselagoon/redis-5 labels : lagoon.type : redis << : *default-user # Uses the defined user from top. environment : << : *default-environment Also, to configure Redis, add the following to your settings.php .","title":"Redis"},{"location":"drupal/services/redis/#drupal-7","text":"settings.php if(getenv('LAGOON')){ $conf['redis_client_interface'] = 'PhpRedis'; $conf['redis_client_host'] = 'redis'; $conf['lock_inc'] = 'sites/all/modules/contrib/redis/redis.lock.inc'; $conf['path_inc'] = 'sites/all/modules/contrib/redis/redis.path.inc'; $conf['cache_backends'][] = 'sites/all/modules/contrib/redis/redis.autoload.inc'; $conf['cache_default_class'] = 'Redis_Cache'; $conf['cache_class_cache_form'] = 'DrupalDatabaseCache'; $conf['cache_class_cache_field'] = 'DrupalDatabaseCache'; } Depending on file system structure, the module paths may need to be updated.","title":"Drupal 7"},{"location":"drupal/services/redis/#drupal-8","text":"The Drupal 8 config is largely stock. Notably, Redis is disabled while Drupal is being installed. settings.php if (getenv('LAGOON')){ $settings['redis.connection']['interface'] = 'PhpRedis'; $settings['redis.connection']['host'] = getenv('REDIS_HOST') ?: 'redis'; $settings['redis.connection']['port'] = getenv('REDIS_SERVICE_PORT') ?: '6379'; $settings['cache_prefix']['default'] = getenv('LAGOON_PROJECT') . '_' . getenv('LAGOON_GIT_SAFE_BRANCH'); // Do not set the cache during installations of Drupal. if (!drupal_installation_attempted() && extension_loaded('redis')) { $settings['cache']['default'] = 'cache.backend.redis'; // And allows to use it without the Redis module being enabled. $class_loader->addPsr4('Drupal\\\\redis\\\\', 'modules/contrib/redis/src'); $settings['bootstrap_container_definition'] = [ 'parameters' => [], 'services' => [ 'redis.factory' => [ 'class' => 'Drupal\\redis\\ClientFactory', ], 'cache.backend.redis' => [ 'class' => 'Drupal\\redis\\Cache\\CacheBackendFactory', 'arguments' => ['@redis.factory', '@cache_tags_provider.container', '@serialization.phpserialize'], ], 'cache.container' => [ 'class' => '\\Drupal\\redis\\Cache\\PhpRedis', 'factory' => ['@cache.backend.redis', 'get'], 'arguments' => ['container'], ], 'cache_tags_provider.container' => [ 'class' => 'Drupal\\redis\\Cache\\RedisCacheTagsChecksum', 'arguments' => ['@redis.factory'], ], 'serialization.phpserialize' => [ 'class' => 'Drupal\\Component\\Serialization\\PhpSerialize', ], ], ]; } }","title":"Drupal 8"},{"location":"drupal/services/redis/#persistent","text":"Redis can also be configured as a persistent backend. docker-compose.yml redis : image : uselagoon/redis-5-persistent labels : lagoon.type : redis-persistent environment : << : *default-environment","title":"Persistent"},{"location":"drupal/services/redis/#environment-variables","text":"Environment variables are meant to store some common information about Redis. Environment Variable Default Description LOGLEVEL notice Redis loglevel DATABASES 1 Number of databases MAXMEMORY 100mb Maximum memory usage of Redis","title":"Environment Variables"},{"location":"drupal/services/redis/#redis-failover","text":"Here is a snippet to implement a Redis failover in case of the Redis container not being available (for example, during maintenance) The following is inserted into Drupal 7's active settings.php file. settings.php if (getenv('LAGOON')) { $contrib_path = is_dir('sites/all/modules/contrib') ? 'sites/all/modules/contrib' : 'sites/all/modules'; $redis = DRUPAL_ROOT . '/sites/all/modules/contrib/redis'; if (file_exists(\"$redis/redis.module\")) { require_once \"$redis/redis.module\"; $conf['redis_client_host'] = getenv('REDIS_HOST') ?: 'redis'; $conf['redis_client_port'] = getenv('REDIS_SERVICE_PORT') ?: 6379; $conf['cache_prefix'] = getenv('REDIS_CACHE_PREFIX') ?: getenv('LAGOON_PROJECT') . '_' . getenv('LAGOON_GIT_SAFE_BRANCH'); try { // Ensure that there is a connection to redis. $client = Redis_Client::getClient(); $response = $client->ping(); if (!strpos($response, 'PONG')) { throw new Exception('Invalid redis response.'); } $conf['redis_client_interface'] = 'PhpRedis'; $conf['lock_inc'] = $contrib_path . '/redis/redis.lock.inc'; $conf['path_inc'] = $contrib_path . '/redis/redis.path.inc'; $conf['cache_backends'][] = $contrib_path . '/redis/redis.autoload.inc'; $conf['cache_default_class'] = 'Redis_Cache'; } catch (\\Exception $e) { // Redis is not available for this request we should not configure the // redis backend and ensure no cache is used. This will retry next // request. if (!class_exists('DrupalFakeCache')) { $conf['cache_backends'][] = 'includes/cache-install.inc'; } $conf['cache_default_class'] = 'DrupalFakeCache'; } } }","title":"Redis Failover"},{"location":"drupal/services/solr/","text":"Solr-Drupal # Standard use # For Solr 5.5, 6.6 and 7.7, we ship the default schema files provided by the search_api_solr Drupal module. Add the Solr version you would like to use in your docker-compose.yml file, following our example . Custom schema # To implement schema customizations for Solr in your project, look to how Lagoon creates our standard images . In the solr section of your docker-compose.yml file, replace image: amazeeio/solr:7.7 with: docker-compose.yml build : context : . dockerfile : solr.dockerfile Place your schema files in your code repository. We typically like to use .lagoon/solr . Create a solr.dockerfile . solr.dockerfile FROM amazeeio/solr:7.7 COPY .lagoon/solr /solr-conf/conf RUN precreate-core drupal /solr-conf CMD [ \"solr-foreground\" ] The goal is to have your Solr configuration files exist at /solr-conf/conf in the image you are building. Multiple cores # To implement multiple cores, you will also need to ship your own Solr schema as above. The only change needed is to the CMD of the Dockerfile - repeat the pattern of precreate-core corename /solr-conf/ ; for each core you require. solr.dockerfile FROM amazeeio/solr:7.7-drupal RUN precreate-core drupal-index1 /solr-conf && \\ precreate-core drupal-index2 /solr-conf && \\ precreate-core drupal-index3 /solr-conf CMD [ \"solr-foreground\" ]","title":"Solr"},{"location":"drupal/services/solr/#solr-drupal","text":"","title":"Solr-Drupal"},{"location":"drupal/services/solr/#standard-use","text":"For Solr 5.5, 6.6 and 7.7, we ship the default schema files provided by the search_api_solr Drupal module. Add the Solr version you would like to use in your docker-compose.yml file, following our example .","title":"Standard use"},{"location":"drupal/services/solr/#custom-schema","text":"To implement schema customizations for Solr in your project, look to how Lagoon creates our standard images . In the solr section of your docker-compose.yml file, replace image: amazeeio/solr:7.7 with: docker-compose.yml build : context : . dockerfile : solr.dockerfile Place your schema files in your code repository. We typically like to use .lagoon/solr . Create a solr.dockerfile . solr.dockerfile FROM amazeeio/solr:7.7 COPY .lagoon/solr /solr-conf/conf RUN precreate-core drupal /solr-conf CMD [ \"solr-foreground\" ] The goal is to have your Solr configuration files exist at /solr-conf/conf in the image you are building.","title":"Custom schema"},{"location":"drupal/services/solr/#multiple-cores","text":"To implement multiple cores, you will also need to ship your own Solr schema as above. The only change needed is to the CMD of the Dockerfile - repeat the pattern of precreate-core corename /solr-conf/ ; for each core you require. solr.dockerfile FROM amazeeio/solr:7.7-drupal RUN precreate-core drupal-index1 /solr-conf && \\ precreate-core drupal-index2 /solr-conf && \\ precreate-core drupal-index3 /solr-conf CMD [ \"solr-foreground\" ]","title":"Multiple cores"},{"location":"drupal/services/varnish/","text":"Varnish # We suggest using Drupal with a Varnish reverse proxy. Lagoon provides a varnish-drupal Docker image that has Varnish already configured with a Drupal Varnish config . This Varnish config does the following: It understands Drupal session cookies and automatically disables the Varnish caching for any authenticated request. It automatically caches any assets (images, css, js, etc.) for one month, and also sends this header to the browser, so browser cache the assets as well. This happens for authenticated and non-authenticated requests. It has support for BAN and URIBAN which is used by the Drupal 8 purge module. It removes utm_ and gclid from the URL parameter to prevent Google Analytics links from creating multiple cache objects. Many other good things - just check out the drupal.vcl . Usage with Drupal 8 # TL;DR : Check out the drupal8-advanced example in our examples repo , it ships with the needed modules and needed Drupal configuration. Note : many of these examples are on the same drupal-example-simple repo, but different branches/hashes. Be sure to get the exact branch from the examples list! Install Purge and Varnish Purge modules # In order to fully use Varnish with Drupal 8 cache tags, you need to install the Purge and Varnish Purge modules. They ship with many submodules. We suggest installing at least the following: purge purge_drush purge_tokens purge_ui purge_processor_cron purge_processor_lateruntime purge_queuer_coretags varnish_purger varnish_purge_tags Grab them all at once: composer require drupal/purge drupal/varnish_purge drush en purge purge_drush purge_tokens purge_ui purge_processor_cron purge_processor_lateruntime purge_queuer_coretags varnish_purger varnish_purge_tags Configure Varnish Purge # Visit Configuration > Development > Performance > Purge . Add a purger via Add purger . Select Varnish Bundled Purger (not the Varnish Purger , see the #Behind the Scenes section, for more information.). Click the dropdown beside the just added purger and click Configure . Give it a nice name, Lagoon Varnish sounds good. Configure it with: TYPE: Tag REQUEST: Hostname: varnish (or whatever your Varnish is called in docker-compose.yml) Port: 8080 Path: / Request Method: BAN Scheme: http HEADERS: Header: Cache-Tags Value: [invalidations:separated_pipe] Save configuration . That's it! If you'd like to test this locally, make sure you read the next section. Configure Drupal for Varnish # There are a few other configurations that can be done: Uninstall the Internal Page Cache Drupal module with drush pmu page_cache . It can cause some weird double caching situations where only the Varnish cache is cleared, but not the internal cache, and changes appear very slowly to the users. Also, it uses a lot of cache storage on big sites. Change $config['system.performance']['cache']['page']['max_age'] in production.settings.php to 2628000 . This tells Varnish to cache sites for up 1 month, which sounds like a lot, but the Drupal 8 cache tag system is so awesome that it will basically make sure that the Varnish cache is purged whenever something changes. Test Varnish Locally # Drupal setups on Lagoon locally have Varnish and the Drupal caches disabled as it can be rather hard to develop with all them set. This is done via the following: The VARNISH_BYPASS=true environment variable in docker-compose.yml which tells Varnish to basically disable itself. Drupal is configured to not send any cache headers (via setting the Drupal config $config['system.performance']['cache']['page']['max_age'] = 0 in development.settings.php ). To test Varnish locally, change the following in docker-compose.yml : Set VARNISH_BYPASS to false in the Varnish service section. Set LAGOON_ENVIRONMENT_TYPE to production in the x-environment section. Run docker-compose up -d , which restarts all services with the new environment variables. Now you should be able to test Varnish! Here is a short example assuming there is a node with the ID 1 and has the URL drupal-example.docker.amazee.io/node/1 Run curl -I drupal-example.docker.amazee.io/node/1 and look for these headers: X-LAGOON should include varnish which tells you that the request actually went through Varnish. Age: will be still 0 as Varnish has probably never seen this site before, and the first request will warm the varnish cache. X-Varnish-Cache will be MISS , also telling you that Varnish didn't find a previously cached version of this request. Now run curl -I drupal-example.docker.amazee.io/node/1 again, and the headers should be: Age: will show you how many seconds ago the request has been cached. In our example it will probably something between 1-30, depending on how fast you are executing the command. X-Varnish-Cache will be HIT , telling you that Varnish successfully found a cached version of the request and returned that one to you. Change some content at node/1 in Drupal. Run curl -I drupal-example.docker.amazee.io/node/1 , and the headers should the same as very first request: Age:0 X-Varnish-Cache: MISS Varnish on Drupal behind the scenes # If you come from other Drupal hosts or have done a Drupal 8 & Varnish tutorial before, you might have realized that there are a couple of changes in the Lagoon Drupal Varnish tutorial. Let's address them: Usage of Varnish Bundled Purger instead of Varnish Purger # The Varnish Purger purger sends a BAN request for each cache-tag that should be invalidated. Drupal has a lot of cache-tags, and this could lead to quite a large amount of requests sent to Varnish. Varnish Bundled Purger instead sends just one BAN request for multiple invalidations, separated nicely by pipe ( | ), which fits perfectly with the Varnish regular expression system of bans. This causes less requests and a smaller ban list table inside Varnish. Usage of Purge Late runtime processor # Contradictory to the Varnish module in Drupal 7, the Drupal 8 Purge module has a slightly different approach to purging caches: It adds them to a queue which is then processed by different processors. Purge suggests using the Cron processor , which means that the Varnish cache is only purged during a cron run. This can lead to old data being cached by Varnish, as your cron is probably not configured to run every minute or so, and can result in confused editors and clients. Instead, we suggest using the Purge Late runtime processor , which processes the queue at the end of each Drupal request. This has the advantage that if a cache-tag is added to the purge queue (because an editor edited a Drupal node, for example) the cache-tags for this node are directly purged. Together with the Varnish Bundled Purger , this means just a single additional request to Varnish at the very end of a Drupal request, which causes no noticeable processing time on the request. Full support for Varnish Ban Lurker # Our Varnish configurations have full support for Ban Lurker . Ban Lurker helps you to maintain a clean cache and keep Varnish running smoothly. It is basically a small tool that runs through the Varnish ban list and compares them to the cached requests in the Varnish cache. Varnish bans are used to mark an object in the cache for purging. If Ban Lurker finds an item that should be \"banned,\" it removes them from the cache and also removes the ban itself. Now any seldom-accessed objects with very long TTLs which would normally never be banned and just keep taking up cache space are removed and can be refreshed. This keeps the list of bans small and with that, less processing time for Varnish on each request. Check out the official Varnish post on Ban Lurker and some other helpful reading for more information. Troubleshooting # Varnish doesn't cache? Or something else not working? Here a couple of ways to debug: Run drush p-debug-en to enable debug logging of the purge module. This should show you debugging in the Drupal log under admin/reports/dblog . Make sure that Drupal sends proper cache headers. To best test this, use the URL that Lagoon generates for bypassing the Varnish cache, (locally in our Drupal example this is http://nginx-drupal-example.docker.amazee.io ). Check for the Cache-Control: max-age=900, public header, where the 900 is what you configured in $config['system.performance']['cache']['page']['max_age'] . Make sure that the environment variable VARNISH_BYPASS is not set to true (see docker-compose.yml and run docker-compose up -d varnish to make sure the environment variable is configured correctly). If all fails, and before you flip your table (\u256f\u00b0\u25a1\u00b0\uff09\u256f\ufe35 \u253b\u2501\u253b, talk to the Lagoon team, we're happy to help.","title":"Varnish"},{"location":"drupal/services/varnish/#varnish","text":"We suggest using Drupal with a Varnish reverse proxy. Lagoon provides a varnish-drupal Docker image that has Varnish already configured with a Drupal Varnish config . This Varnish config does the following: It understands Drupal session cookies and automatically disables the Varnish caching for any authenticated request. It automatically caches any assets (images, css, js, etc.) for one month, and also sends this header to the browser, so browser cache the assets as well. This happens for authenticated and non-authenticated requests. It has support for BAN and URIBAN which is used by the Drupal 8 purge module. It removes utm_ and gclid from the URL parameter to prevent Google Analytics links from creating multiple cache objects. Many other good things - just check out the drupal.vcl .","title":"Varnish"},{"location":"drupal/services/varnish/#usage-with-drupal-8","text":"TL;DR : Check out the drupal8-advanced example in our examples repo , it ships with the needed modules and needed Drupal configuration. Note : many of these examples are on the same drupal-example-simple repo, but different branches/hashes. Be sure to get the exact branch from the examples list!","title":"Usage with Drupal 8"},{"location":"drupal/services/varnish/#install-purge-and-varnish-purge-modules","text":"In order to fully use Varnish with Drupal 8 cache tags, you need to install the Purge and Varnish Purge modules. They ship with many submodules. We suggest installing at least the following: purge purge_drush purge_tokens purge_ui purge_processor_cron purge_processor_lateruntime purge_queuer_coretags varnish_purger varnish_purge_tags Grab them all at once: composer require drupal/purge drupal/varnish_purge drush en purge purge_drush purge_tokens purge_ui purge_processor_cron purge_processor_lateruntime purge_queuer_coretags varnish_purger varnish_purge_tags","title":"Install Purge and Varnish Purge modules"},{"location":"drupal/services/varnish/#configure-varnish-purge","text":"Visit Configuration > Development > Performance > Purge . Add a purger via Add purger . Select Varnish Bundled Purger (not the Varnish Purger , see the #Behind the Scenes section, for more information.). Click the dropdown beside the just added purger and click Configure . Give it a nice name, Lagoon Varnish sounds good. Configure it with: TYPE: Tag REQUEST: Hostname: varnish (or whatever your Varnish is called in docker-compose.yml) Port: 8080 Path: / Request Method: BAN Scheme: http HEADERS: Header: Cache-Tags Value: [invalidations:separated_pipe] Save configuration . That's it! If you'd like to test this locally, make sure you read the next section.","title":"Configure Varnish Purge"},{"location":"drupal/services/varnish/#configure-drupal-for-varnish","text":"There are a few other configurations that can be done: Uninstall the Internal Page Cache Drupal module with drush pmu page_cache . It can cause some weird double caching situations where only the Varnish cache is cleared, but not the internal cache, and changes appear very slowly to the users. Also, it uses a lot of cache storage on big sites. Change $config['system.performance']['cache']['page']['max_age'] in production.settings.php to 2628000 . This tells Varnish to cache sites for up 1 month, which sounds like a lot, but the Drupal 8 cache tag system is so awesome that it will basically make sure that the Varnish cache is purged whenever something changes.","title":"Configure Drupal for Varnish"},{"location":"drupal/services/varnish/#test-varnish-locally","text":"Drupal setups on Lagoon locally have Varnish and the Drupal caches disabled as it can be rather hard to develop with all them set. This is done via the following: The VARNISH_BYPASS=true environment variable in docker-compose.yml which tells Varnish to basically disable itself. Drupal is configured to not send any cache headers (via setting the Drupal config $config['system.performance']['cache']['page']['max_age'] = 0 in development.settings.php ). To test Varnish locally, change the following in docker-compose.yml : Set VARNISH_BYPASS to false in the Varnish service section. Set LAGOON_ENVIRONMENT_TYPE to production in the x-environment section. Run docker-compose up -d , which restarts all services with the new environment variables. Now you should be able to test Varnish! Here is a short example assuming there is a node with the ID 1 and has the URL drupal-example.docker.amazee.io/node/1 Run curl -I drupal-example.docker.amazee.io/node/1 and look for these headers: X-LAGOON should include varnish which tells you that the request actually went through Varnish. Age: will be still 0 as Varnish has probably never seen this site before, and the first request will warm the varnish cache. X-Varnish-Cache will be MISS , also telling you that Varnish didn't find a previously cached version of this request. Now run curl -I drupal-example.docker.amazee.io/node/1 again, and the headers should be: Age: will show you how many seconds ago the request has been cached. In our example it will probably something between 1-30, depending on how fast you are executing the command. X-Varnish-Cache will be HIT , telling you that Varnish successfully found a cached version of the request and returned that one to you. Change some content at node/1 in Drupal. Run curl -I drupal-example.docker.amazee.io/node/1 , and the headers should the same as very first request: Age:0 X-Varnish-Cache: MISS","title":"Test Varnish Locally"},{"location":"drupal/services/varnish/#varnish-on-drupal-behind-the-scenes","text":"If you come from other Drupal hosts or have done a Drupal 8 & Varnish tutorial before, you might have realized that there are a couple of changes in the Lagoon Drupal Varnish tutorial. Let's address them:","title":"Varnish on Drupal behind the scenes"},{"location":"drupal/services/varnish/#usage-of-varnish-bundled-purger-instead-of-varnish-purger","text":"The Varnish Purger purger sends a BAN request for each cache-tag that should be invalidated. Drupal has a lot of cache-tags, and this could lead to quite a large amount of requests sent to Varnish. Varnish Bundled Purger instead sends just one BAN request for multiple invalidations, separated nicely by pipe ( | ), which fits perfectly with the Varnish regular expression system of bans. This causes less requests and a smaller ban list table inside Varnish.","title":"Usage of Varnish Bundled Purger instead of Varnish Purger"},{"location":"drupal/services/varnish/#usage-of-purge-late-runtime-processor","text":"Contradictory to the Varnish module in Drupal 7, the Drupal 8 Purge module has a slightly different approach to purging caches: It adds them to a queue which is then processed by different processors. Purge suggests using the Cron processor , which means that the Varnish cache is only purged during a cron run. This can lead to old data being cached by Varnish, as your cron is probably not configured to run every minute or so, and can result in confused editors and clients. Instead, we suggest using the Purge Late runtime processor , which processes the queue at the end of each Drupal request. This has the advantage that if a cache-tag is added to the purge queue (because an editor edited a Drupal node, for example) the cache-tags for this node are directly purged. Together with the Varnish Bundled Purger , this means just a single additional request to Varnish at the very end of a Drupal request, which causes no noticeable processing time on the request.","title":"Usage of Purge Late runtime processor"},{"location":"drupal/services/varnish/#full-support-for-varnish-ban-lurker","text":"Our Varnish configurations have full support for Ban Lurker . Ban Lurker helps you to maintain a clean cache and keep Varnish running smoothly. It is basically a small tool that runs through the Varnish ban list and compares them to the cached requests in the Varnish cache. Varnish bans are used to mark an object in the cache for purging. If Ban Lurker finds an item that should be \"banned,\" it removes them from the cache and also removes the ban itself. Now any seldom-accessed objects with very long TTLs which would normally never be banned and just keep taking up cache space are removed and can be refreshed. This keeps the list of bans small and with that, less processing time for Varnish on each request. Check out the official Varnish post on Ban Lurker and some other helpful reading for more information.","title":"Full support for Varnish Ban Lurker"},{"location":"drupal/services/varnish/#troubleshooting","text":"Varnish doesn't cache? Or something else not working? Here a couple of ways to debug: Run drush p-debug-en to enable debug logging of the purge module. This should show you debugging in the Drupal log under admin/reports/dblog . Make sure that Drupal sends proper cache headers. To best test this, use the URL that Lagoon generates for bypassing the Varnish cache, (locally in our Drupal example this is http://nginx-drupal-example.docker.amazee.io ). Check for the Cache-Control: max-age=900, public header, where the 900 is what you configured in $config['system.performance']['cache']['page']['max_age'] . Make sure that the environment variable VARNISH_BYPASS is not set to true (see docker-compose.yml and run docker-compose up -d varnish to make sure the environment variable is configured correctly). If all fails, and before you flip your table (\u256f\u00b0\u25a1\u00b0\uff09\u256f\ufe35 \u253b\u2501\u253b, talk to the Lagoon team, we're happy to help.","title":"Troubleshooting"},{"location":"installing-lagoon/add-group/","text":"Add Group # lagoon add group -N groupname","title":"Add Group"},{"location":"installing-lagoon/add-group/#add-group","text":"lagoon add group -N groupname","title":"Add Group"},{"location":"installing-lagoon/add-project/","text":"Adding a Project # Add the project to Lagoon # Run this command: lagoon add project \\ --gitUrl <YOUR-GITHUB-REPO-URL> \\ --openshift 1 \\ --productionEnvironment <YOUR-PROD-ENV> \\ --branches <THE-BRANCHES-YOU-WANT-TO-DEPLOY> \\ --project <YOUR-PROJECT-NAME> The value for --openshift is the ID of your Kubernetes cluster. Your production environment should be the name of the branch you want to have as your production environment. The branches you want to deploy might look like this: \u201c^(main|develop)$\u201d The name of your project is anything you want - \u201cCompany Website,\u201d \u201cexample,\u201d etc. Go to the Lagoon UI, and you should see your project listed! Add the deploy key to your git repository # Lagoon creates a deploy key for each project. You now need to add it as a deploy key in your Git repository to allow Lagoon to download the code. Run the following command to get the deploy key: lagoon get project-key --project <YOUR-PROJECT-NAME> Copy the key and save it as a deploy key in your Git repository. GitHub GitLab Bitbucket Add the webhooks endpoint to your git repository # In order for Lagoon to be able to deploy on code updates, it needs to be connected to your git repository Add your Lagoon cluster's webhook endpoint to your git repository Payload URL: <LAGOON-WEBHOOK-INGRESS> Content Type: JSON Active: Active (allows you to enable/disable as required) Events: Select the relevant events, or choose All. Usually Push, Branch Create/Delete are required GitHub GitLab Bitbucket","title":"Add a Project"},{"location":"installing-lagoon/add-project/#adding-a-project","text":"","title":"Adding a Project"},{"location":"installing-lagoon/add-project/#add-the-project-to-lagoon","text":"Run this command: lagoon add project \\ --gitUrl <YOUR-GITHUB-REPO-URL> \\ --openshift 1 \\ --productionEnvironment <YOUR-PROD-ENV> \\ --branches <THE-BRANCHES-YOU-WANT-TO-DEPLOY> \\ --project <YOUR-PROJECT-NAME> The value for --openshift is the ID of your Kubernetes cluster. Your production environment should be the name of the branch you want to have as your production environment. The branches you want to deploy might look like this: \u201c^(main|develop)$\u201d The name of your project is anything you want - \u201cCompany Website,\u201d \u201cexample,\u201d etc. Go to the Lagoon UI, and you should see your project listed!","title":"Add the project to Lagoon"},{"location":"installing-lagoon/add-project/#add-the-deploy-key-to-your-git-repository","text":"Lagoon creates a deploy key for each project. You now need to add it as a deploy key in your Git repository to allow Lagoon to download the code. Run the following command to get the deploy key: lagoon get project-key --project <YOUR-PROJECT-NAME> Copy the key and save it as a deploy key in your Git repository. GitHub GitLab Bitbucket","title":"Add the deploy key to your git repository"},{"location":"installing-lagoon/add-project/#add-the-webhooks-endpoint-to-your-git-repository","text":"In order for Lagoon to be able to deploy on code updates, it needs to be connected to your git repository Add your Lagoon cluster's webhook endpoint to your git repository Payload URL: <LAGOON-WEBHOOK-INGRESS> Content Type: JSON Active: Active (allows you to enable/disable as required) Events: Select the relevant events, or choose All. Usually Push, Branch Create/Delete are required GitHub GitLab Bitbucket","title":"Add the webhooks endpoint to your git repository"},{"location":"installing-lagoon/create-user/","text":"Create Lagoon user # Add user via Lagoon CLI: lagoon add user --email user@example.com --firstName MyFirstName --lastName MyLastName Go to your email and click the password reset link in the email. Follow the instructions and log in to Lagoon UI with created password. Add the SSH public key of the user via Settings .","title":"Create Lagoon User"},{"location":"installing-lagoon/create-user/#create-lagoon-user","text":"Add user via Lagoon CLI: lagoon add user --email user@example.com --firstName MyFirstName --lastName MyLastName Go to your email and click the password reset link in the email. Follow the instructions and log in to Lagoon UI with created password. Add the SSH public key of the user via Settings .","title":"Create Lagoon user"},{"location":"installing-lagoon/deploy-project/","text":"Deploy Your Project # Run the following command to deploy your project: lagoon deploy branch -p <YOUR-PROJECT-NAME> -b <YOUR-BRANCH-NAME> Go to the Lagoon UI and take a look at your project - you should now see the environment for this project! Look in your cluster at your pods list, and you should see the build pod as it begins to clone Git repositories, set up services, etc. kubectl get pods --all-namespaces | grep lagoon-build","title":"Deploy Your Project"},{"location":"installing-lagoon/deploy-project/#deploy-your-project","text":"Run the following command to deploy your project: lagoon deploy branch -p <YOUR-PROJECT-NAME> -b <YOUR-BRANCH-NAME> Go to the Lagoon UI and take a look at your project - you should now see the environment for this project! Look in your cluster at your pods list, and you should see the build pod as it begins to clone Git repositories, set up services, etc. kubectl get pods --all-namespaces | grep lagoon-build","title":"Deploy Your Project"},{"location":"installing-lagoon/efs-provisioner/","text":"EFS Provisioner # Note: This is only applicable to AWS installations. Add Helm repository: helm repo add stable https://charts.helm.sh/stable Create efs-provisioner-values.yml in your config directory and update the values: efs-provisioner-values.yml efsProvisioner : efsFileSystemId : <efsFileSystemId> awsRegion : <awsRegion> path : / provisionerName : example.com/aws-efs storageClass : name : bulk isDefault : false reclaimPolicy : Delete mountOptions : [] global : deployEnv : prod Install EFS Provisioner: helm upgrade --install --create-namespace --namespace efs-provisioner -f efs-provisioner-values.yaml efs-provisioner stable/efs-provisioner","title":"EFS Provisioner"},{"location":"installing-lagoon/efs-provisioner/#efs-provisioner","text":"Note: This is only applicable to AWS installations. Add Helm repository: helm repo add stable https://charts.helm.sh/stable Create efs-provisioner-values.yml in your config directory and update the values: efs-provisioner-values.yml efsProvisioner : efsFileSystemId : <efsFileSystemId> awsRegion : <awsRegion> path : / provisionerName : example.com/aws-efs storageClass : name : bulk isDefault : false reclaimPolicy : Delete mountOptions : [] global : deployEnv : prod Install EFS Provisioner: helm upgrade --install --create-namespace --namespace efs-provisioner -f efs-provisioner-values.yaml efs-provisioner stable/efs-provisioner","title":"EFS Provisioner"},{"location":"installing-lagoon/gitlab/","text":"Gitlab # Not needed for *most* installs, but this is configured to integrate Lagoon with GitLab for user and group authentication. Create Personal Access token in GitLab for a User with Admin Access. Create System Hooks under `your-gitlab.com/admin/hooks` pointing to: webhookhandler.lagoon.example.com and define a random secret token. Enable \u201crepository update events\u201d Update lagoon-core-values.yaml : lagoon-core-values.yaml api : additionalEnvs : GITLAB_API_HOST : <<URL of Gitlab example : https://your-gitlab.com>> GITLAB_API_TOKEN : << Personal Access token with Access to API >> GITLAB_SYSTEM_HOOK_TOKEN : << System Hook Secret Token >> webhook-haondler : additionalEnvs : GITLAB_API_HOST : <<URL of Gitlab example : https://your-gitlab.com>> GITLAB_API_TOKEN : << Personal Access token with Access to API >> GITLAB_SYSTEM_HOOK_TOKEN : << System Hook Secret Token >> webhooks2tasks : additionalEnvs : GITLAB_API_HOST : <<URL of Gitlab example : https://your-gitlab.com>> GITLAB_API_TOKEN : << Personal Access token with Access to API >> GITLAB_SYSTEM_HOOK_TOKEN : << System Hook Secret Token >> Helm update the lagoon-core helmchart If you've already created users in Keycloak, delete them. Run the following command in an API pod yarn sync:gitlab:all","title":"GitLab"},{"location":"installing-lagoon/gitlab/#gitlab","text":"Not needed for *most* installs, but this is configured to integrate Lagoon with GitLab for user and group authentication. Create Personal Access token in GitLab for a User with Admin Access. Create System Hooks under `your-gitlab.com/admin/hooks` pointing to: webhookhandler.lagoon.example.com and define a random secret token. Enable \u201crepository update events\u201d Update lagoon-core-values.yaml : lagoon-core-values.yaml api : additionalEnvs : GITLAB_API_HOST : <<URL of Gitlab example : https://your-gitlab.com>> GITLAB_API_TOKEN : << Personal Access token with Access to API >> GITLAB_SYSTEM_HOOK_TOKEN : << System Hook Secret Token >> webhook-haondler : additionalEnvs : GITLAB_API_HOST : <<URL of Gitlab example : https://your-gitlab.com>> GITLAB_API_TOKEN : << Personal Access token with Access to API >> GITLAB_SYSTEM_HOOK_TOKEN : << System Hook Secret Token >> webhooks2tasks : additionalEnvs : GITLAB_API_HOST : <<URL of Gitlab example : https://your-gitlab.com>> GITLAB_API_TOKEN : << Personal Access token with Access to API >> GITLAB_SYSTEM_HOOK_TOKEN : << System Hook Secret Token >> Helm update the lagoon-core helmchart If you've already created users in Keycloak, delete them. Run the following command in an API pod yarn sync:gitlab:all","title":"Gitlab"},{"location":"installing-lagoon/install-harbor/","text":"Install Harbor # Add Helm repo: helm repo add harbor https://helm.goharbor.io Create the file harbor-values.yml inside of your config directory: harbor-values.yml expose : ingress : annotations : kubernetes.io/tls-acme : \"true\" hosts : core : harbor.lagoon.example.com tls : enabled : true certSource : secret secret : secretName : harbor-harbor-ingress externalURL : https://harbor.lagoon.example.com harborAdminPassword : <your Harbor Admin Password> chartmuseum : enabled : false clair : enabled : false notary : enabled : false trivy : enabled : false jobservice : jobLogger : stdout registry : replicas : 1 Install Harbor, checking the requirements for the currently supported Harbor versions.: helm upgrade --install --create-namespace \\ --namespace harbor --wait \\ -f harbor-values.yaml \\ harbor harbor/harbor Visit Harbor at the URL you set in harbor.yml . Username: admin Password: kubectl -n harbor get secret harbor-harbor-core -o jsonpath=\"{.data.HARBOR_ADMIN_PASSWORD}\" | base64 --decode You will need to add the above Harbor credentials to the Lagoon Remote values.yml in the next step, as well as harbor-values.yml .","title":"Install Harbor"},{"location":"installing-lagoon/install-harbor/#install-harbor","text":"Add Helm repo: helm repo add harbor https://helm.goharbor.io Create the file harbor-values.yml inside of your config directory: harbor-values.yml expose : ingress : annotations : kubernetes.io/tls-acme : \"true\" hosts : core : harbor.lagoon.example.com tls : enabled : true certSource : secret secret : secretName : harbor-harbor-ingress externalURL : https://harbor.lagoon.example.com harborAdminPassword : <your Harbor Admin Password> chartmuseum : enabled : false clair : enabled : false notary : enabled : false trivy : enabled : false jobservice : jobLogger : stdout registry : replicas : 1 Install Harbor, checking the requirements for the currently supported Harbor versions.: helm upgrade --install --create-namespace \\ --namespace harbor --wait \\ -f harbor-values.yaml \\ harbor harbor/harbor Visit Harbor at the URL you set in harbor.yml . Username: admin Password: kubectl -n harbor get secret harbor-harbor-core -o jsonpath=\"{.data.HARBOR_ADMIN_PASSWORD}\" | base64 --decode You will need to add the above Harbor credentials to the Lagoon Remote values.yml in the next step, as well as harbor-values.yml .","title":"Install Harbor"},{"location":"installing-lagoon/install-lagoon-remote/","text":"Install Lagoon Remote # Now we will install Lagoon Remote into the Lagoon namespace. The RabbitMQ service is the broker. Create lagoon-remote-values.yml in your config directory as you did the previous two files, and update the values. rabbitMQPassword kubectl -n lagoon-core get secret lagoon-core-broker -o jsonpath=\"{.data.RABBITMQ_PASSWORD}\" | base64 --decode rabbitMQHostname lagoon-core-broker.lagoon-core.svc.local taskSSHHost kubectl get service lagoon-core-broker-amqp-ext \\ -o custom-columns=\"NAME:.metadata.name,IP ADDRESS:.status.loadBalancer.ingress[*].ip,HOSTNAME:.status.loadBalancer.ingress[*].hostname\" harbor-password kubectl -n harbor get secret harbor-harbor-core -o jsonpath=\"{.data.HARBOR_ADMIN_PASSWORD}\" | base64 --decode Add the Harbor configuration from the Install Harbor step. lagoon-remote-values.yml lagoon-build-deploy : enabled : true extraArgs : - \"--enable-harbor=true\" - \"--harbor-url=https://harbor.lagoon.example.com\" - \"--harbor-api=https://harbor.lagoon.example.com/api/\" - \"--harbor-username=admin\" - \"--harbor-password=<from harbor-harbor-core secret>\" rabbitMQUsername : lagoon rabbitMQPassword : <from lagoon-core-broker secret> rabbitMQHostname : lagoon-core-broker.lagoon-core.svc.cluster.local lagoonTargetName : <name of lagoon remote, can be anything> taskSSHHost : <IP of ssh service loadbalancer> taskSSHPort : \"22\" taskAPIHost : \"api.lagoon.example.com\" dbaas-operator : enabled : true mariadbProviders : production : environment : production hostname : 172.17.0.1.nip.io readReplicaHostnames : - 172.17.0.1.nip.io password : password port : '3306' user : root development : environment : development hostname : 172.17.0.1.nip.io readReplicaHostnames : - 172.17.0.1.nip.io password : password port : '3306' user : root Install Harbor: helm upgrade --install --create-namespace \\ --namespace lagoon \\ -f remote-values.yaml lagoon-remote lagoon/lagoon-remote","title":"Install Lagoon Remote"},{"location":"installing-lagoon/install-lagoon-remote/#install-lagoon-remote","text":"Now we will install Lagoon Remote into the Lagoon namespace. The RabbitMQ service is the broker. Create lagoon-remote-values.yml in your config directory as you did the previous two files, and update the values. rabbitMQPassword kubectl -n lagoon-core get secret lagoon-core-broker -o jsonpath=\"{.data.RABBITMQ_PASSWORD}\" | base64 --decode rabbitMQHostname lagoon-core-broker.lagoon-core.svc.local taskSSHHost kubectl get service lagoon-core-broker-amqp-ext \\ -o custom-columns=\"NAME:.metadata.name,IP ADDRESS:.status.loadBalancer.ingress[*].ip,HOSTNAME:.status.loadBalancer.ingress[*].hostname\" harbor-password kubectl -n harbor get secret harbor-harbor-core -o jsonpath=\"{.data.HARBOR_ADMIN_PASSWORD}\" | base64 --decode Add the Harbor configuration from the Install Harbor step. lagoon-remote-values.yml lagoon-build-deploy : enabled : true extraArgs : - \"--enable-harbor=true\" - \"--harbor-url=https://harbor.lagoon.example.com\" - \"--harbor-api=https://harbor.lagoon.example.com/api/\" - \"--harbor-username=admin\" - \"--harbor-password=<from harbor-harbor-core secret>\" rabbitMQUsername : lagoon rabbitMQPassword : <from lagoon-core-broker secret> rabbitMQHostname : lagoon-core-broker.lagoon-core.svc.cluster.local lagoonTargetName : <name of lagoon remote, can be anything> taskSSHHost : <IP of ssh service loadbalancer> taskSSHPort : \"22\" taskAPIHost : \"api.lagoon.example.com\" dbaas-operator : enabled : true mariadbProviders : production : environment : production hostname : 172.17.0.1.nip.io readReplicaHostnames : - 172.17.0.1.nip.io password : password port : '3306' user : root development : environment : development hostname : 172.17.0.1.nip.io readReplicaHostnames : - 172.17.0.1.nip.io password : password port : '3306' user : root Install Harbor: helm upgrade --install --create-namespace \\ --namespace lagoon \\ -f remote-values.yaml lagoon-remote lagoon/lagoon-remote","title":"Install Lagoon Remote"},{"location":"installing-lagoon/lagoon-backups/","text":"Lagoon Backups # Lagoon uses the k8up backup operator: https://k8up.io . Lagoon isn\u2019t tightly integrated with k8up, it\u2019s more that Lagoon can create its resources in a way that k8up can automatically discover and backup. Lagoon has been extensively tested with k8up 1.x, but is not compatible with 2.x yet. We recommend using the 1.1.0 chart version (App version v1.2.0) Create new AWS User with policies: example K8up IAM user { \"Version\" : \"2012-10-17\" , \"Statement\" :[ { \"Sid\" : \"VisualEditor0\" , \"Effect\" : \"Allow\" , \"Action\" :[ \"s3:ListAllMyBuckets\" , \"s3:CreateBucket\" , \"s3:GetBucketLocation\" ], \"Resource\" : \"*\" }, { \"Sid\" : \"VisualEditor1\" , \"Effect\" : \"Allow\" , \"Action\" : \"s3:ListBucket\" , \"Resource\" : \"arn:aws:s3:::baas-*\" }, { \"Sid\" : \"VisualEditor2\" , \"Effect\" : \"Allow\" , \"Action\" :[ \"s3:PutObject\" , \"s3:GetObject\" , \"s3:AbortMultipartUpload\" , \"s3:DeleteObject\" , \"s3:ListMultipartUploadParts\" ], \"Resource\" : \"arn:aws:s3:::baas-*/*\" } ] } Create k8up-values.yaml (customise for your provider): k8up-values.yaml k8up : envVars : - name : BACKUP_GLOBALS3ENDPOINT value : 'https://s3.eu-west-1.amazonaws.com' - name : BACKUP_GLOBALS3BUCKET value : '' - name : BACKUP_GLOBALKEEPJOBS value : '1' - name : BACKUP_GLOBALSTATSURL value : 'https://backup.lagoon.example.com' - name : BACKUP_GLOBALACCESSKEYID value : '' - name : BACKUP_GLOBALSECRETACCESSKEY value : '' - name : BACKUP_BACKOFFLIMIT value : '2' - name : BACKUP_GLOBALRESTORES3BUCKET value : '' - name : BACKUP_GLOBALRESTORES3ENDPOINT value : 'https://s3.eu-west-1.amazonaws.com' - name : BACKUP_GLOBALRESTORES3ACCESSKEYID value : '' - name : BACKUP_GLOBALRESTORES3SECRETACCESSKEY value : '' timezone : Europe/Zurich Install k8up: helm repo add appuio https://charts.appuio.ch kubectl apply -f https://github.com/vshn/k8up/releases/download/v1.2.0/k8up-crd.yaml helm upgrade --install --create-namespace \\ --namespace k8up \\ -f k8up-values.yaml \\ --version 1.1.0 \\ k8up appuio/k8up Update lagoon-core-values.yaml : lagoon-core-values.yaml s3BAASAccessKeyID : <<Access Key ID for restore bucket>> s3BAASSecretAccessKey : <<Access Key Secret for restore bucket>> Redeploy lagoon-core .","title":"Lagoon Backups"},{"location":"installing-lagoon/lagoon-backups/#lagoon-backups","text":"Lagoon uses the k8up backup operator: https://k8up.io . Lagoon isn\u2019t tightly integrated with k8up, it\u2019s more that Lagoon can create its resources in a way that k8up can automatically discover and backup. Lagoon has been extensively tested with k8up 1.x, but is not compatible with 2.x yet. We recommend using the 1.1.0 chart version (App version v1.2.0) Create new AWS User with policies: example K8up IAM user { \"Version\" : \"2012-10-17\" , \"Statement\" :[ { \"Sid\" : \"VisualEditor0\" , \"Effect\" : \"Allow\" , \"Action\" :[ \"s3:ListAllMyBuckets\" , \"s3:CreateBucket\" , \"s3:GetBucketLocation\" ], \"Resource\" : \"*\" }, { \"Sid\" : \"VisualEditor1\" , \"Effect\" : \"Allow\" , \"Action\" : \"s3:ListBucket\" , \"Resource\" : \"arn:aws:s3:::baas-*\" }, { \"Sid\" : \"VisualEditor2\" , \"Effect\" : \"Allow\" , \"Action\" :[ \"s3:PutObject\" , \"s3:GetObject\" , \"s3:AbortMultipartUpload\" , \"s3:DeleteObject\" , \"s3:ListMultipartUploadParts\" ], \"Resource\" : \"arn:aws:s3:::baas-*/*\" } ] } Create k8up-values.yaml (customise for your provider): k8up-values.yaml k8up : envVars : - name : BACKUP_GLOBALS3ENDPOINT value : 'https://s3.eu-west-1.amazonaws.com' - name : BACKUP_GLOBALS3BUCKET value : '' - name : BACKUP_GLOBALKEEPJOBS value : '1' - name : BACKUP_GLOBALSTATSURL value : 'https://backup.lagoon.example.com' - name : BACKUP_GLOBALACCESSKEYID value : '' - name : BACKUP_GLOBALSECRETACCESSKEY value : '' - name : BACKUP_BACKOFFLIMIT value : '2' - name : BACKUP_GLOBALRESTORES3BUCKET value : '' - name : BACKUP_GLOBALRESTORES3ENDPOINT value : 'https://s3.eu-west-1.amazonaws.com' - name : BACKUP_GLOBALRESTORES3ACCESSKEYID value : '' - name : BACKUP_GLOBALRESTORES3SECRETACCESSKEY value : '' timezone : Europe/Zurich Install k8up: helm repo add appuio https://charts.appuio.ch kubectl apply -f https://github.com/vshn/k8up/releases/download/v1.2.0/k8up-crd.yaml helm upgrade --install --create-namespace \\ --namespace k8up \\ -f k8up-values.yaml \\ --version 1.1.0 \\ k8up appuio/k8up Update lagoon-core-values.yaml : lagoon-core-values.yaml s3BAASAccessKeyID : <<Access Key ID for restore bucket>> s3BAASSecretAccessKey : <<Access Key Secret for restore bucket>> Redeploy lagoon-core .","title":"Lagoon Backups"},{"location":"installing-lagoon/lagoon-cli/","text":"Install the Lagoon CLI # Install the Lagoon CLI on your local machine: Check https://github.com/uselagoon/lagoon-cli#install on how to install for your operating system. For macOS, you can use Homebrew: brew tap uselagoon/lagoon-cli brew install lagoon The CLI needs to know how to communicate with Lagoon, so run the following command: lagoon config add --graphql https://<YOUR-API-URL>/graphql --ui https://YOUR-UI-URL --hostname <YOUR.SSH.IP> --lagoon <YOUR-LAGOON-NAME> --port 22 Access Lagoon by authenticating with your SSH key. In the Lagoon UI (the URL is in values.yml if you forget), go to Settings . Add your public SSH key. You need to set the default Lagoon to your Lagoon so that it doesn\u2019t try to use the amazee.io defaults: lagoon config default --lagoon <YOUR-LAGOON-NAME> Now run lagoon login How the system works: Lagoon talks to SSH and authenticates against your public/private key pair, and gets a token for your username. Verify via lagoon whoami that you are logged in. Note: Note: We don\u2019t generally recommend using the Lagoon Admin role, but you\u2019ll need to create an admin account at first to get started. Ideally, you\u2019ll immediately create another account to work from which is not an admin.","title":"Install the Lagoon CLI"},{"location":"installing-lagoon/lagoon-cli/#install-the-lagoon-cli","text":"Install the Lagoon CLI on your local machine: Check https://github.com/uselagoon/lagoon-cli#install on how to install for your operating system. For macOS, you can use Homebrew: brew tap uselagoon/lagoon-cli brew install lagoon The CLI needs to know how to communicate with Lagoon, so run the following command: lagoon config add --graphql https://<YOUR-API-URL>/graphql --ui https://YOUR-UI-URL --hostname <YOUR.SSH.IP> --lagoon <YOUR-LAGOON-NAME> --port 22 Access Lagoon by authenticating with your SSH key. In the Lagoon UI (the URL is in values.yml if you forget), go to Settings . Add your public SSH key. You need to set the default Lagoon to your Lagoon so that it doesn\u2019t try to use the amazee.io defaults: lagoon config default --lagoon <YOUR-LAGOON-NAME> Now run lagoon login How the system works: Lagoon talks to SSH and authenticates against your public/private key pair, and gets a token for your username. Verify via lagoon whoami that you are logged in. Note: Note: We don\u2019t generally recommend using the Lagoon Admin role, but you\u2019ll need to create an admin account at first to get started. Ideally, you\u2019ll immediately create another account to work from which is not an admin.","title":"Install the Lagoon CLI"},{"location":"installing-lagoon/lagoon-core/","text":"Install Lagoon Core # Install the Helm chart # Add Lagoon Charts repository to your Helm Repos: helm repo add lagoon https://uselagoon.github.io/lagoon-charts/ Create a directory for the configuration files we will create, and make sure that it\u2019s version controlled. Ensure that you reference this path in commands referencing your values.yml files. Create values.yml in the directory you\u2019ve just created. Update the endpoint URLs (change them from api.lagoon.example.com to your values). Example: https://gist.github.com/Schnitzel/58e390bf1b6f93117a37a3eb02e8bae3 Now run helm upgrade --install command, pointing to values.yml , like so: helm upgrade --install --create-namespace --namespace lagoon-core -f values.yml lagoon-core lagoon/lagoon-core ` Lagoon Core is now installed! :tada: Warning: Note: Sometimes we run into Docker Hub pull limits. We are considering moving our images elsewhere if this continues to be a problem. Configure Keycloak # Visit the Keycloak dashboard at the URL you defined in the values.yml for Keycloak. Click Administration Console Username: admin Password: use lagoon-core-keycloak secret, key-value KEYCLOAK_ADMIN_PASSWORD Retrieve the secret like so:` kubectl -n lagoon-core get secret lagoon-core-keycloak -o jsonpath = \"{.data.KEYCLOAK_ADMIN_PASSWORD}\" | base64 --decode Click on User on top right. Go to Manage Account. Add an Email for the admin account you created. Save. Go to Realm Lagoon -> Realm Settings -> Email Configure email server for Keycloak, test connection via \u201cTest connection\u201d button. Go to Realm Lagoon -> Realm Settings -> Login Enable \u201cForgot Password\u201d Save. Log in to the UI # You should now be able to visit the Lagoon UI at the URL you defined in the values.yml for the UI. Username: lagoonadmin Secret: use lagoon-core-keycloak secret key-value: LAGOON-CORE-KEYCLOAK Retrieve the secret: kubectl -n lagoon-core get secret lagoon-core-keycloak -o jsonpath=\"{.data.KEYCLOAK_LAGOON_ADMIN_PASSWORD}\" | base64 --decode Note: Note: Currently Lagoon only supports one Lagoon per cluster - meaning you can\u2019t currently split your dev/test/prod environments across separate clusters, but this is something we are looking to implement in the future.","title":"Install Lagoon Core"},{"location":"installing-lagoon/lagoon-core/#install-lagoon-core","text":"","title":"Install Lagoon Core"},{"location":"installing-lagoon/lagoon-core/#install-the-helm-chart","text":"Add Lagoon Charts repository to your Helm Repos: helm repo add lagoon https://uselagoon.github.io/lagoon-charts/ Create a directory for the configuration files we will create, and make sure that it\u2019s version controlled. Ensure that you reference this path in commands referencing your values.yml files. Create values.yml in the directory you\u2019ve just created. Update the endpoint URLs (change them from api.lagoon.example.com to your values). Example: https://gist.github.com/Schnitzel/58e390bf1b6f93117a37a3eb02e8bae3 Now run helm upgrade --install command, pointing to values.yml , like so: helm upgrade --install --create-namespace --namespace lagoon-core -f values.yml lagoon-core lagoon/lagoon-core ` Lagoon Core is now installed! :tada: Warning: Note: Sometimes we run into Docker Hub pull limits. We are considering moving our images elsewhere if this continues to be a problem.","title":"Install the Helm chart"},{"location":"installing-lagoon/lagoon-core/#configure-keycloak","text":"Visit the Keycloak dashboard at the URL you defined in the values.yml for Keycloak. Click Administration Console Username: admin Password: use lagoon-core-keycloak secret, key-value KEYCLOAK_ADMIN_PASSWORD Retrieve the secret like so:` kubectl -n lagoon-core get secret lagoon-core-keycloak -o jsonpath = \"{.data.KEYCLOAK_ADMIN_PASSWORD}\" | base64 --decode Click on User on top right. Go to Manage Account. Add an Email for the admin account you created. Save. Go to Realm Lagoon -> Realm Settings -> Email Configure email server for Keycloak, test connection via \u201cTest connection\u201d button. Go to Realm Lagoon -> Realm Settings -> Login Enable \u201cForgot Password\u201d Save.","title":"Configure Keycloak"},{"location":"installing-lagoon/lagoon-core/#log-in-to-the-ui","text":"You should now be able to visit the Lagoon UI at the URL you defined in the values.yml for the UI. Username: lagoonadmin Secret: use lagoon-core-keycloak secret key-value: LAGOON-CORE-KEYCLOAK Retrieve the secret: kubectl -n lagoon-core get secret lagoon-core-keycloak -o jsonpath=\"{.data.KEYCLOAK_LAGOON_ADMIN_PASSWORD}\" | base64 --decode Note: Note: Currently Lagoon only supports one Lagoon per cluster - meaning you can\u2019t currently split your dev/test/prod environments across separate clusters, but this is something we are looking to implement in the future.","title":"Log in to the UI"},{"location":"installing-lagoon/lagoon-files/","text":"Lagoon Files # Lagoon files are used to store the file output of tasks, such as backups, and can be hosted on any S3-compatible storage. Create new AWS User with policies: example files IAM user { \"Version\" : \"2012-10-17\" , \"Statement\" :[ { \"Effect\" : \"Allow\" , \"Action\" :[ \"s3:ListBucket\" , \"s3:GetBucketLocation\" , \"s3:ListBucketMultipartUploads\" ], \"Resource\" : \"arn:aws:s3:::S3_BUCKET_NAME\" }, { \"Effect\" : \"Allow\" , \"Action\" :[ \"s3:PutObject\" , \"s3:GetObject\" , \"s3:DeleteObject\" , \"s3:ListMultipartUploadParts\" , \"s3:AbortMultipartUpload\" ], \"Resource\" : \"arn:aws:s3:::S3_BUCKET_NAME/*\" } ] } Update lagoon-core-values.yaml : lagoon-core-values.yaml s3FilesAccessKeyID : <<Access Key ID>> s3FilesBucket : <<Bucket Name for Lagoon Files>> s3FilesHost : <<S3 endpoint like \"https://s3.eu-west-1.amazonaws.com\" >> s3FilesSecretAccessKey : <<Access Key Secret>> s3FilesRegion : <<S3 Region >> If you use ingress-nginx in front of lagoon-core , we suggest setting this configuration which will allow for bigger file uploads: lagoon-core-values.yaml controller : config : client-body-timeout : '600' # max 600 secs fileuploads proxy-send-timeout : '1800' # max 30min connections - needed for websockets proxy-read-timeout : '1800' # max 30min connections - needed for websockets proxy-body-size : 1024m # 1GB file size proxy-buffer-size : 64k # bigger buffer","title":"Lagoon Files"},{"location":"installing-lagoon/lagoon-files/#lagoon-files","text":"Lagoon files are used to store the file output of tasks, such as backups, and can be hosted on any S3-compatible storage. Create new AWS User with policies: example files IAM user { \"Version\" : \"2012-10-17\" , \"Statement\" :[ { \"Effect\" : \"Allow\" , \"Action\" :[ \"s3:ListBucket\" , \"s3:GetBucketLocation\" , \"s3:ListBucketMultipartUploads\" ], \"Resource\" : \"arn:aws:s3:::S3_BUCKET_NAME\" }, { \"Effect\" : \"Allow\" , \"Action\" :[ \"s3:PutObject\" , \"s3:GetObject\" , \"s3:DeleteObject\" , \"s3:ListMultipartUploadParts\" , \"s3:AbortMultipartUpload\" ], \"Resource\" : \"arn:aws:s3:::S3_BUCKET_NAME/*\" } ] } Update lagoon-core-values.yaml : lagoon-core-values.yaml s3FilesAccessKeyID : <<Access Key ID>> s3FilesBucket : <<Bucket Name for Lagoon Files>> s3FilesHost : <<S3 endpoint like \"https://s3.eu-west-1.amazonaws.com\" >> s3FilesSecretAccessKey : <<Access Key Secret>> s3FilesRegion : <<S3 Region >> If you use ingress-nginx in front of lagoon-core , we suggest setting this configuration which will allow for bigger file uploads: lagoon-core-values.yaml controller : config : client-body-timeout : '600' # max 600 secs fileuploads proxy-send-timeout : '1800' # max 30min connections - needed for websockets proxy-read-timeout : '1800' # max 30min connections - needed for websockets proxy-body-size : 1024m # 1GB file size proxy-buffer-size : 64k # bigger buffer","title":"Lagoon Files"},{"location":"installing-lagoon/lagoon-logging/","text":"Lagoon Logging # Lagoon integrates with OpenSearch to store application, container and router logs. Lagoon Logging collects the application, router and container logs from Lagoon projects, and sends them to the logs concentrator. It needs to be installed onto each lagoon-remote instance. In addition, it should be installed in the lagoon-core cluster to collect logs from the lagoon-core service. This is configured in the LagoonLogs section. Logging Overview: https://lucid.app/lucidchart/b1da011f-2b91-4798-9518-4164b19d327d/view See also: Logging . Read more about Lagoon logging here: https://github.com/uselagoon/lagoon-charts/tree/main/charts/lagoon-logging Create lagoon-logging-values.yaml : lagoon-logging-values.yaml tls : caCert : | << content of ca.pem from Logs-Concentrator>> clientCert : | << content of client.pem from Logs-Concentrator>> clientKey : | << content of client-key.pem from Logs-Concentrator>> forward : username : <<Username for Lagoon Remote 1>> password : <<Password for Lagoon Remote 1>> host : <<ExternalIP of Logs-Concentrator Service LoadBalancer>> hostName : <<Hostname in Server Cert of Logs-Concentrator>> hostPort : '24224' selfHostname : <<Hostname in Client Cert of Logs-Concentrator>> sharedKey : <<Generated ForwardSharedKey of Logs-Concentrator>> tlsVerifyHostname : false clusterName : <<Short Cluster Identifier>> logsDispatcher : serviceMonitor : enabled : false logging-operator : monitoring : serviceMonitor : enabled : false lagoonLogs : enabled : true rabbitMQHost : lagoon-core-broker.lagoon-core.svc.cluster.local rabbitMQUser : lagoon rabbitMQPassword : <<RabbitMQ Lagoon Password>> excludeNamespaces : {} Install lagoon-logging : helm repo add banzaicloud-stable https://kubernetes-charts.banzaicloud.com helm upgrade --install --create-namespace \\ --namespace lagoon-logging \\ -f lagoon-logging-values.yaml \\ lagoon-logging lagoon/lagoon-logging Logging NGINX Ingress Controller # If you'd like logs from ingress-nginx inside lagoon-logging : The ingress controller must be installed in the namespace ingress-nginx Add the content of this file to `ingress-nginx: ingress-nginx log-format-upstream controller : config : log-format-upstream : >- { \"time\": \"$time_iso8601\", \"remote_addr\": \"$remote_addr\", \"x-forwarded-for\": \"$http_x_forwarded_for\", \"true-client-ip\": \"$http_true_client_ip\", \"req_id\": \"$req_id\", \"remote_user\": \"$remote_user\", \"bytes_sent\": $bytes_sent, \"request_time\": $request_time, \"status\": \"$status\", \"host\": \"$host\", \"request_proto\": \"$server_protocol\", \"request_uri\": \"$uri\", \"request_query\": \"$args\", \"request_length\": $request_length, \"request_time\": $request_time, \"request_method\": \"$request_method\", \"http_referer\": \"$http_referer\", \"http_user_agent\": \"$http_user_agent\", \"namespace\": \"$namespace\", \"ingress_name\": \"$ingress_name\", \"service_name\": \"$service_name\", \"service_port\": \"$service_port\" }","title":"Lagoon Logging"},{"location":"installing-lagoon/lagoon-logging/#lagoon-logging","text":"Lagoon integrates with OpenSearch to store application, container and router logs. Lagoon Logging collects the application, router and container logs from Lagoon projects, and sends them to the logs concentrator. It needs to be installed onto each lagoon-remote instance. In addition, it should be installed in the lagoon-core cluster to collect logs from the lagoon-core service. This is configured in the LagoonLogs section. Logging Overview: https://lucid.app/lucidchart/b1da011f-2b91-4798-9518-4164b19d327d/view See also: Logging . Read more about Lagoon logging here: https://github.com/uselagoon/lagoon-charts/tree/main/charts/lagoon-logging Create lagoon-logging-values.yaml : lagoon-logging-values.yaml tls : caCert : | << content of ca.pem from Logs-Concentrator>> clientCert : | << content of client.pem from Logs-Concentrator>> clientKey : | << content of client-key.pem from Logs-Concentrator>> forward : username : <<Username for Lagoon Remote 1>> password : <<Password for Lagoon Remote 1>> host : <<ExternalIP of Logs-Concentrator Service LoadBalancer>> hostName : <<Hostname in Server Cert of Logs-Concentrator>> hostPort : '24224' selfHostname : <<Hostname in Client Cert of Logs-Concentrator>> sharedKey : <<Generated ForwardSharedKey of Logs-Concentrator>> tlsVerifyHostname : false clusterName : <<Short Cluster Identifier>> logsDispatcher : serviceMonitor : enabled : false logging-operator : monitoring : serviceMonitor : enabled : false lagoonLogs : enabled : true rabbitMQHost : lagoon-core-broker.lagoon-core.svc.cluster.local rabbitMQUser : lagoon rabbitMQPassword : <<RabbitMQ Lagoon Password>> excludeNamespaces : {} Install lagoon-logging : helm repo add banzaicloud-stable https://kubernetes-charts.banzaicloud.com helm upgrade --install --create-namespace \\ --namespace lagoon-logging \\ -f lagoon-logging-values.yaml \\ lagoon-logging lagoon/lagoon-logging","title":"Lagoon Logging"},{"location":"installing-lagoon/lagoon-logging/#logging-nginx-ingress-controller","text":"If you'd like logs from ingress-nginx inside lagoon-logging : The ingress controller must be installed in the namespace ingress-nginx Add the content of this file to `ingress-nginx: ingress-nginx log-format-upstream controller : config : log-format-upstream : >- { \"time\": \"$time_iso8601\", \"remote_addr\": \"$remote_addr\", \"x-forwarded-for\": \"$http_x_forwarded_for\", \"true-client-ip\": \"$http_true_client_ip\", \"req_id\": \"$req_id\", \"remote_user\": \"$remote_user\", \"bytes_sent\": $bytes_sent, \"request_time\": $request_time, \"status\": \"$status\", \"host\": \"$host\", \"request_proto\": \"$server_protocol\", \"request_uri\": \"$uri\", \"request_query\": \"$args\", \"request_length\": $request_length, \"request_time\": $request_time, \"request_method\": \"$request_method\", \"http_referer\": \"$http_referer\", \"http_user_agent\": \"$http_user_agent\", \"namespace\": \"$namespace\", \"ingress_name\": \"$ingress_name\", \"service_name\": \"$service_name\", \"service_port\": \"$service_port\" }","title":"Logging NGINX Ingress Controller"},{"location":"installing-lagoon/logs-concentrator/","text":"Logs-Concentrator # Logs-concentrator collects the logs being sent by Lagoon clusters and augments them with additional metadata before inserting them into Elasticsearch. Create certificates according to ReadMe: https://github.com/uselagoon/lagoon-charts/tree/main/charts/lagoon-logs-concentrator Create logs-concentrator-values.yaml : logs-concentrator-values.yaml tls : caCert : | <<contents of ca.pem>> serverCert : | <<contents of server.pem serverKey : | <<contents of server-key.pem>> elasticsearchHost : elasticsearch-opendistro-es-client-service.elasticsearch.svc.cluster.local elasticsearchAdminPassword : <<ElasticSearch Admin Password>> forwardSharedKey : <<Random 32 Character Password>> users : - username : <<Username for Lagoon Remote 1>> password : <<Random Password for Lagoon Remote 1>> service : type : LoadBalancer serviceMonitor : enabled : false Install logs-concentrator: helm upgrade --install --create-namespace \\ --namespace lagoon-logs-concentrator \\ -f logs-concentrator-values.yaml \\ lagoon-logs-concentrator lagoon/lagoon-logs-concentrator","title":"Logs Concentrator"},{"location":"installing-lagoon/logs-concentrator/#logs-concentrator","text":"Logs-concentrator collects the logs being sent by Lagoon clusters and augments them with additional metadata before inserting them into Elasticsearch. Create certificates according to ReadMe: https://github.com/uselagoon/lagoon-charts/tree/main/charts/lagoon-logs-concentrator Create logs-concentrator-values.yaml : logs-concentrator-values.yaml tls : caCert : | <<contents of ca.pem>> serverCert : | <<contents of server.pem serverKey : | <<contents of server-key.pem>> elasticsearchHost : elasticsearch-opendistro-es-client-service.elasticsearch.svc.cluster.local elasticsearchAdminPassword : <<ElasticSearch Admin Password>> forwardSharedKey : <<Random 32 Character Password>> users : - username : <<Username for Lagoon Remote 1>> password : <<Random Password for Lagoon Remote 1>> service : type : LoadBalancer serviceMonitor : enabled : false Install logs-concentrator: helm upgrade --install --create-namespace \\ --namespace lagoon-logs-concentrator \\ -f logs-concentrator-values.yaml \\ lagoon-logs-concentrator lagoon/lagoon-logs-concentrator","title":"Logs-Concentrator"},{"location":"installing-lagoon/opendistro/","text":"OpenDistro # To install an OpenDistro cluster, you will need to configure TLS and secrets so that Lagoon can talk to it securely. You're going to have to create a handful of JSON files - put these in the same directory as the values files you've been creating throughout this installation process. Install OpenDistro Helm, according to https://opendistro.github.io/for-elasticsearch-docs/docs/install/helm/ Generate certificates Install CFSSL: https://github.com/cloudflare/cfssl CFSSL is CloudFlare's PKI/TLS swiss army knife. It is both a command line tool and an HTTP API server for signing, verifying, and bundling TLS certificates. It requires Go 1.12+ to build. 2. Generate CA. You'll need the following file: ca-csr.json { \"CN\" : \"ca.elasticsearch.svc.cluster.local\" , \"hosts\" : [ \"ca.elasticsearch.svc.cluster.local\" ], \"key\" : { \"algo\" : \"ecdsa\" , \"size\" : 256 }, \"ca\" : { \"expiry\" : \"87600h\" } } Run the following two commands: cfssl gencert -initca ca-csr.json | cfssljson -bare ca - rm ca.csr You'll get ca-key.pem , and ca.pem . This is your CA key and self-signed certificate. Next, we'll generate the node peering certificate. You'll need the following two files: ca-config.json { \"signing\" : { \"default\" : { \"expiry\" : \"87600h\" }, \"profiles\" : { \"peer\" : { \"expiry\" : \"87600h\" , \"usages\" : [ \"signing\" , \"key encipherment\" , \"server auth\" , \"client auth\" ] }, \"client\" : { \"expiry\" : \"87600h\" , \"usages\" : [ \"signing\" , \"key encipherment\" , \"client auth\" ] } } } } node.json { \"hosts\" : [ \"node.elasticsearch.svc.cluster.local\" ], \"CN\" : \"node.elasticsearch.svc.cluster.local\" , \"key\" : { \"algo\" : \"ecdsa\" , \"size\" : 256 } } Run the following two commands: cfssl gencert -ca = ca.pem -ca-key = ca-key.pem -config = ca-config.json -profile = peer node.json | cfssljson -bare node rm node.csr You'll get node.pem and node-key.pem . This is the peer certificate that will be used by nodes in the ES cluster. Next, we'll convert the key to the format supported by Java with the following command: openssl pkey -in node-key.pem -out node-key.pkcs8 Now we'll generate the admin certificate. You'll need the following file: admin.json { \"CN\" : \"admin.elasticsearch.svc.cluster.local\" , \"key\" : { \"algo\" : \"ecdsa\" , \"size\" : 256 } } Run the following two commands: cfssl gencert -ca = ca.pem -ca-key = ca-key.pem -config = ca-config.json -profile = client admin.json | cfssljson -bare admin rm admin.csr You'll get admin.pem and admin-key.pem . This is the certificate that will be used to perform admin commands on the opendistro-security plugin. Next, we'll convert the key to the format supported by Java with the following command: openssl pkey -in admin-key.pem -out admin-key.pkcs8 Now that we have our keys and certificates, we can continue with the installation. Generate hashed passwords The elasticsearch-secrets-values.yaml needs two hashed passwords. Create them with this command (run it twice, enter a random password, store both the plaintext and hashed passwords). docker run --rm -it docker.io/amazon/opendistro-for-elasticsearch:1.12.0 sh -c \"chmod +x /usr/share/elasticsearch/plugins/opendistro_security/tools/hash.sh; /usr/share/elasticsearch/plugins/opendistro_security/tools/hash.sh\" Create secrets: You'll need to create elasticsearch-secrets-values.yaml . See this gist as an example: https://gist.github.com/Schnitzel/43f483dfe0b23ca0dddd939b12bb4b0b Install secrets with the following commands: helm repo add incubator https://charts.helm.sh/incubator helm upgrade --namespace elasticsearch --create-namespace --install elasticsearch-secrets incubator/raw --values elasticsearch-secrets-values.yaml 4. You'll need to create elasticsearch-values.yaml . See this gist as an example: (fill all <\\ > with values) https://gist.github.com/Schnitzel/1e386654b6abf75bf4d66a544db4aa6a 5. Install Elasticsearch: helm upgrade --namespace elasticsearch --create-namespace --install elasticsearch opendistro-es-X.Y.Z.tgz --values elasticsearch-values.yaml 6. Configure security inside Elasticsearch with the following: kubectl exec -n elasticsearch -it elasticsearch-opendistro-es-master-0 -- bash chmod +x /usr/share/elasticsearch/plugins/opendistro_security/tools/securityadmin.sh /usr/share/elasticsearch/plugins/opendistro_security/tools/securityadmin.sh -nhnv -cacert /usr/share/elasticsearch/config/admin-root-ca.pem -cert /usr/share/elasticsearch/config/admin-crt.pem -key /usr/share/elasticsearch/config/admin-key.pem -cd /usr/share/elasticsearch/plugins/opendistro_security/securityconfig/ 7. Update lagoon-core-values.yaml with: lagoon-core-values.yaml elasticsearchURL : http://elasticsearch-opendistro-es-client-service.elasticsearch.svc.cluster.local:9200 kibanaURL : https://<<Kibana Public URL>> logsDBAdminPassword : \"<<PlainText Elasticsearch Admin Password>>\" Rollout Lagoon Core: helm upgrade --install --create-namespace --namespace lagoon-core -f values.yaml lagoon-core lagoon/lagoon-core Sync all Lagoon Groups with Opendistro Elasticsearch kubectl -n lagoon-core exec -it deploy/lagoon-core-api -- sh yarn run sync:opendistro-security","title":"OpenDistro"},{"location":"installing-lagoon/opendistro/#opendistro","text":"To install an OpenDistro cluster, you will need to configure TLS and secrets so that Lagoon can talk to it securely. You're going to have to create a handful of JSON files - put these in the same directory as the values files you've been creating throughout this installation process. Install OpenDistro Helm, according to https://opendistro.github.io/for-elasticsearch-docs/docs/install/helm/ Generate certificates Install CFSSL: https://github.com/cloudflare/cfssl CFSSL is CloudFlare's PKI/TLS swiss army knife. It is both a command line tool and an HTTP API server for signing, verifying, and bundling TLS certificates. It requires Go 1.12+ to build. 2. Generate CA. You'll need the following file: ca-csr.json { \"CN\" : \"ca.elasticsearch.svc.cluster.local\" , \"hosts\" : [ \"ca.elasticsearch.svc.cluster.local\" ], \"key\" : { \"algo\" : \"ecdsa\" , \"size\" : 256 }, \"ca\" : { \"expiry\" : \"87600h\" } } Run the following two commands: cfssl gencert -initca ca-csr.json | cfssljson -bare ca - rm ca.csr You'll get ca-key.pem , and ca.pem . This is your CA key and self-signed certificate. Next, we'll generate the node peering certificate. You'll need the following two files: ca-config.json { \"signing\" : { \"default\" : { \"expiry\" : \"87600h\" }, \"profiles\" : { \"peer\" : { \"expiry\" : \"87600h\" , \"usages\" : [ \"signing\" , \"key encipherment\" , \"server auth\" , \"client auth\" ] }, \"client\" : { \"expiry\" : \"87600h\" , \"usages\" : [ \"signing\" , \"key encipherment\" , \"client auth\" ] } } } } node.json { \"hosts\" : [ \"node.elasticsearch.svc.cluster.local\" ], \"CN\" : \"node.elasticsearch.svc.cluster.local\" , \"key\" : { \"algo\" : \"ecdsa\" , \"size\" : 256 } } Run the following two commands: cfssl gencert -ca = ca.pem -ca-key = ca-key.pem -config = ca-config.json -profile = peer node.json | cfssljson -bare node rm node.csr You'll get node.pem and node-key.pem . This is the peer certificate that will be used by nodes in the ES cluster. Next, we'll convert the key to the format supported by Java with the following command: openssl pkey -in node-key.pem -out node-key.pkcs8 Now we'll generate the admin certificate. You'll need the following file: admin.json { \"CN\" : \"admin.elasticsearch.svc.cluster.local\" , \"key\" : { \"algo\" : \"ecdsa\" , \"size\" : 256 } } Run the following two commands: cfssl gencert -ca = ca.pem -ca-key = ca-key.pem -config = ca-config.json -profile = client admin.json | cfssljson -bare admin rm admin.csr You'll get admin.pem and admin-key.pem . This is the certificate that will be used to perform admin commands on the opendistro-security plugin. Next, we'll convert the key to the format supported by Java with the following command: openssl pkey -in admin-key.pem -out admin-key.pkcs8 Now that we have our keys and certificates, we can continue with the installation. Generate hashed passwords The elasticsearch-secrets-values.yaml needs two hashed passwords. Create them with this command (run it twice, enter a random password, store both the plaintext and hashed passwords). docker run --rm -it docker.io/amazon/opendistro-for-elasticsearch:1.12.0 sh -c \"chmod +x /usr/share/elasticsearch/plugins/opendistro_security/tools/hash.sh; /usr/share/elasticsearch/plugins/opendistro_security/tools/hash.sh\" Create secrets: You'll need to create elasticsearch-secrets-values.yaml . See this gist as an example: https://gist.github.com/Schnitzel/43f483dfe0b23ca0dddd939b12bb4b0b Install secrets with the following commands: helm repo add incubator https://charts.helm.sh/incubator helm upgrade --namespace elasticsearch --create-namespace --install elasticsearch-secrets incubator/raw --values elasticsearch-secrets-values.yaml 4. You'll need to create elasticsearch-values.yaml . See this gist as an example: (fill all <\\ > with values) https://gist.github.com/Schnitzel/1e386654b6abf75bf4d66a544db4aa6a 5. Install Elasticsearch: helm upgrade --namespace elasticsearch --create-namespace --install elasticsearch opendistro-es-X.Y.Z.tgz --values elasticsearch-values.yaml 6. Configure security inside Elasticsearch with the following: kubectl exec -n elasticsearch -it elasticsearch-opendistro-es-master-0 -- bash chmod +x /usr/share/elasticsearch/plugins/opendistro_security/tools/securityadmin.sh /usr/share/elasticsearch/plugins/opendistro_security/tools/securityadmin.sh -nhnv -cacert /usr/share/elasticsearch/config/admin-root-ca.pem -cert /usr/share/elasticsearch/config/admin-crt.pem -key /usr/share/elasticsearch/config/admin-key.pem -cd /usr/share/elasticsearch/plugins/opendistro_security/securityconfig/ 7. Update lagoon-core-values.yaml with: lagoon-core-values.yaml elasticsearchURL : http://elasticsearch-opendistro-es-client-service.elasticsearch.svc.cluster.local:9200 kibanaURL : https://<<Kibana Public URL>> logsDBAdminPassword : \"<<PlainText Elasticsearch Admin Password>>\" Rollout Lagoon Core: helm upgrade --install --create-namespace --namespace lagoon-core -f values.yaml lagoon-core lagoon/lagoon-core Sync all Lagoon Groups with Opendistro Elasticsearch kubectl -n lagoon-core exec -it deploy/lagoon-core-api -- sh yarn run sync:opendistro-security","title":"OpenDistro"},{"location":"installing-lagoon/querying-graphql/","text":"Querying with GraphQL # You\u2019ll need an app for sending and receiving GraphQL queries. We recommend GraphiQL. If you\u2019re using Homebrew, you can install it with brew install --cask graphiql . We need to tell Lagoon Core about the Kubernetes cluster. The GraphQL endpoint is: https://<YOUR-API-URL>/graphql Go to Edit HTTP Headers , and Add Header . Header Name: Authorization Value: Bearer YOUR-TOKEN-HERE In your home directory, the Lagoon CLI has created a .lagoon.yml file. Copy the token from that file and use it for the value here. Save. Now you\u2019re ready to run some queries. Run the following test query to ensure everything is working correctly: query allProjects {allProjects {name } } This should give you the following response: { \"data\": { \"allProjects\": [] } } Read more about GraphQL here in our documentation. Once you get the correct response, we need to add a mutation. Run the following query: mutation addKubernetes { addKubernetes(input: { name: \"<TARGET-NAME-FROM-REMOTE-VALUES.yml>\", consoleUrl: \"<URL-OF-K8S-CLUSTER>\", token: \"xxxxxx\u201d routerPattern: \"${environment}.${project}.lagoon.example.com\" }){id} } consoleUrl: API Endpoint of Kubernetes Cluster token: kubectl -n lagoon describe secret $(kubectl -n lagoon get secret | grep kubernetes-build-deploy | awk '{print $1}') | grep token: | awk '{print $2}' Note: Note: Authorization tokens for GraphQL are very short term so you may need to generate a new one. Run lagoon login and then cat the .lagoon.yml file to get the new token, and replace the old token in the HTTP header with the new one.","title":"Querying with GraphQL"},{"location":"installing-lagoon/querying-graphql/#querying-with-graphql","text":"You\u2019ll need an app for sending and receiving GraphQL queries. We recommend GraphiQL. If you\u2019re using Homebrew, you can install it with brew install --cask graphiql . We need to tell Lagoon Core about the Kubernetes cluster. The GraphQL endpoint is: https://<YOUR-API-URL>/graphql Go to Edit HTTP Headers , and Add Header . Header Name: Authorization Value: Bearer YOUR-TOKEN-HERE In your home directory, the Lagoon CLI has created a .lagoon.yml file. Copy the token from that file and use it for the value here. Save. Now you\u2019re ready to run some queries. Run the following test query to ensure everything is working correctly: query allProjects {allProjects {name } } This should give you the following response: { \"data\": { \"allProjects\": [] } } Read more about GraphQL here in our documentation. Once you get the correct response, we need to add a mutation. Run the following query: mutation addKubernetes { addKubernetes(input: { name: \"<TARGET-NAME-FROM-REMOTE-VALUES.yml>\", consoleUrl: \"<URL-OF-K8S-CLUSTER>\", token: \"xxxxxx\u201d routerPattern: \"${environment}.${project}.lagoon.example.com\" }){id} } consoleUrl: API Endpoint of Kubernetes Cluster token: kubectl -n lagoon describe secret $(kubectl -n lagoon get secret | grep kubernetes-build-deploy | awk '{print $1}') | grep token: | awk '{print $2}' Note: Note: Authorization tokens for GraphQL are very short term so you may need to generate a new one. Run lagoon login and then cat the .lagoon.yml file to get the new token, and replace the old token in the HTTP header with the new one.","title":"Querying with GraphQL"},{"location":"installing-lagoon/requirements/","text":"Installing Lagoon Into Existing Kubernetes Cluster # Requirements # Kubernetes 1.22+ (Kubernetes 1.19 is supported, but 1.22 is recommended) Familiarity with Helm and Helm Charts , and kubectl . Ingress controller, we recommend ingress-nginx , installed into ingress-nginx namespace Cert manager (for TLS) - We highly recommend using letsencrypt StorageClasses (RWO as default, RWM for persistent types) Note: We acknowledge that this is a lot of steps, and our roadmap for the immediate future includes reducing the number of steps in this process. Specific requirements (as of March 2022) # Kubernetes # Lagoon supports Kubernetes versions 1.19 onwards. We actively test and develop against Kubernetes 1.23, also regularly testing against 1.21,1.22 and 1.24. The next round of breaking changes is in Kubernetes 1.25 , and we will endeavour to be across these in advance. ingress-nginx # Lagoon is currently configured only for a single ingress-nginx controller, and therefore defining an IngressClass has not been necessary. In order to use the recent ingress-nginx controllers (v4 onwards, required for Kubernetes 1.22), the following configuration should be used, as per the ingress-nginx docs . nginx-ingress should be configured as the default controller - set .controller.ingressClassResource.default: true in Helm values nginx-ingress should be configured to watch ingresses without IngressClass set - set .controller.watchIngressWithoutClass: true in Helm values This will configure the controller to create any new ingresses with itself as the IngressClass, and also to handle any existing ingresses without an IngressClass set. Other configurations may be possible, but have not been tested. Harbor # Versions 2.1 and 2.2+ of Harbor are currently supported - the method of retrieving robot accounts was changed in 2.2, and the Lagoon remote-controller is able to handle these tokens. This means that Harbor has to be configured with the credentials in lagoon-build-deploy - not lagoon-core. We recommend installing a Harbor version greater than 2.5.0 with Helm chart 1.9.0 or greater. K8up for backups # Lagoon has built in configuration for the K8up backup operator. Lagoon can configure prebackup pods, schedules and retentions, and manage backups and restores for K8up. Lagoon currently only supports the 1.x versions of K8up, owing to a namespace change in v2 onwards, but we are working on a fix. We recommend installing K8up version 1.2.0 with helm chart 1.1.0 Storage provisioners # Lagoon utilises a default 'standard' StorageClass for most workloads, and the internal provisioner for most Kubernetes platforms will suffice. This should be configured to be dynamic provisioning and expandable where possible. Lagoon also requires a storageClass called 'bulk' to be available to support persistant pod replicas (across nodes). This storageClass should support ReadWriteMany access mode and should be configured to be dynamic provisioning and expandable where possible. See https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes for more information. We have curently only included the instructions for (the now deprecated) EFS Provisioner , but most CSI drivers should also work, as will configurations with an NFS-compatible server and provisioner. How much Kubernetes experience/knowledge is required? # Lagoon uses some very involved Kubernetes and Cloud Native concepts, and while full familiarity may not be necessary to install and configure Lagoon, diagnosing issues and contributing may prove difficult without a good level of familiarity. As an indicator, comfort with the curriculum for the Certified Kubernetes Administrator would be suggested as a minimum.","title":"Requirements"},{"location":"installing-lagoon/requirements/#installing-lagoon-into-existing-kubernetes-cluster","text":"","title":"Installing Lagoon Into Existing Kubernetes Cluster"},{"location":"installing-lagoon/requirements/#requirements","text":"Kubernetes 1.22+ (Kubernetes 1.19 is supported, but 1.22 is recommended) Familiarity with Helm and Helm Charts , and kubectl . Ingress controller, we recommend ingress-nginx , installed into ingress-nginx namespace Cert manager (for TLS) - We highly recommend using letsencrypt StorageClasses (RWO as default, RWM for persistent types) Note: We acknowledge that this is a lot of steps, and our roadmap for the immediate future includes reducing the number of steps in this process.","title":"Requirements"},{"location":"installing-lagoon/requirements/#specific-requirements-as-of-march-2022","text":"","title":"Specific requirements (as of March 2022)"},{"location":"installing-lagoon/requirements/#kubernetes","text":"Lagoon supports Kubernetes versions 1.19 onwards. We actively test and develop against Kubernetes 1.23, also regularly testing against 1.21,1.22 and 1.24. The next round of breaking changes is in Kubernetes 1.25 , and we will endeavour to be across these in advance.","title":"Kubernetes"},{"location":"installing-lagoon/requirements/#ingress-nginx","text":"Lagoon is currently configured only for a single ingress-nginx controller, and therefore defining an IngressClass has not been necessary. In order to use the recent ingress-nginx controllers (v4 onwards, required for Kubernetes 1.22), the following configuration should be used, as per the ingress-nginx docs . nginx-ingress should be configured as the default controller - set .controller.ingressClassResource.default: true in Helm values nginx-ingress should be configured to watch ingresses without IngressClass set - set .controller.watchIngressWithoutClass: true in Helm values This will configure the controller to create any new ingresses with itself as the IngressClass, and also to handle any existing ingresses without an IngressClass set. Other configurations may be possible, but have not been tested.","title":"ingress-nginx"},{"location":"installing-lagoon/requirements/#harbor","text":"Versions 2.1 and 2.2+ of Harbor are currently supported - the method of retrieving robot accounts was changed in 2.2, and the Lagoon remote-controller is able to handle these tokens. This means that Harbor has to be configured with the credentials in lagoon-build-deploy - not lagoon-core. We recommend installing a Harbor version greater than 2.5.0 with Helm chart 1.9.0 or greater.","title":"Harbor"},{"location":"installing-lagoon/requirements/#k8up-for-backups","text":"Lagoon has built in configuration for the K8up backup operator. Lagoon can configure prebackup pods, schedules and retentions, and manage backups and restores for K8up. Lagoon currently only supports the 1.x versions of K8up, owing to a namespace change in v2 onwards, but we are working on a fix. We recommend installing K8up version 1.2.0 with helm chart 1.1.0","title":"K8up for backups"},{"location":"installing-lagoon/requirements/#storage-provisioners","text":"Lagoon utilises a default 'standard' StorageClass for most workloads, and the internal provisioner for most Kubernetes platforms will suffice. This should be configured to be dynamic provisioning and expandable where possible. Lagoon also requires a storageClass called 'bulk' to be available to support persistant pod replicas (across nodes). This storageClass should support ReadWriteMany access mode and should be configured to be dynamic provisioning and expandable where possible. See https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes for more information. We have curently only included the instructions for (the now deprecated) EFS Provisioner , but most CSI drivers should also work, as will configurations with an NFS-compatible server and provisioner.","title":"Storage provisioners"},{"location":"installing-lagoon/requirements/#how-much-kubernetes-experienceknowledge-is-required","text":"Lagoon uses some very involved Kubernetes and Cloud Native concepts, and while full familiarity may not be necessary to install and configure Lagoon, diagnosing issues and contributing may prove difficult without a good level of familiarity. As an indicator, comfort with the curriculum for the Certified Kubernetes Administrator would be suggested as a minimum.","title":"How much Kubernetes experience/knowledge is required?"},{"location":"installing-lagoon/update-lagoon/","text":"Updating # Download newest charts using helm helm repo update Check with helm diff for changes https://github.com/databus23/helm-diff . helm diff upgrade --install --create-namespace --namespace lagoon-core \\ -f values.yaml lagoon-core lagoon/lagoon-core Run the upgrade using helm helm upgrade --install --create-namespace --namespace lagoon-core \\ -f values.yaml lagoon-core lagoon/lagoon-core If upgrading Lagoon Core, ensure you run the rerun_initdb.sh script to perform post upgrade migrations kubectl --namespace lagoon-core exec -it lagoon-core-api-db-0 -- \\ sh -c /rerun_initdb.sh If upgrading Lagoon Core, and you have enabled groups/user syncing for OpenSearch, you may additionally need to run the sync:opendistro-security script to update the groups in OpenSearch. This command can also be prefixed with a GROUP_REGEX=<group-to-sync to sync a single group at a time, as syncing the entire group structure may take a long time. kubectl --namespace lagoon-core exec -it deploy/lagoon-core-api -- \\ sh -c yarn sync:opendistro-security Check https://github.com/uselagoon/lagoon/releases for additional upgrades. Database Backups # You may want to backup the databases before upgrading Lagoon Core, the following will create backups you can use to restore from if required. You can delete them afterwards. API DB # kubectl --namespace lagoon-core exec -it lagoon-core-api-db-0 -- \\ sh -c 'mysqldump --max-allowed-packet=500M --events \\ --routines --quick --add-locks --no-autocommit \\ --single-transaction infrastructure | gzip -9 > \\ /var/lib/mysql/backup/$(date +%Y-%m-%d_%H%M%S).infrastructure.sql.gz' Keycloak DB # kubectl --namespace lagoon-core exec -it lagoon-core-keycloak-db-0 -- \\ sh -c 'mysqldump --max-allowed-packet=500M --events \\ --routines --quick --add-locks --no-autocommit \\ --single-transaction keycloak | gzip -9 > \\ /var/lib/mysql/backup/$(date +%Y-%m-%d_%H%M%S).keycloak.sql.gz'","title":"Updating"},{"location":"installing-lagoon/update-lagoon/#updating","text":"Download newest charts using helm helm repo update Check with helm diff for changes https://github.com/databus23/helm-diff . helm diff upgrade --install --create-namespace --namespace lagoon-core \\ -f values.yaml lagoon-core lagoon/lagoon-core Run the upgrade using helm helm upgrade --install --create-namespace --namespace lagoon-core \\ -f values.yaml lagoon-core lagoon/lagoon-core If upgrading Lagoon Core, ensure you run the rerun_initdb.sh script to perform post upgrade migrations kubectl --namespace lagoon-core exec -it lagoon-core-api-db-0 -- \\ sh -c /rerun_initdb.sh If upgrading Lagoon Core, and you have enabled groups/user syncing for OpenSearch, you may additionally need to run the sync:opendistro-security script to update the groups in OpenSearch. This command can also be prefixed with a GROUP_REGEX=<group-to-sync to sync a single group at a time, as syncing the entire group structure may take a long time. kubectl --namespace lagoon-core exec -it deploy/lagoon-core-api -- \\ sh -c yarn sync:opendistro-security Check https://github.com/uselagoon/lagoon/releases for additional upgrades.","title":"Updating"},{"location":"installing-lagoon/update-lagoon/#database-backups","text":"You may want to backup the databases before upgrading Lagoon Core, the following will create backups you can use to restore from if required. You can delete them afterwards.","title":"Database Backups"},{"location":"installing-lagoon/update-lagoon/#api-db","text":"kubectl --namespace lagoon-core exec -it lagoon-core-api-db-0 -- \\ sh -c 'mysqldump --max-allowed-packet=500M --events \\ --routines --quick --add-locks --no-autocommit \\ --single-transaction infrastructure | gzip -9 > \\ /var/lib/mysql/backup/$(date +%Y-%m-%d_%H%M%S).infrastructure.sql.gz'","title":"API DB"},{"location":"installing-lagoon/update-lagoon/#keycloak-db","text":"kubectl --namespace lagoon-core exec -it lagoon-core-keycloak-db-0 -- \\ sh -c 'mysqldump --max-allowed-packet=500M --events \\ --routines --quick --add-locks --no-autocommit \\ --single-transaction keycloak | gzip -9 > \\ /var/lib/mysql/backup/$(date +%Y-%m-%d_%H%M%S).keycloak.sql.gz'","title":"Keycloak DB"},{"location":"logging/kibana-examples/","text":"Kibana Examples # Have you seen the Kibana getting started video and are now ready to work with logs? We are here to help! This page will give you examples of Kibana queries you can use. This is not a Kibana 101 class, but it can help you understand some of what you can do in Kibana. Ready to get started? Good! Note: Make sure that you have selected your tenant before starting! You can do that by on the Tenant icon on the left-hand menu. Once you have selected your tenant, click on the Discover icon again to get started. Router Logs # Below you'll find examples for two common log requests: Viewing the total number of hits/requests to your site. Viewing the number of hits/requests from a specific IP address. Total Number of hits/requests to your site # Let's start Kibana up and select Discovery (#1 in screen shot below) Then the router logs for your project(#2). From there, we will filter some of this information down a bit. Let's focus on our main production environment. In the search bar (#3), enter: openshift_project: \"name of your production project\" This will show you all the hits to your production environment in the given time frame. You can change the time frame in the upper right hand corner (#4). Clicking on the arrow next to the entry (#5) will expand it and show you all the information that was captured. You can add any of those fields to the window by hovering over them and clicking add on the left hand side (#6). You can also further filter your results by using the search bar. Number of hits/requests from a specific IP address # Running the query above will give you a general look at all the traffic to your site, but what if you want to narrow in on a specific IP address? Perhaps you want to see how many times an IP has hit your site and what specific pages they were looking at. This next query should help. We are going to start off with the same query as above, but we are going to add a couple of things. First, add the following fields: client_ip and http_request . This will show you a list of all IP addresses and the page they requested. Here is what we see for the Amazee.io page: That looks good, but what if we wanted to just show requests from a specific IP address? You can filter for the address by adding it to your search criteria. We are going to add: AND client_ip: \"IP address\" . That will filter the results to just show you hits from that specific IP address, and the page they were requesting. Here is what it looks like for our Amazee.io website: Container Logs # Container logs will show you all stout and sterr messages for your specific container and project. We are going to show an example for getting logs from a specific container and finding specific error numbers in that container. Logs from a container # Want to see the logs for a specific container (php, nginx, etc)? This section will help! Let's focus on looking at Nginx logs. We start by opening up Kibana and selecting Discover (#1 in the screen shot below). From there, we select the container logs for our project (#2). Let's go to the search bar (#3) and enter: kubernetes.container_name: \"nginx\" This will display all Nginx logs for our project. Clicking on the arrow next to an entry (#4) will expand that entry and show you all of the information it gathered. Let's add the message field and the level field to the view. You can do that by clicking on \"Add\" on the left hand side (#5). You can change the time frame in the upper right hand corner of the screen (#6), in the example below I'm looking at logs for the last 4 hours. Specific errors in logs # Want to see how many 500 Internal Server errors you've had in your Nginx container? You can do that by changing the search query. If you search: kubernetes.container_name: \"nginx\" AND message: \"500\" That will only display 500 error messages in the Nginx container. You can search for any error message in any container that you would like! Visualization # Kibana will also give you the option to create visualizations or graphs. We are going to create a chart to show number of hits/requests in a month using the same query we used above. Click on Visualize on the left hand side of Kibana. Click on the blue plus sign. For this example, we are going to select a Vertical Bar chart. Select the router logs for your project. Click on X-Axis under Buckets and select Date Histogram, with the interval set to daily Success!! You should now see a nice bar graph showing your daily traffic. Note: Make sure that you select an appropriate time frame for the data in the upper right hand corner. Here is an example of a daily hits visualization chart: Also note that you can save your visualizations (and searches)! That will make it even faster to access them in the future. And because each account has their own Kibana Tenant, no searches or visualizations are shared with another account. Troubleshooting #","title":"Kibana Examples"},{"location":"logging/kibana-examples/#kibana-examples","text":"Have you seen the Kibana getting started video and are now ready to work with logs? We are here to help! This page will give you examples of Kibana queries you can use. This is not a Kibana 101 class, but it can help you understand some of what you can do in Kibana. Ready to get started? Good! Note: Make sure that you have selected your tenant before starting! You can do that by on the Tenant icon on the left-hand menu. Once you have selected your tenant, click on the Discover icon again to get started.","title":"Kibana Examples"},{"location":"logging/kibana-examples/#router-logs","text":"Below you'll find examples for two common log requests: Viewing the total number of hits/requests to your site. Viewing the number of hits/requests from a specific IP address.","title":"Router Logs"},{"location":"logging/kibana-examples/#total-number-of-hitsrequests-to-your-site","text":"Let's start Kibana up and select Discovery (#1 in screen shot below) Then the router logs for your project(#2). From there, we will filter some of this information down a bit. Let's focus on our main production environment. In the search bar (#3), enter: openshift_project: \"name of your production project\" This will show you all the hits to your production environment in the given time frame. You can change the time frame in the upper right hand corner (#4). Clicking on the arrow next to the entry (#5) will expand it and show you all the information that was captured. You can add any of those fields to the window by hovering over them and clicking add on the left hand side (#6). You can also further filter your results by using the search bar.","title":"Total Number of hits/requests to your site"},{"location":"logging/kibana-examples/#number-of-hitsrequests-from-a-specific-ip-address","text":"Running the query above will give you a general look at all the traffic to your site, but what if you want to narrow in on a specific IP address? Perhaps you want to see how many times an IP has hit your site and what specific pages they were looking at. This next query should help. We are going to start off with the same query as above, but we are going to add a couple of things. First, add the following fields: client_ip and http_request . This will show you a list of all IP addresses and the page they requested. Here is what we see for the Amazee.io page: That looks good, but what if we wanted to just show requests from a specific IP address? You can filter for the address by adding it to your search criteria. We are going to add: AND client_ip: \"IP address\" . That will filter the results to just show you hits from that specific IP address, and the page they were requesting. Here is what it looks like for our Amazee.io website:","title":"Number of hits/requests from a specific IP address"},{"location":"logging/kibana-examples/#container-logs","text":"Container logs will show you all stout and sterr messages for your specific container and project. We are going to show an example for getting logs from a specific container and finding specific error numbers in that container.","title":"Container Logs"},{"location":"logging/kibana-examples/#logs-from-a-container","text":"Want to see the logs for a specific container (php, nginx, etc)? This section will help! Let's focus on looking at Nginx logs. We start by opening up Kibana and selecting Discover (#1 in the screen shot below). From there, we select the container logs for our project (#2). Let's go to the search bar (#3) and enter: kubernetes.container_name: \"nginx\" This will display all Nginx logs for our project. Clicking on the arrow next to an entry (#4) will expand that entry and show you all of the information it gathered. Let's add the message field and the level field to the view. You can do that by clicking on \"Add\" on the left hand side (#5). You can change the time frame in the upper right hand corner of the screen (#6), in the example below I'm looking at logs for the last 4 hours.","title":"Logs from a container"},{"location":"logging/kibana-examples/#specific-errors-in-logs","text":"Want to see how many 500 Internal Server errors you've had in your Nginx container? You can do that by changing the search query. If you search: kubernetes.container_name: \"nginx\" AND message: \"500\" That will only display 500 error messages in the Nginx container. You can search for any error message in any container that you would like!","title":"Specific errors in logs"},{"location":"logging/kibana-examples/#visualization","text":"Kibana will also give you the option to create visualizations or graphs. We are going to create a chart to show number of hits/requests in a month using the same query we used above. Click on Visualize on the left hand side of Kibana. Click on the blue plus sign. For this example, we are going to select a Vertical Bar chart. Select the router logs for your project. Click on X-Axis under Buckets and select Date Histogram, with the interval set to daily Success!! You should now see a nice bar graph showing your daily traffic. Note: Make sure that you select an appropriate time frame for the data in the upper right hand corner. Here is an example of a daily hits visualization chart: Also note that you can save your visualizations (and searches)! That will make it even faster to access them in the future. And because each account has their own Kibana Tenant, no searches or visualizations are shared with another account.","title":"Visualization"},{"location":"logging/kibana-examples/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"logging/logging/","text":"Logging # Lagoon provides access to the following logs via Kibana: Logs from the Kubernetes Routers, including every single HTTP and HTTPS request with: Source IP URL Path HTTP verb Cookies Headers User agent Project Container name Response size Response time Logs from containers: stdout and stderr messages Container name Project Lagoon logs: Webhooks parsing Build logs Build errors Any other Lagoon related logs Application logs: For Drupal: install the Lagoon Logs module in order to receive logs from Drupal Watchdog. For Laravel: install the Lagoon Logs for Laravel package. For other workloads: Send logs to udp://application-logs.lagoon.svc:5140 Ensure logs are structured as JSON encoded objects. Ensure the type field contains the name of the Kubernetes namespace ( $LAGOON_PROJECT-$LAGOON_ENVIRONMENT ). To access the logs, please check with your Lagoon administrator to get the URL for the Kibana route (for amazee.io this is https://logs.amazeeio.cloud/ ). Each Lagoon user account has their own login and will see the logs only for the projects to which they have access. Each Lagoon user account also has their own Kibana Tenant , which means no saved searches or visualizations are shared with another account. If you would like to know more about how to use Kibana: https://www.elastic.co/webinars/getting-started-kibana .","title":"Logging"},{"location":"logging/logging/#logging","text":"Lagoon provides access to the following logs via Kibana: Logs from the Kubernetes Routers, including every single HTTP and HTTPS request with: Source IP URL Path HTTP verb Cookies Headers User agent Project Container name Response size Response time Logs from containers: stdout and stderr messages Container name Project Lagoon logs: Webhooks parsing Build logs Build errors Any other Lagoon related logs Application logs: For Drupal: install the Lagoon Logs module in order to receive logs from Drupal Watchdog. For Laravel: install the Lagoon Logs for Laravel package. For other workloads: Send logs to udp://application-logs.lagoon.svc:5140 Ensure logs are structured as JSON encoded objects. Ensure the type field contains the name of the Kubernetes namespace ( $LAGOON_PROJECT-$LAGOON_ENVIRONMENT ). To access the logs, please check with your Lagoon administrator to get the URL for the Kibana route (for amazee.io this is https://logs.amazeeio.cloud/ ). Each Lagoon user account has their own login and will see the logs only for the projects to which they have access. Each Lagoon user account also has their own Kibana Tenant , which means no saved searches or visualizations are shared with another account. If you would like to know more about how to use Kibana: https://www.elastic.co/webinars/getting-started-kibana .","title":"Logging"},{"location":"resources/faq/","text":"FAQ # How do I contact my Lagoon administrator? # You should have either a private RocketChat or Slack channel that was set up for you to communicate - if not, or you've forgotten how to contact us, reach out at support@amazee.io . I found a bug! \ud83d\udc1e # If you've found a bug or security issue, please send your findings to support@amazee.io . Please DO NOT file a GitHub issue for them. I'm interested in amazee.io's hosting services with Lagoon! # That's great news! You can contact them via email at inquiries@amazee.io . How can I restore a backup? # We have backups available for files and databases, typically taken every 24 hours at most. These backups are stored offsite. We keep up to 7 daily backups and 4 weekly backups. If you ever need to recover or restore a backup feel free to submit a ticket or send us a message via chat and we will be more than happy to help! How can I download a database dump? # I'm getting an invalid SSL certificate error # The first thing to try is what is listed in our documentation about SSL . If you follow those steps, and you are still seeing an error, please submit a ticket or send us a message on chat and we can help resolve this for you. I'm getting an \"Array\" error when running a drush command # This was a bug that was prevalent in drush versions 8.1.16 and 8.1.17. There error would look something like this: The command could not be executed successfully (returned: Array [error] ( [default] => Array ( [default] => Array ( [driver] => mysql [prefix] => Array ( [default] => ) , code: 0) Error: no database record could be found for source @main [error] Upgrading Drush should fix that for you. We strongly suggest that you use version 8.3 or newer. Once Drush is upgraded the command should work! I'm seeing an Internal Server Error when trying to access my Kibana logs! # No need to panic! This usually happens when a tenant has not been selected. To fix this, follow these steps: Go to \"Tenants\" on the left-hand menu of Kibana. Click on your tenant name. You'll see a pop-up window that says: \"Tenant Change\" and the name of your tenant. Go back to the \"Discover\" tab and attempt your query again. You should now be able to see your logs. I'm unable to SSH into any environment # I'm unable to SSH into any environment. I'm getting the following message: Permission denied (publickey) . When I run drush sa no aliases are returned. This typically indicates an issue with Pygmy. You can find our troubleshooting docs for Pygmy here: https://pygmy.readthedocs.io/en/master/troubleshooting/ How can I check the status of a build # How do I add a cron job? # How do I add a new route? # How do I remove a route? # You will need to contact your helpful Lagoon administrator should you need to remove a route. You can use either the private RocketChat or Slack channel that was set up for you to communicate - if not, you can always reach us at support@amazee.io. When I run pygmy status , no keys are loaded # You'll need to load your SSH key into pygmy. Here's how: https://pygmy.readthedocs.io/en/master/ssh_agent When I run drush sa no aliases are returned # This typically indicates an issue with Pygmy. You can find our troubleshooting docs for Pygmy here: https://pygmy.readthedocs.io/en/master/troubleshooting My deployments fail with a message saying: \"drush needs a more functional environment\" # This usually means that there is no database uploaded to the project. Follow our step-by-step guide to add a database to your project . When I start pygmy I see an \"address already in use\" error? # Error starting userland proxy: listen tcp 0.0.0.0:80: bind: address already in use Error: failed to start containers: amazeeio-haproxy This is a known error! Most of the time it means that there is already something running on port 80. You can find the culprit by running the following query: netstat -ltnp | grep -w ':80' That should list everything running on port 80. Kill the process running on port 80. Once port 80 is freed up, pygmy should start up with no further errors. How can I change branches/PR environments/production on my project? # You can make that change using the Lagoon API! You can find the documentation for this change in our GraphQL documentation . How do I add a redirect? # How can I add new users (and SSH keys) to my project/group? # This can be done via the Lagoon API. You can find the steps documentation for this change in our GraphQL documentation . Can an environment be completely deleted to roll out large code changes to my project? # Environments are fully built from scratch at each deploy, dropping the old database and files and pushing your code would result in a fresh clean build, Don\u2019t forget to re-sync! It is possible to delete an environment via GraphQL. You can find the instructions in our GraphQL documentation . How do I get my new environment variable to show up? # Once you've added a runtime environment variable to your production environment via GraphQL, then all you need to do a deploy in order to get your change to show up on your environment. How do I SFTP files to/from my Lagoon environment? # For cloud hosting customers, you can SFTP to your Lagoon environment by using the following information: Server Hostname: ssh.lagoon.amazeeio.cloud Port: 32222 Username: <Project-Environment-Name> Your username is going to be the name of the environment you are connecting to, most commonly in the pattern PROJECTNAME-ENVIRONMENT . You may also be interested in checking out our new Lagoon Sync tool, which you can read about here: https://github.com/uselagoon/lagoon-sync Authentication also happens automatically via SSH Public & Private Key Authentication. I don't want to use Let's Encrypt. I have an SSL certificate I would like to install # We can definitely help with that. Once you have your own SSL certificate, feel free to submit a ticket or send us a message via chat and we will be more than happy to help! You will need to send us the following files: Certificate key (.key) Certificate file (.crt) Intermediate certificates (.crt) Also, you will need to set the tls-acme option in .lagoon.yml to false . Is it possible to mount an external volume (EFS/Fuse/SMB/etc) into Lagoon? # Mounting an external volume would need to be handled completely inside of your containers, Lagoon does not provide a provision for this type of connection as part of the platform. A developer can handle this by installing the necessary packages into the container (via the Dockerfile ), and ensuring the volume mount is connected via a pre- or post-rollout task . Is there a way to stop a Lagoon build? # If you have a build that has been running for a long time, and want to stop it, you will need to reach out to support. Currently, builds can only be stopped by users with admin access to the cluster. We installed the Elasticsearch\\Solr service on our website. How can we get access to the UI (port 9200/8983) from a browser? # We suggest only exposing web services (NGINX/Varnish/Node.js) in your deployed environments. Locally, you can get the ports mapped for these services by checking docker-compose ps , and then load http://localhost :<port> in your browser. I have a question that isn't answered here # You can reach out to the team via Discord or email at uselagoon@amazee.io .","title":"FAQ"},{"location":"resources/faq/#faq","text":"","title":"FAQ"},{"location":"resources/faq/#how-do-i-contact-my-lagoon-administrator","text":"You should have either a private RocketChat or Slack channel that was set up for you to communicate - if not, or you've forgotten how to contact us, reach out at support@amazee.io .","title":"How do I contact my Lagoon administrator?"},{"location":"resources/faq/#i-found-a-bug","text":"If you've found a bug or security issue, please send your findings to support@amazee.io . Please DO NOT file a GitHub issue for them.","title":"I found a bug! \ud83d\udc1e"},{"location":"resources/faq/#im-interested-in-amazeeios-hosting-services-with-lagoon","text":"That's great news! You can contact them via email at inquiries@amazee.io .","title":"I'm interested in amazee.io's hosting services with Lagoon!"},{"location":"resources/faq/#how-can-i-restore-a-backup","text":"We have backups available for files and databases, typically taken every 24 hours at most. These backups are stored offsite. We keep up to 7 daily backups and 4 weekly backups. If you ever need to recover or restore a backup feel free to submit a ticket or send us a message via chat and we will be more than happy to help!","title":"How can I restore a backup?"},{"location":"resources/faq/#how-can-i-download-a-database-dump","text":"","title":"How can I download a database dump?"},{"location":"resources/faq/#im-getting-an-invalid-ssl-certificate-error","text":"The first thing to try is what is listed in our documentation about SSL . If you follow those steps, and you are still seeing an error, please submit a ticket or send us a message on chat and we can help resolve this for you.","title":"I'm getting an invalid SSL certificate error"},{"location":"resources/faq/#im-getting-an-array-error-when-running-a-drush-command","text":"This was a bug that was prevalent in drush versions 8.1.16 and 8.1.17. There error would look something like this: The command could not be executed successfully (returned: Array [error] ( [default] => Array ( [default] => Array ( [driver] => mysql [prefix] => Array ( [default] => ) , code: 0) Error: no database record could be found for source @main [error] Upgrading Drush should fix that for you. We strongly suggest that you use version 8.3 or newer. Once Drush is upgraded the command should work!","title":"I'm getting an \"Array\" error when running a drush command"},{"location":"resources/faq/#im-seeing-an-internal-server-error-when-trying-to-access-my-kibana-logs","text":"No need to panic! This usually happens when a tenant has not been selected. To fix this, follow these steps: Go to \"Tenants\" on the left-hand menu of Kibana. Click on your tenant name. You'll see a pop-up window that says: \"Tenant Change\" and the name of your tenant. Go back to the \"Discover\" tab and attempt your query again. You should now be able to see your logs.","title":"I'm seeing an Internal Server Error when trying to access my Kibana logs!"},{"location":"resources/faq/#im-unable-to-ssh-into-any-environment","text":"I'm unable to SSH into any environment. I'm getting the following message: Permission denied (publickey) . When I run drush sa no aliases are returned. This typically indicates an issue with Pygmy. You can find our troubleshooting docs for Pygmy here: https://pygmy.readthedocs.io/en/master/troubleshooting/","title":"I'm unable to SSH into any environment"},{"location":"resources/faq/#how-can-i-check-the-status-of-a-build","text":"","title":"How can I check the status of a build"},{"location":"resources/faq/#how-do-i-add-a-cron-job","text":"","title":"How do I add a cron job?"},{"location":"resources/faq/#how-do-i-add-a-new-route","text":"","title":"How do I add a new route?"},{"location":"resources/faq/#how-do-i-remove-a-route","text":"You will need to contact your helpful Lagoon administrator should you need to remove a route. You can use either the private RocketChat or Slack channel that was set up for you to communicate - if not, you can always reach us at support@amazee.io.","title":"How do I remove a route?"},{"location":"resources/faq/#when-i-run-pygmy-status-no-keys-are-loaded","text":"You'll need to load your SSH key into pygmy. Here's how: https://pygmy.readthedocs.io/en/master/ssh_agent","title":"When I run pygmy status, no keys are loaded"},{"location":"resources/faq/#when-i-run-drush-sa-no-aliases-are-returned","text":"This typically indicates an issue with Pygmy. You can find our troubleshooting docs for Pygmy here: https://pygmy.readthedocs.io/en/master/troubleshooting","title":"When I run drush sa no aliases are returned"},{"location":"resources/faq/#my-deployments-fail-with-a-message-saying-drush-needs-a-more-functional-environment","text":"This usually means that there is no database uploaded to the project. Follow our step-by-step guide to add a database to your project .","title":"My deployments fail with a message saying: \"drush needs a more functional environment\""},{"location":"resources/faq/#when-i-start-pygmy-i-see-an-address-already-in-use-error","text":"Error starting userland proxy: listen tcp 0.0.0.0:80: bind: address already in use Error: failed to start containers: amazeeio-haproxy This is a known error! Most of the time it means that there is already something running on port 80. You can find the culprit by running the following query: netstat -ltnp | grep -w ':80' That should list everything running on port 80. Kill the process running on port 80. Once port 80 is freed up, pygmy should start up with no further errors.","title":"When I start pygmy I see an \"address already in use\" error?"},{"location":"resources/faq/#how-can-i-change-branchespr-environmentsproduction-on-my-project","text":"You can make that change using the Lagoon API! You can find the documentation for this change in our GraphQL documentation .","title":"How can I change branches/PR environments/production on my project?"},{"location":"resources/faq/#how-do-i-add-a-redirect","text":"","title":"How do I add a redirect?"},{"location":"resources/faq/#how-can-i-add-new-users-and-ssh-keys-to-my-projectgroup","text":"This can be done via the Lagoon API. You can find the steps documentation for this change in our GraphQL documentation .","title":"How can I add new users (and SSH keys) to my project/group?"},{"location":"resources/faq/#can-an-environment-be-completely-deleted-to-roll-out-large-code-changes-to-my-project","text":"Environments are fully built from scratch at each deploy, dropping the old database and files and pushing your code would result in a fresh clean build, Don\u2019t forget to re-sync! It is possible to delete an environment via GraphQL. You can find the instructions in our GraphQL documentation .","title":"Can an environment be completely deleted to roll out large code changes to my project?"},{"location":"resources/faq/#how-do-i-get-my-new-environment-variable-to-show-up","text":"Once you've added a runtime environment variable to your production environment via GraphQL, then all you need to do a deploy in order to get your change to show up on your environment.","title":"How do I get my new environment variable to show up?"},{"location":"resources/faq/#how-do-i-sftp-files-tofrom-my-lagoon-environment","text":"For cloud hosting customers, you can SFTP to your Lagoon environment by using the following information: Server Hostname: ssh.lagoon.amazeeio.cloud Port: 32222 Username: <Project-Environment-Name> Your username is going to be the name of the environment you are connecting to, most commonly in the pattern PROJECTNAME-ENVIRONMENT . You may also be interested in checking out our new Lagoon Sync tool, which you can read about here: https://github.com/uselagoon/lagoon-sync Authentication also happens automatically via SSH Public & Private Key Authentication.","title":"How do I SFTP files to/from my Lagoon environment?"},{"location":"resources/faq/#i-dont-want-to-use-lets-encrypt-i-have-an-ssl-certificate-i-would-like-to-install","text":"We can definitely help with that. Once you have your own SSL certificate, feel free to submit a ticket or send us a message via chat and we will be more than happy to help! You will need to send us the following files: Certificate key (.key) Certificate file (.crt) Intermediate certificates (.crt) Also, you will need to set the tls-acme option in .lagoon.yml to false .","title":"I don't want to use Let's Encrypt. I have an SSL certificate I would like to install"},{"location":"resources/faq/#is-it-possible-to-mount-an-external-volume-efsfusesmbetc-into-lagoon","text":"Mounting an external volume would need to be handled completely inside of your containers, Lagoon does not provide a provision for this type of connection as part of the platform. A developer can handle this by installing the necessary packages into the container (via the Dockerfile ), and ensuring the volume mount is connected via a pre- or post-rollout task .","title":"Is it possible to mount an external volume (EFS/Fuse/SMB/etc) into Lagoon?"},{"location":"resources/faq/#is-there-a-way-to-stop-a-lagoon-build","text":"If you have a build that has been running for a long time, and want to stop it, you will need to reach out to support. Currently, builds can only be stopped by users with admin access to the cluster.","title":"Is there a way to stop a Lagoon build?"},{"location":"resources/faq/#we-installed-the-elasticsearchsolr-service-on-our-website-how-can-we-get-access-to-the-ui-port-92008983-from-a-browser","text":"We suggest only exposing web services (NGINX/Varnish/Node.js) in your deployed environments. Locally, you can get the ports mapped for these services by checking docker-compose ps , and then load http://localhost :<port> in your browser.","title":"We installed the Elasticsearch\\Solr service on our website. How can we get access to the UI (port 9200/8983) from a browser?"},{"location":"resources/faq/#i-have-a-question-that-isnt-answered-here","text":"You can reach out to the team via Discord or email at uselagoon@amazee.io .","title":"I have a question that isn't answered here"},{"location":"resources/glossary/","text":"Glossary # Term Definition AWS Amazon Web Services AWS Glacier A secure and inexpensive S3 storage for long-term backup. CI Continuous Integration CLI Command Line Interface Cluster A unified group of servers or VMs, distributed and managed together, which serves one entity to ensure high availability, load balancing, and scalability. CMS Content Management System Composer A package manager DDoS Distributed Denial of Service DNS Domain Name System Docker A container engine using Linux features and automating application deployment. Drupal Open-source Content Management System Drush EC2 Amazon Elastic Compute Cloud Elasticsearch An open-source search engine. It provides a distributed, multi-tenant-capable full-text search engine with a web interface and schema-free JSON documents. Galera A generic synchronous multi-master replication library for transactional databases. Git A free and open-source distributed version control system. GitHub A proprietary version control hosting company using Git. A subsidiary of Microsoft, it offers all of the distributed version control and source code management functionality of Git as well as additional features. GitLab A web-based Git repository manager with CI capabilities. GraphQL An open-source data query and manipulation language for APIs, and a runtime for fulfilling queries with existing data. Harbor An open source container image registry that secures images with role-based access control, scans images for vulnerabilities, and signs images as trusted. Helm A package manager for Kubernetes, it helps you manage Kubernetes applications. Helm Charts Helm Charts help you define, install, and upgrade even the most complex Kubernetes application. HTTP HyperText Transfer Protocol. HTTP is the underlying protocol used by the World Wide Web and this protocol defines how messages are formatted and transmitted, and what actions Web servers and browsers should take in response to various commands. IPTables A command line utility for configuring Linux kernel firewall. Jenkins An open-source automation server. k3s A highly available, certified Kubernetes distribution. k3d k3d is a lightweight wrapper to run k3s in Docker. k8s Numeronym for Kubernetes (K + 8 letters + s) Kibana An open-source data visualization plugin for Elasticsearch. It provides visualization capabilities on top of the content indexed on an Elasticsearch cluster. Kubernetes An open-source system for automating deployment, scaling, and management of containerized applications. Lagoon An open-source application delivery platform for Kubernetes. Laravel A free, open-source PHP web framework, following the model\u2013view\u2013controller (MVC) architectural pattern and based on Symfony. MariaDB A community-developed, commercially supported fork of the MySQL relational database management system, intended to remain free and open-source software under the GNU General Public License. Master node A single node in the cluster on which a collection of processes which manage the cluster state are running. Microservice The practice of breaking up an application into a series of smaller, more specialized parts, each of which communicate with one another across common interfaces such as APIs and REST interfaces like HTTP MongoDB MongoDB is a cross-platform document-oriented database program. Classified as a NoSQL database program, MongoDB uses JSON-like documents with schema. Multi-Tenant A single instance of software runs on a server and serves multiple tenants - a tenant is a group of users who share common access with privileges to access the software instance. The software is designed to provide each tenant a share of the resources. MVC Model-view-controller - an architectural pattern that separates an application into three main logical components: the model, the view, and the controller. Each of these components are built to handle specific development aspects of an application. NGINX NGINX is a web server which can also be used as a reverse proxy, load balancer, mail proxy and HTTP cache. Node Single EC2 instance (AWS virtual machine) Node.js An open-source, cross-platform, JavaScript runtime environment that executes JavaScript code outside of a browser. OpenShift Container application platform that brings Docker and Kubernetes to the enterprise. PHP PHP (Personal Home Page) is a general-purpose programming language originally designed for web development. PHPStorm Pod A group of containers that are deployed together on the same host. The basic unit that Kubernetes works with. PostgreSQL A free and open-source relational database management system emphasizing extensibility and technical standards compliance. Public/Private Key Public-key encryption is a cryptographic system that uses two keys -- a public key known to everyone and a private or secret key known only to the recipient of the message. Puppet An open-source software configuration management and deployment tool. Python Python is an open-source, interpreted, high-level, general-purpose programming language. RabbitMQ An open-source message-broker software. RBAC Role-Based Access Control RDS Relational Database Service Solr An open-source enterprise-search platform, written in Java. SSH Secure Socket Shell, a network protocol that provides administrators with a secure way to access a remote computer. SSL Secure Socket Layer Symfony Symfony is a PHP web application framework and a set of reusable PHP components/libraries, Drupal 8 and up are based on Symfony. TCP Transmission Control Protocol, a standard that defines how to establish and maintain a network conversation through which application programs can exchange data. TLS Transport Layer Security Trivy A simple and comprehensive vulnerability scanner for containers, suitable for CI. TTL Time to live or hop limit is a mechanism that limits the lifespan or lifetime of data in a computer or network. Varnish A powerful, open-source HTTP engine/reverse HTTP proxy that can speed up a website by caching (or storing) a copy of a webpage the first time a user visits. VM Virtual Machine Webhook A webhook is a way for an app like GitHub, GitLab, Bitbucket, etc, to provide other applications with immediate data and act upon something, like a pull request.","title":"Glossary"},{"location":"resources/glossary/#glossary","text":"Term Definition AWS Amazon Web Services AWS Glacier A secure and inexpensive S3 storage for long-term backup. CI Continuous Integration CLI Command Line Interface Cluster A unified group of servers or VMs, distributed and managed together, which serves one entity to ensure high availability, load balancing, and scalability. CMS Content Management System Composer A package manager DDoS Distributed Denial of Service DNS Domain Name System Docker A container engine using Linux features and automating application deployment. Drupal Open-source Content Management System Drush EC2 Amazon Elastic Compute Cloud Elasticsearch An open-source search engine. It provides a distributed, multi-tenant-capable full-text search engine with a web interface and schema-free JSON documents. Galera A generic synchronous multi-master replication library for transactional databases. Git A free and open-source distributed version control system. GitHub A proprietary version control hosting company using Git. A subsidiary of Microsoft, it offers all of the distributed version control and source code management functionality of Git as well as additional features. GitLab A web-based Git repository manager with CI capabilities. GraphQL An open-source data query and manipulation language for APIs, and a runtime for fulfilling queries with existing data. Harbor An open source container image registry that secures images with role-based access control, scans images for vulnerabilities, and signs images as trusted. Helm A package manager for Kubernetes, it helps you manage Kubernetes applications. Helm Charts Helm Charts help you define, install, and upgrade even the most complex Kubernetes application. HTTP HyperText Transfer Protocol. HTTP is the underlying protocol used by the World Wide Web and this protocol defines how messages are formatted and transmitted, and what actions Web servers and browsers should take in response to various commands. IPTables A command line utility for configuring Linux kernel firewall. Jenkins An open-source automation server. k3s A highly available, certified Kubernetes distribution. k3d k3d is a lightweight wrapper to run k3s in Docker. k8s Numeronym for Kubernetes (K + 8 letters + s) Kibana An open-source data visualization plugin for Elasticsearch. It provides visualization capabilities on top of the content indexed on an Elasticsearch cluster. Kubernetes An open-source system for automating deployment, scaling, and management of containerized applications. Lagoon An open-source application delivery platform for Kubernetes. Laravel A free, open-source PHP web framework, following the model\u2013view\u2013controller (MVC) architectural pattern and based on Symfony. MariaDB A community-developed, commercially supported fork of the MySQL relational database management system, intended to remain free and open-source software under the GNU General Public License. Master node A single node in the cluster on which a collection of processes which manage the cluster state are running. Microservice The practice of breaking up an application into a series of smaller, more specialized parts, each of which communicate with one another across common interfaces such as APIs and REST interfaces like HTTP MongoDB MongoDB is a cross-platform document-oriented database program. Classified as a NoSQL database program, MongoDB uses JSON-like documents with schema. Multi-Tenant A single instance of software runs on a server and serves multiple tenants - a tenant is a group of users who share common access with privileges to access the software instance. The software is designed to provide each tenant a share of the resources. MVC Model-view-controller - an architectural pattern that separates an application into three main logical components: the model, the view, and the controller. Each of these components are built to handle specific development aspects of an application. NGINX NGINX is a web server which can also be used as a reverse proxy, load balancer, mail proxy and HTTP cache. Node Single EC2 instance (AWS virtual machine) Node.js An open-source, cross-platform, JavaScript runtime environment that executes JavaScript code outside of a browser. OpenShift Container application platform that brings Docker and Kubernetes to the enterprise. PHP PHP (Personal Home Page) is a general-purpose programming language originally designed for web development. PHPStorm Pod A group of containers that are deployed together on the same host. The basic unit that Kubernetes works with. PostgreSQL A free and open-source relational database management system emphasizing extensibility and technical standards compliance. Public/Private Key Public-key encryption is a cryptographic system that uses two keys -- a public key known to everyone and a private or secret key known only to the recipient of the message. Puppet An open-source software configuration management and deployment tool. Python Python is an open-source, interpreted, high-level, general-purpose programming language. RabbitMQ An open-source message-broker software. RBAC Role-Based Access Control RDS Relational Database Service Solr An open-source enterprise-search platform, written in Java. SSH Secure Socket Shell, a network protocol that provides administrators with a secure way to access a remote computer. SSL Secure Socket Layer Symfony Symfony is a PHP web application framework and a set of reusable PHP components/libraries, Drupal 8 and up are based on Symfony. TCP Transmission Control Protocol, a standard that defines how to establish and maintain a network conversation through which application programs can exchange data. TLS Transport Layer Security Trivy A simple and comprehensive vulnerability scanner for containers, suitable for CI. TTL Time to live or hop limit is a mechanism that limits the lifespan or lifetime of data in a computer or network. Varnish A powerful, open-source HTTP engine/reverse HTTP proxy that can speed up a website by caching (or storing) a copy of a webpage the first time a user visits. VM Virtual Machine Webhook A webhook is a way for an app like GitHub, GitLab, Bitbucket, etc, to provide other applications with immediate data and act upon something, like a pull request.","title":"Glossary"},{"location":"resources/tutorials-and-webinars/","text":"Tutorials, Webinars, and Videos # Intro to Lagoon Webinar # [ Slides ] Advance Lando-ing with Lagoon # Webinar - Lagoon Insights # Lagoon Deployment Demo # How to Manage Multiple Drupal Sites with Lagoon # [ Slides ] Kubernetes Webinar 101 # [ Slides ] Kubernetes Webinar 102 # [ Slides ] Server-side Rendering Best Practices: How We Run Decoupled Websites with 110 Million Hits per Month # Lagoon: OpenSource Docker Build & Deployment System with Full Drupal Support # How do I fix an internal server error in Kibana? # How do I add a new route? # How do I check the status of a build? # How do I add a redirect in Lagoon? # How do I download a database dump? # How do I add a cron job? # Deploying web applications on Kubernetes - Toby Bellwood | Techweek21 Talk # Dealing with unprecedented scale during Covid-19 - Sean Hamlin| Techweek21 Talk # Silverstripe from local to live on Lagoon -Thom Toogood | Techweek21 Talk #","title":"Tutorials, Webinars, and Videos"},{"location":"resources/tutorials-and-webinars/#tutorials-webinars-and-videos","text":"","title":"Tutorials, Webinars, and Videos"},{"location":"resources/tutorials-and-webinars/#intro-to-lagoon-webinar","text":"[ Slides ]","title":"Intro to Lagoon Webinar"},{"location":"resources/tutorials-and-webinars/#advance-lando-ing-with-lagoon","text":"","title":"Advance Lando-ing with Lagoon"},{"location":"resources/tutorials-and-webinars/#webinar-lagoon-insights","text":"","title":"Webinar - Lagoon Insights"},{"location":"resources/tutorials-and-webinars/#lagoon-deployment-demo","text":"","title":"Lagoon Deployment Demo"},{"location":"resources/tutorials-and-webinars/#how-to-manage-multiple-drupal-sites-with-lagoon","text":"[ Slides ]","title":"How to Manage Multiple Drupal Sites with Lagoon"},{"location":"resources/tutorials-and-webinars/#kubernetes-webinar-101","text":"[ Slides ]","title":"Kubernetes Webinar 101"},{"location":"resources/tutorials-and-webinars/#kubernetes-webinar-102","text":"[ Slides ]","title":"Kubernetes Webinar 102"},{"location":"resources/tutorials-and-webinars/#server-side-rendering-best-practices-how-we-run-decoupled-websites-with-110-million-hits-per-month","text":"","title":"Server-side Rendering Best Practices: How We Run Decoupled Websites with 110 Million Hits per Month"},{"location":"resources/tutorials-and-webinars/#lagoon-opensource-docker-build-deployment-system-with-full-drupal-support","text":"","title":"Lagoon: OpenSource Docker Build &amp; Deployment System with Full Drupal Support"},{"location":"resources/tutorials-and-webinars/#how-do-i-fix-an-internal-server-error-in-kibana","text":"","title":"How do I fix an internal server error in Kibana?"},{"location":"resources/tutorials-and-webinars/#how-do-i-add-a-new-route","text":"","title":"How do I add a new route?"},{"location":"resources/tutorials-and-webinars/#how-do-i-check-the-status-of-a-build","text":"","title":"How do I check the status of a build?"},{"location":"resources/tutorials-and-webinars/#how-do-i-add-a-redirect-in-lagoon","text":"","title":"How do I add a redirect in Lagoon?"},{"location":"resources/tutorials-and-webinars/#how-do-i-download-a-database-dump","text":"","title":"How do I download a database dump?"},{"location":"resources/tutorials-and-webinars/#how-do-i-add-a-cron-job","text":"","title":"How do I add a cron job?"},{"location":"resources/tutorials-and-webinars/#deploying-web-applications-on-kubernetes-toby-bellwood-techweek21-talk","text":"","title":"Deploying web applications on Kubernetes - Toby Bellwood | Techweek21 Talk"},{"location":"resources/tutorials-and-webinars/#dealing-with-unprecedented-scale-during-covid-19-sean-hamlin-techweek21-talk","text":"","title":"Dealing with unprecedented scale during Covid-19 - Sean Hamlin| Techweek21 Talk"},{"location":"resources/tutorials-and-webinars/#silverstripe-from-local-to-live-on-lagoon-thom-toogood-techweek21-talk","text":"","title":"Silverstripe from local to live on Lagoon -Thom Toogood | Techweek21 Talk"},{"location":"using-lagoon-advanced/active-standby/","text":"Active/Standby # Configuration # To change an existing project to support active/standby you'll need to configure some project settings with the Lagoon API. productionEnviromment should be set to the branch name of the current active environment. standbyProductionEnvironment should be set to the branch name of the current environment that is in standby. mutation updateProject { updateProject(input:{ id:1234 patch:{ productionEnvironment:\"production-brancha\" standbyProductionEnvironment:\"production-branchb\" } }){ standbyProductionEnvironment name productionEnvironment } } .lagoon.yml - production_routes # To configure a project for active/standby in the .lagoon.yml file, you'll need to configure the production_routes section with any routes you want to attach to the active environment, and any routes to the standby environment. During an active/standby switch, these routes will migrate between the two environments. If you have two production environments, production-brancha and production-branchb , with the current active production environment as production-brancha then: Routes under production_routes.active will direct you to production-brancha . Routes under production_routes.standby will direct you to production-branchb . During an active/standby switch, the routes will swap: Routes under production_routes.active will direct you to production-branchb . Routes under production_routes.standby will direct you to production-brancha . .lagoon.yml production_routes : active : routes : - nginx : - example.com : tls-acme : 'false' - active.example.com : tls-acme : 'false' standby : routes : - nginx : - standby.example.com : tls-acme : 'false' Note: Any routes that are under the section environments..routes will not be moved as part of active/standby. These routes will always be attached to the environment as defined. Ensure that if you do need a specific route to be migrated during an active/standby switch, that you remove them from the environments section and place them under the production_routes section specific to if it should be an active or standby route. See more about routes in .lagoon.yml . Triggering a switch event # via the UI # To trigger the switching of environment routes, you can visit the standby environment in the Lagoon UI and click on the button labeled Switch Active/Standby environments . You will be prompted to confirm your action. Once confirmed, it will take you to the tasks page where you can view the progress of the switch. via the API # To trigger an event to switch the environments, run the following graphQL mutation. This will tell Lagoon to begin the process. mutation ActiveStandby { switchActiveStandby( input:{ project:{ name:\"drupal-example\" } } ){ id remoteId } } A task is created in the current active environment tasks tab when a switch event is triggered. You can check the status of the switch here. Using the remoteId from the switchActiveStandby mutation, we can also check the status of the task. query getTask { taskByRemoteId(id: \"<remoteId>\") { id name created started completed status logs } } drush aliases # By default, projects will be created with the following aliases that will be available when active/standby is enabled on a project. lagoon-production lagoon-standby The lagoon-production alias will point to whichever site is defined as productionEnvironment , and lagoon-standby will always point to the site that is defined as standbyProductionEnvironment . These aliases are configurable by updating the project. Be aware that changing them may require you to update any scripts that rely on them. mutation updateProject { updateProject(input:{ id:1234 patch:{ productionAlias:\"custom-lagoon-production-alias\" standbyAlias:\"custom-lagoon-standby-alias\" } }){ productionAlias name standbyAlias } } Notes # When the active/standby trigger has been executed, the productionEnvironment and standbyProductionEnvironments will switch within the Lagoon API. Both environments are still classed as production environment types. We use the productionEnvironment to determine which one is labelled as active . For more information on the differences between environment types, read the documentation for environment types query projectByName { projectByName(name:\"drupal-example\"){ productionEnvironment standbyProductionEnvironment } } Before switching environments: { \"data\": { \"projectByName\": { \"productionEnvironment\": \"production-brancha\", \"standbyProductionEnvironment\": \"production-branchb\" } } } After switching environments: { \"data\": { \"projectByName\": { \"productionEnvironment\": \"production-branchb\", \"standbyProductionEnvironment\": \"production-brancha\" } } }","title":"Active/Standby"},{"location":"using-lagoon-advanced/active-standby/#activestandby","text":"","title":"Active/Standby"},{"location":"using-lagoon-advanced/active-standby/#configuration","text":"To change an existing project to support active/standby you'll need to configure some project settings with the Lagoon API. productionEnviromment should be set to the branch name of the current active environment. standbyProductionEnvironment should be set to the branch name of the current environment that is in standby. mutation updateProject { updateProject(input:{ id:1234 patch:{ productionEnvironment:\"production-brancha\" standbyProductionEnvironment:\"production-branchb\" } }){ standbyProductionEnvironment name productionEnvironment } }","title":"Configuration"},{"location":"using-lagoon-advanced/active-standby/#lagoonyml-production_routes","text":"To configure a project for active/standby in the .lagoon.yml file, you'll need to configure the production_routes section with any routes you want to attach to the active environment, and any routes to the standby environment. During an active/standby switch, these routes will migrate between the two environments. If you have two production environments, production-brancha and production-branchb , with the current active production environment as production-brancha then: Routes under production_routes.active will direct you to production-brancha . Routes under production_routes.standby will direct you to production-branchb . During an active/standby switch, the routes will swap: Routes under production_routes.active will direct you to production-branchb . Routes under production_routes.standby will direct you to production-brancha . .lagoon.yml production_routes : active : routes : - nginx : - example.com : tls-acme : 'false' - active.example.com : tls-acme : 'false' standby : routes : - nginx : - standby.example.com : tls-acme : 'false' Note: Any routes that are under the section environments..routes will not be moved as part of active/standby. These routes will always be attached to the environment as defined. Ensure that if you do need a specific route to be migrated during an active/standby switch, that you remove them from the environments section and place them under the production_routes section specific to if it should be an active or standby route. See more about routes in .lagoon.yml .","title":".lagoon.yml - production_routes"},{"location":"using-lagoon-advanced/active-standby/#triggering-a-switch-event","text":"","title":"Triggering a switch event"},{"location":"using-lagoon-advanced/active-standby/#via-the-ui","text":"To trigger the switching of environment routes, you can visit the standby environment in the Lagoon UI and click on the button labeled Switch Active/Standby environments . You will be prompted to confirm your action. Once confirmed, it will take you to the tasks page where you can view the progress of the switch.","title":"via the UI"},{"location":"using-lagoon-advanced/active-standby/#via-the-api","text":"To trigger an event to switch the environments, run the following graphQL mutation. This will tell Lagoon to begin the process. mutation ActiveStandby { switchActiveStandby( input:{ project:{ name:\"drupal-example\" } } ){ id remoteId } } A task is created in the current active environment tasks tab when a switch event is triggered. You can check the status of the switch here. Using the remoteId from the switchActiveStandby mutation, we can also check the status of the task. query getTask { taskByRemoteId(id: \"<remoteId>\") { id name created started completed status logs } }","title":"via the API"},{"location":"using-lagoon-advanced/active-standby/#drush-aliases","text":"By default, projects will be created with the following aliases that will be available when active/standby is enabled on a project. lagoon-production lagoon-standby The lagoon-production alias will point to whichever site is defined as productionEnvironment , and lagoon-standby will always point to the site that is defined as standbyProductionEnvironment . These aliases are configurable by updating the project. Be aware that changing them may require you to update any scripts that rely on them. mutation updateProject { updateProject(input:{ id:1234 patch:{ productionAlias:\"custom-lagoon-production-alias\" standbyAlias:\"custom-lagoon-standby-alias\" } }){ productionAlias name standbyAlias } }","title":"drush aliases"},{"location":"using-lagoon-advanced/active-standby/#notes","text":"When the active/standby trigger has been executed, the productionEnvironment and standbyProductionEnvironments will switch within the Lagoon API. Both environments are still classed as production environment types. We use the productionEnvironment to determine which one is labelled as active . For more information on the differences between environment types, read the documentation for environment types query projectByName { projectByName(name:\"drupal-example\"){ productionEnvironment standbyProductionEnvironment } } Before switching environments: { \"data\": { \"projectByName\": { \"productionEnvironment\": \"production-brancha\", \"standbyProductionEnvironment\": \"production-branchb\" } } } After switching environments: { \"data\": { \"projectByName\": { \"productionEnvironment\": \"production-branchb\", \"standbyProductionEnvironment\": \"production-brancha\" } } }","title":"Notes"},{"location":"using-lagoon-advanced/backups/","text":"Backups # Lagoon makes use of the k8up operator to provide backup functionality for both database data as well as containers' persistent storage volumes. This operator utilizes Restic to catalog these backups, which is typically connected to an AWS S3 bucket to provide secure, off-site storage for the generated backups. Production Environments # Backup Schedules # Backups of databases and containers' persistent storage volumes happens nightly within production environments by default. If a different backup schedule for production backups is required, this can be specified at a project level via setting the \"Backup Schedule\" variables in the project's .lagoon.yml file. Backup Retention # Production environment backups will be held according to the following schedule by default: Daily: 7 Weekly: 6 Monthly: 1 Hourly: 0 If a different retention period for production backups is required, this can be specified at a project level via setting the \"Backup Retention\" variables in the project's .lagoon.yml file. Development Environments # Backups of development environments are attempted nightly and are strictly a best effort service. Retrieving Backups # Backups stored in Restic will be tracked within Lagoon, and can be recovered via the \"Backup\" tab for each environment in the Lagoon UI. Custom Backup and/or Restore Locations # Lagoon supports custom backup and restore locations via the use of the \" Custom Backup Settings \" and/or \" Custom Restore Settings \" variables stored in the Lagoon API for each project. Danger Proceed with caution: Setting these variables will override backup/restore storage locations that may be configured at a cluster level. Any misconfiguration will cause backup/restore failures.","title":"Backups"},{"location":"using-lagoon-advanced/backups/#backups","text":"Lagoon makes use of the k8up operator to provide backup functionality for both database data as well as containers' persistent storage volumes. This operator utilizes Restic to catalog these backups, which is typically connected to an AWS S3 bucket to provide secure, off-site storage for the generated backups.","title":"Backups"},{"location":"using-lagoon-advanced/backups/#production-environments","text":"","title":"Production Environments"},{"location":"using-lagoon-advanced/backups/#backup-schedules","text":"Backups of databases and containers' persistent storage volumes happens nightly within production environments by default. If a different backup schedule for production backups is required, this can be specified at a project level via setting the \"Backup Schedule\" variables in the project's .lagoon.yml file.","title":"Backup Schedules"},{"location":"using-lagoon-advanced/backups/#backup-retention","text":"Production environment backups will be held according to the following schedule by default: Daily: 7 Weekly: 6 Monthly: 1 Hourly: 0 If a different retention period for production backups is required, this can be specified at a project level via setting the \"Backup Retention\" variables in the project's .lagoon.yml file.","title":"Backup Retention"},{"location":"using-lagoon-advanced/backups/#development-environments","text":"Backups of development environments are attempted nightly and are strictly a best effort service.","title":"Development Environments"},{"location":"using-lagoon-advanced/backups/#retrieving-backups","text":"Backups stored in Restic will be tracked within Lagoon, and can be recovered via the \"Backup\" tab for each environment in the Lagoon UI.","title":"Retrieving Backups"},{"location":"using-lagoon-advanced/backups/#custom-backup-andor-restore-locations","text":"Lagoon supports custom backup and restore locations via the use of the \" Custom Backup Settings \" and/or \" Custom Restore Settings \" variables stored in the Lagoon API for each project. Danger Proceed with caution: Setting these variables will override backup/restore storage locations that may be configured at a cluster level. Any misconfiguration will cause backup/restore failures.","title":"Custom Backup and/or Restore Locations"},{"location":"using-lagoon-advanced/base-images/","text":"Base Images # What is a base image? # A base image is a Docker image that can be and is used by a project deployed on Lagoon. A base image provides a way to ensure that nothing is brought into the codebase/project from upstream that has not been audited. It also allows us to ensure that anything we might need on the deployed environment is available - from lower-level libraries to application-level themes and modules. Base images save time and resources when you know what system is being deployed to - if shared packages are included in the base image, they don\u2019t have to be deployed to hundreds of sites individually. Derived images # A derived image is one that extends a base image. For example, you might need to make several blog sites. You take our Drupal image, customize it to include all of the modules and themes you need for your blog sites, and deploy them all with that blog image. Templates are derived from base images. All derived images should pull in the composer.json file (via repositories like Packagist , Satis , or GitHub ) so that they are using the most recent versions of the base packages. Further, the derived image includes a call to the script /build/pre_composer , which can be used by the base image to run scripts, updates, etc., downstream in the derived images. For instance, it should run by default when any package is updated or installed at the derived image, and the pre_composer script will then update the base image package. Anatomy of a base image # Note: Note : this document will talk about Drupal and Laravel base images as examples, as it was originally written for a client who uses those technologies in their Lagoon projects. It will be expanded to cover the contents of other base images, but none of the processes differ, no matter what the content of your base image. Base images are managed with Composer and hosted in Bitbucket , Github , or GitLab (whatever your team is using). Each base image has its own repository. Metapackages # The metapackage is a Composer package that wraps several other components. These include, for example, the core files for Laravel or Drupal, along with any needed modules or themes. This way, you do not need to include Laravel or Drupal, etc., as a dependency in your project. Here\u2019s an example from the composer.json in a Laravel base image: composer.json \"require\": { \"amazeelabs/algm_laravel_baseimage\": \"*\" }, We only require this metapackage, which points to a GitHub repository. docker-compose.yml # Other pieces of your project are defined in docker-compose.yml . For example, if you have a Drupal project, you need the Drupal image, but you also need MariaDB, Solr, Redis, and Varnish. We have versions of these services optimized for Drupal, all of which are included in docker-compose.yml . Drupal # The Drupal base image contains the following contributed tools and modules, in addition to Drupal core: Drupal Console Drush Configuration Installer Redis Poll Search API Search API Solr Varnish Purge Purge Admin Toolbar CDN Password Policy Pathauto Ultimate Cron Laravel # Configuration # The base images have provided the default values for the environment variables used by Laravel. These are values for: DB_CONNECTION DB_HOST DB_PORT DB_DATABASE DB_USERNAME DB_PASSWORD REDIS_HOST REDIS_PASSWORD REDIS_PORT Ensure that your config files (typically located in /config ) make use of these by default. Queues # If your project makes use of queues , you can make use of the artisan-worker service. It is a worker container, used for executing artisan queue:work . This is disabled by default - look at the comments in docker-compose.yml . Understanding the process of building a base image # There are several parts to the process of building a base image. All of the major steps are represented in the Makefile. The Jenkinsfile contains a more stripped-down view. Taking a look at both files will give you a good understanding of what happens during this process. Most steps can be tested locally (this is important when building new versions of the base image). After you\u2019ve created and tested everything locally and pushed it up, the actual base image is built by Jenkins and pushed to Harbor . Makefile and build assumptions # If you're planning on running locally, there are some minimum environment variables that need to be present to build at all. Base image build variables # Variables injected into the base image build process and where to find them. BUILD_NUMBER - This is injected by Jenkins automatically. GIT_BRANCH - This is provided by the Jenkins build process itself. Depends on the branch being built at the time (develop, main, etc.). DOCKER_REPO / DOCKER_HUB - This is defined inside the Jenkinsfile itself. It points to the Docker project and hub into which the resulting images will be pushed. DOCKER_USERNAME / DOCKER_PASSWORD - These are used to actually log into the Docker repository early in the build. These variables are stored inside of the Jenkins credentials. These are used in the Jenkinsfile itself and are not part of the Makefile. This means that if you\u2019re building base images outside of Jenkins (i.e. locally, to test, etc.) you have to run a docker login manually before running any of the make steps. In practice, this means that if you're running any of the make targets on your local machine, you'll want to ensure that these are available in the environment - even if this is just setting them when running make from the command line, as an example: GIT_BRANCH = example_branch_name DOCKER_HUB = the_docker_hub_the_images_are_pushed_to DOCKER_REPO = your_docker_repo_here BUILD_NUMBER = <some_integer> make images_remove Makefile targets # The most important targets are the following: images_build : Given the environment variables, this will build and tag the images for publication. images_publish : Pushes built images to a Docker repository. images_start : Will start the images for testing, etc. images_test : Runs basic tests against images. images_remove : Removes previously built images, given the build environment variables. Example workflow for building a new release of a base image # There are several steps to the build process. Most of these are shared among the various base images. These mostly correspond to the Makefile target described above. Docker Login - The Docker username, password, and URL for Harbor are passed to the Docker client. Docker Build - The make images_build step is run now, which will: Ensure that all environment variables are prepared for the build. Run a docker-compose build . This will produce several new Docker images from the current Git branch. Images Test - This will run the make images_test target, which will differ depending on the images being tested. In most cases this is a very straightforward test to ensure that the images can be started and interacted with in some way (installing Drupal, listing files, etc.) Docker Push - This step runs the logic (contained in the make target images_publish ) that will tag the images resulting from the Docker Build in Step 2 and push them to Harbor. This is described in more detail elsewhere in this guide. Docker Clean Images - Runs the make target images_remove , which simply deletes the newly built images from the Docker host now that they are in Harbor. Releasing a new version of a base image # There are many reasons to release a new version of a base image. On Drupal or Laravel, Node.js, etc images, it may be in order to upgrade or install a module/package for features or security. It may be about the underlying software that comes bundled in the container, such as updating the version of PHP or Node.js. It may be about updating the actual underlying images on which the base images are built. The images that your project's base images are built on are the managed images maintained by the Lagoon team. We release updates to these underlying images on a monthly (or more fequent) basus. When these are updated, you need to build new versions of your own base images in order to incorporate the changes and upgrades bundled in the upstream images. In this section we will demonstrate the process of updating and tagging a new release of the Drupal 8 base image. We will add a new module ( ClamAV ) to the base. We\u2019re demonstrating on Drupal because it has the most complex setup of the base images. The steps that are common to every base image are noted below. Step 1 - Pull down the base image locally # This is just pulling down the Git repository locally. In the case of the Drupal 8 base image. In this example, we're using Bitbucket, so we will run: git clone ssh://git@bitbucket.biscrum.com:7999/webpro/drupal8_base_image.git Step 2 - Make the changes to the repository # Note: Note: What is demonstrated here is specific to the Drupal 8 base image. However, any changes (adding files, changing base Docker images, etc.) will be done in this step for all of the base images. In our example, we are adding the ClamAV module to the Drupal 8 base image. This involves a few steps. The first is requiring the package so that it gets added to our composer.json file. This is done by running a composer require . Here we run: composer require drupal/clamav When the composer require process completes, the package should then appear in the composer.json file. Here we open the composer.json file and take a look at the list of required packages, and check that the ClamAV package is listed, and see that it is there: Step 2.2 - Ensure that the required Drupal module is enabled in template-based derived images. # For any modules now added to the base image, we need to ensure that they\u2019re enabled on the template-based derived images. This is done by adding the module to the Lagoon Bundle module located at ./web/modules/lagoon/lagoon_bundle . Specifically, it requires you to add it as a dependency to the dependencies section of the lagoon_bundle.info.yml file. The Lagoon Bundle module is a utility module that exists only to help enforce dependencies across derived images. Here we open web/modules/contrib/lagoon/lagoon_bundle/lagoon_bundle.info.yml and add clamav:clamav as a dependency: Adding a dependency to this will ensure that whenever the Lagoon Bundle module is enabled on the derived image, its dependencies (in this case, the just-added ClamAV module) will also be enabled. This is enforced by a post-rollout script which enables lagoon_bundle on the derived images when they are rolled out. Step 2.3 - Test # This will depend on what you\u2019re testing. In the case of adding the ClamAV module, we want to ensure that in the base image, the module is downloaded, and that the Lagoon Bundle module enables ClamAV when it is enabled. Here we check that the module is downloaded to /app/web/modules/contrib : And then we check that when we enable the lagoon_bundle module, it enables clamav by running: drush pm-enable lagoon_bundle -y Warning: Note: You\u2019ll see that there is a JWT error in the container above. You can safely ignore this in the demonstration above - but, for background, you will see this error when there is no Lagoon environment for the site you\u2019re working on. With our testing done, we can now tag and build the images. Step 3 - Tagging images Images are versioned based on their Git tags - these should follow standard semantic versioning (semver) practices. All tags should have the structure vX.Y.Z where X, Y, and Z are integers (to be precise the X.Y.Z are themselves the semantic version - the vX.Y.Z is a tag). This is an assumption that is used to determine the image tags, so it must be adhered to. In this example we will be tagging a new version of the Drupal 8 base image indicating that we have added ClamAV. Here we demonstrate how to tag an image. We check that we have committed (but not pushed) our changes, just as you would do for any regular commit and push, using git log . Commit your changes if you haven\u2019t yet. We then check to see what tag we are on using git tag . Then, tag them using git tag -a v0.0.9 -m \u201cAdds clamAV to base.\u201d git -a, --annotate: Make an unsigned, annotated tag object Next, we push our tags with git push --tags . And finally, push all of our changes with git push . Danger: Note: The tags must be pushed explicitly in their own step! How Git tags map to image tags # Danger: Important note: Depending on the build workflow, you will almost certainly push the changes via the develop branch before merging it into the main branch. An important point to remember here is that the Jenkins base image build process will tag images based on the most recent commit\u2019s tag . Images are tagged using the following rules, and images will be built for each of these that apply: When the main branch is built, it is tagged as latest . When the develop branch is built, it is tagged as development . If the commit being built is tagged then that branch will be built with that commit\u2019s tag. This is how we release a new version as we demonstrated above. It can also be used to make ad hoc builds with fairly arbitrary tags - be reasonable with the tag names, it has only been tested with semver tags. Step 4 - Building the new base images # Note: Note: Generally you will have a trigger strategy set up here for automatic builds, but as that will differ based on your needs and setup, this explains how to build manually. Visit your Lagoon Jenkins instance. Select the project you are working on (in this case, AIOBI Drupal 8 Base). Click the branch you would like to build. Click \u201cBuild Now.\u201d This will kick off the build process which, if successful, will push up the new images to Harbor. If the build is not successful, you can click into the build itself and read the logs to understand where it failed. As shown in the screenshot below from Harbor, the image we\u2019ve just built in Jenkins has been uploaded and tagged in Harbor, where it will now be scanned for any vulnerabilities. Since it was tagged as v0.0.9, an image with that tag is present, and because we built the main branch, the \u201clatest\u201d image has also been built. At this stage, the v0.0.9 and \u201clatest\u201d images are identical. Acknowledgement # The base image structure draws heavily (and, in fact, is a fork of) Denpal . It is based on the original Drupal Composer Template , but includes everything necessary to run on Lagoon (either the local development environment or on hosted Lagoon).","title":"Base Images"},{"location":"using-lagoon-advanced/base-images/#base-images","text":"","title":"Base Images"},{"location":"using-lagoon-advanced/base-images/#what-is-a-base-image","text":"A base image is a Docker image that can be and is used by a project deployed on Lagoon. A base image provides a way to ensure that nothing is brought into the codebase/project from upstream that has not been audited. It also allows us to ensure that anything we might need on the deployed environment is available - from lower-level libraries to application-level themes and modules. Base images save time and resources when you know what system is being deployed to - if shared packages are included in the base image, they don\u2019t have to be deployed to hundreds of sites individually.","title":"What is a base image?"},{"location":"using-lagoon-advanced/base-images/#derived-images","text":"A derived image is one that extends a base image. For example, you might need to make several blog sites. You take our Drupal image, customize it to include all of the modules and themes you need for your blog sites, and deploy them all with that blog image. Templates are derived from base images. All derived images should pull in the composer.json file (via repositories like Packagist , Satis , or GitHub ) so that they are using the most recent versions of the base packages. Further, the derived image includes a call to the script /build/pre_composer , which can be used by the base image to run scripts, updates, etc., downstream in the derived images. For instance, it should run by default when any package is updated or installed at the derived image, and the pre_composer script will then update the base image package.","title":"Derived images"},{"location":"using-lagoon-advanced/base-images/#anatomy-of-a-base-image","text":"Note: Note : this document will talk about Drupal and Laravel base images as examples, as it was originally written for a client who uses those technologies in their Lagoon projects. It will be expanded to cover the contents of other base images, but none of the processes differ, no matter what the content of your base image. Base images are managed with Composer and hosted in Bitbucket , Github , or GitLab (whatever your team is using). Each base image has its own repository.","title":"Anatomy of a base image"},{"location":"using-lagoon-advanced/base-images/#metapackages","text":"The metapackage is a Composer package that wraps several other components. These include, for example, the core files for Laravel or Drupal, along with any needed modules or themes. This way, you do not need to include Laravel or Drupal, etc., as a dependency in your project. Here\u2019s an example from the composer.json in a Laravel base image: composer.json \"require\": { \"amazeelabs/algm_laravel_baseimage\": \"*\" }, We only require this metapackage, which points to a GitHub repository.","title":"Metapackages"},{"location":"using-lagoon-advanced/base-images/#docker-composeyml","text":"Other pieces of your project are defined in docker-compose.yml . For example, if you have a Drupal project, you need the Drupal image, but you also need MariaDB, Solr, Redis, and Varnish. We have versions of these services optimized for Drupal, all of which are included in docker-compose.yml .","title":"docker-compose.yml"},{"location":"using-lagoon-advanced/base-images/#drupal","text":"The Drupal base image contains the following contributed tools and modules, in addition to Drupal core: Drupal Console Drush Configuration Installer Redis Poll Search API Search API Solr Varnish Purge Purge Admin Toolbar CDN Password Policy Pathauto Ultimate Cron","title":"Drupal"},{"location":"using-lagoon-advanced/base-images/#laravel","text":"","title":"Laravel"},{"location":"using-lagoon-advanced/base-images/#configuration","text":"The base images have provided the default values for the environment variables used by Laravel. These are values for: DB_CONNECTION DB_HOST DB_PORT DB_DATABASE DB_USERNAME DB_PASSWORD REDIS_HOST REDIS_PASSWORD REDIS_PORT Ensure that your config files (typically located in /config ) make use of these by default.","title":"Configuration"},{"location":"using-lagoon-advanced/base-images/#queues","text":"If your project makes use of queues , you can make use of the artisan-worker service. It is a worker container, used for executing artisan queue:work . This is disabled by default - look at the comments in docker-compose.yml .","title":"Queues"},{"location":"using-lagoon-advanced/base-images/#understanding-the-process-of-building-a-base-image","text":"There are several parts to the process of building a base image. All of the major steps are represented in the Makefile. The Jenkinsfile contains a more stripped-down view. Taking a look at both files will give you a good understanding of what happens during this process. Most steps can be tested locally (this is important when building new versions of the base image). After you\u2019ve created and tested everything locally and pushed it up, the actual base image is built by Jenkins and pushed to Harbor .","title":"Understanding the process of building a base image"},{"location":"using-lagoon-advanced/base-images/#makefile-and-build-assumptions","text":"If you're planning on running locally, there are some minimum environment variables that need to be present to build at all.","title":"Makefile and build assumptions"},{"location":"using-lagoon-advanced/base-images/#base-image-build-variables","text":"Variables injected into the base image build process and where to find them. BUILD_NUMBER - This is injected by Jenkins automatically. GIT_BRANCH - This is provided by the Jenkins build process itself. Depends on the branch being built at the time (develop, main, etc.). DOCKER_REPO / DOCKER_HUB - This is defined inside the Jenkinsfile itself. It points to the Docker project and hub into which the resulting images will be pushed. DOCKER_USERNAME / DOCKER_PASSWORD - These are used to actually log into the Docker repository early in the build. These variables are stored inside of the Jenkins credentials. These are used in the Jenkinsfile itself and are not part of the Makefile. This means that if you\u2019re building base images outside of Jenkins (i.e. locally, to test, etc.) you have to run a docker login manually before running any of the make steps. In practice, this means that if you're running any of the make targets on your local machine, you'll want to ensure that these are available in the environment - even if this is just setting them when running make from the command line, as an example: GIT_BRANCH = example_branch_name DOCKER_HUB = the_docker_hub_the_images_are_pushed_to DOCKER_REPO = your_docker_repo_here BUILD_NUMBER = <some_integer> make images_remove","title":"Base image build variables"},{"location":"using-lagoon-advanced/base-images/#makefile-targets","text":"The most important targets are the following: images_build : Given the environment variables, this will build and tag the images for publication. images_publish : Pushes built images to a Docker repository. images_start : Will start the images for testing, etc. images_test : Runs basic tests against images. images_remove : Removes previously built images, given the build environment variables.","title":"Makefile targets"},{"location":"using-lagoon-advanced/base-images/#example-workflow-for-building-a-new-release-of-a-base-image","text":"There are several steps to the build process. Most of these are shared among the various base images. These mostly correspond to the Makefile target described above. Docker Login - The Docker username, password, and URL for Harbor are passed to the Docker client. Docker Build - The make images_build step is run now, which will: Ensure that all environment variables are prepared for the build. Run a docker-compose build . This will produce several new Docker images from the current Git branch. Images Test - This will run the make images_test target, which will differ depending on the images being tested. In most cases this is a very straightforward test to ensure that the images can be started and interacted with in some way (installing Drupal, listing files, etc.) Docker Push - This step runs the logic (contained in the make target images_publish ) that will tag the images resulting from the Docker Build in Step 2 and push them to Harbor. This is described in more detail elsewhere in this guide. Docker Clean Images - Runs the make target images_remove , which simply deletes the newly built images from the Docker host now that they are in Harbor.","title":"Example workflow for building a new release of a base image"},{"location":"using-lagoon-advanced/base-images/#releasing-a-new-version-of-a-base-image","text":"There are many reasons to release a new version of a base image. On Drupal or Laravel, Node.js, etc images, it may be in order to upgrade or install a module/package for features or security. It may be about the underlying software that comes bundled in the container, such as updating the version of PHP or Node.js. It may be about updating the actual underlying images on which the base images are built. The images that your project's base images are built on are the managed images maintained by the Lagoon team. We release updates to these underlying images on a monthly (or more fequent) basus. When these are updated, you need to build new versions of your own base images in order to incorporate the changes and upgrades bundled in the upstream images. In this section we will demonstrate the process of updating and tagging a new release of the Drupal 8 base image. We will add a new module ( ClamAV ) to the base. We\u2019re demonstrating on Drupal because it has the most complex setup of the base images. The steps that are common to every base image are noted below.","title":"Releasing a new version of a base image"},{"location":"using-lagoon-advanced/base-images/#step-1-pull-down-the-base-image-locally","text":"This is just pulling down the Git repository locally. In the case of the Drupal 8 base image. In this example, we're using Bitbucket, so we will run: git clone ssh://git@bitbucket.biscrum.com:7999/webpro/drupal8_base_image.git","title":"Step 1 - Pull down the base image locally"},{"location":"using-lagoon-advanced/base-images/#step-2-make-the-changes-to-the-repository","text":"Note: Note: What is demonstrated here is specific to the Drupal 8 base image. However, any changes (adding files, changing base Docker images, etc.) will be done in this step for all of the base images. In our example, we are adding the ClamAV module to the Drupal 8 base image. This involves a few steps. The first is requiring the package so that it gets added to our composer.json file. This is done by running a composer require . Here we run: composer require drupal/clamav When the composer require process completes, the package should then appear in the composer.json file. Here we open the composer.json file and take a look at the list of required packages, and check that the ClamAV package is listed, and see that it is there:","title":"Step 2 - Make the changes to the repository"},{"location":"using-lagoon-advanced/base-images/#step-22-ensure-that-the-required-drupal-module-is-enabled-in-template-based-derived-images","text":"For any modules now added to the base image, we need to ensure that they\u2019re enabled on the template-based derived images. This is done by adding the module to the Lagoon Bundle module located at ./web/modules/lagoon/lagoon_bundle . Specifically, it requires you to add it as a dependency to the dependencies section of the lagoon_bundle.info.yml file. The Lagoon Bundle module is a utility module that exists only to help enforce dependencies across derived images. Here we open web/modules/contrib/lagoon/lagoon_bundle/lagoon_bundle.info.yml and add clamav:clamav as a dependency: Adding a dependency to this will ensure that whenever the Lagoon Bundle module is enabled on the derived image, its dependencies (in this case, the just-added ClamAV module) will also be enabled. This is enforced by a post-rollout script which enables lagoon_bundle on the derived images when they are rolled out.","title":"Step 2.2 - Ensure that the required Drupal module is enabled in template-based derived images."},{"location":"using-lagoon-advanced/base-images/#step-23-test","text":"This will depend on what you\u2019re testing. In the case of adding the ClamAV module, we want to ensure that in the base image, the module is downloaded, and that the Lagoon Bundle module enables ClamAV when it is enabled. Here we check that the module is downloaded to /app/web/modules/contrib : And then we check that when we enable the lagoon_bundle module, it enables clamav by running: drush pm-enable lagoon_bundle -y Warning: Note: You\u2019ll see that there is a JWT error in the container above. You can safely ignore this in the demonstration above - but, for background, you will see this error when there is no Lagoon environment for the site you\u2019re working on. With our testing done, we can now tag and build the images. Step 3 - Tagging images Images are versioned based on their Git tags - these should follow standard semantic versioning (semver) practices. All tags should have the structure vX.Y.Z where X, Y, and Z are integers (to be precise the X.Y.Z are themselves the semantic version - the vX.Y.Z is a tag). This is an assumption that is used to determine the image tags, so it must be adhered to. In this example we will be tagging a new version of the Drupal 8 base image indicating that we have added ClamAV. Here we demonstrate how to tag an image. We check that we have committed (but not pushed) our changes, just as you would do for any regular commit and push, using git log . Commit your changes if you haven\u2019t yet. We then check to see what tag we are on using git tag . Then, tag them using git tag -a v0.0.9 -m \u201cAdds clamAV to base.\u201d git -a, --annotate: Make an unsigned, annotated tag object Next, we push our tags with git push --tags . And finally, push all of our changes with git push . Danger: Note: The tags must be pushed explicitly in their own step!","title":"Step 2.3 - Test"},{"location":"using-lagoon-advanced/base-images/#how-git-tags-map-to-image-tags","text":"Danger: Important note: Depending on the build workflow, you will almost certainly push the changes via the develop branch before merging it into the main branch. An important point to remember here is that the Jenkins base image build process will tag images based on the most recent commit\u2019s tag . Images are tagged using the following rules, and images will be built for each of these that apply: When the main branch is built, it is tagged as latest . When the develop branch is built, it is tagged as development . If the commit being built is tagged then that branch will be built with that commit\u2019s tag. This is how we release a new version as we demonstrated above. It can also be used to make ad hoc builds with fairly arbitrary tags - be reasonable with the tag names, it has only been tested with semver tags.","title":"How Git tags map to image tags"},{"location":"using-lagoon-advanced/base-images/#step-4-building-the-new-base-images","text":"Note: Note: Generally you will have a trigger strategy set up here for automatic builds, but as that will differ based on your needs and setup, this explains how to build manually. Visit your Lagoon Jenkins instance. Select the project you are working on (in this case, AIOBI Drupal 8 Base). Click the branch you would like to build. Click \u201cBuild Now.\u201d This will kick off the build process which, if successful, will push up the new images to Harbor. If the build is not successful, you can click into the build itself and read the logs to understand where it failed. As shown in the screenshot below from Harbor, the image we\u2019ve just built in Jenkins has been uploaded and tagged in Harbor, where it will now be scanned for any vulnerabilities. Since it was tagged as v0.0.9, an image with that tag is present, and because we built the main branch, the \u201clatest\u201d image has also been built. At this stage, the v0.0.9 and \u201clatest\u201d images are identical.","title":"Step 4 - Building the new base images"},{"location":"using-lagoon-advanced/base-images/#acknowledgement","text":"The base image structure draws heavily (and, in fact, is a fork of) Denpal . It is based on the original Drupal Composer Template , but includes everything necessary to run on Lagoon (either the local development environment or on hosted Lagoon).","title":"Acknowledgement"},{"location":"using-lagoon-advanced/blackfire/","text":"Blackfire # Blackfire variables # The Lagoon Base Images have support for Blackfire included in the PHP Images (see the PHP images ). In order to use Blackfire in Lagoon, these three environment variables need to be defined: Environment Variable Default Description BLACKFIRE_ENABLED (not set) Used to enable blackfire extension with setting variable to TRUE or true BLACKFIRE_SERVER_ID (not set) Set to Blackfire Server ID provided by Blackfire.io. Needs BLACKFIRE_ENABLED set to true BLACKFIRE_SERVER_TOKEN (not set) Set to Blackfire Server Token provided by Blackfire.io. Needs BLACKFIRE_ENABLED set to true Local Usage of Blackfire # For local usage of Blackfire with Lagoon Images, set the above environment variables for the PHP container. Here is an example for a Drupal application: services: [[snip]] php: [[snip]] environment: << : *default-environment # loads the defined environment variables from the top BLACKFIRE_ENABLED: TRUE BLACKFIRE_SERVER_ID: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx BLACKFIRE_SERVER_TOKEN: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx After restarting the containers, you should be able to profile via the Blackfire Browser Plugin or the Blackfire CLI . Remote Usage of Blackfire # In order to use Blackfire in deployed Lagoon environments the same enviornment variables need to be set, this time via one of the possibilities of adding environment variables to Lagoon . Important: Environment variables set in the docker-compose.yaml for local development are not used by Lagoon in remote environments! Debugging # The Blackfire Agent running in the PHP containers outputs logs as normal container logs, which can be seen via docker-compose logs or via the Lagoon Logging Infrastructure for remote environments. By default the Logs are set to Level 3 (info), via the environment variable BLACKFIRE_LOG_LEVEL the level can be increased to 4 (debug) to generate more debugging ouput.","title":"Blackfire"},{"location":"using-lagoon-advanced/blackfire/#blackfire","text":"","title":"Blackfire"},{"location":"using-lagoon-advanced/blackfire/#blackfire-variables","text":"The Lagoon Base Images have support for Blackfire included in the PHP Images (see the PHP images ). In order to use Blackfire in Lagoon, these three environment variables need to be defined: Environment Variable Default Description BLACKFIRE_ENABLED (not set) Used to enable blackfire extension with setting variable to TRUE or true BLACKFIRE_SERVER_ID (not set) Set to Blackfire Server ID provided by Blackfire.io. Needs BLACKFIRE_ENABLED set to true BLACKFIRE_SERVER_TOKEN (not set) Set to Blackfire Server Token provided by Blackfire.io. Needs BLACKFIRE_ENABLED set to true","title":"Blackfire variables"},{"location":"using-lagoon-advanced/blackfire/#local-usage-of-blackfire","text":"For local usage of Blackfire with Lagoon Images, set the above environment variables for the PHP container. Here is an example for a Drupal application: services: [[snip]] php: [[snip]] environment: << : *default-environment # loads the defined environment variables from the top BLACKFIRE_ENABLED: TRUE BLACKFIRE_SERVER_ID: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx BLACKFIRE_SERVER_TOKEN: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx After restarting the containers, you should be able to profile via the Blackfire Browser Plugin or the Blackfire CLI .","title":"Local Usage of Blackfire"},{"location":"using-lagoon-advanced/blackfire/#remote-usage-of-blackfire","text":"In order to use Blackfire in deployed Lagoon environments the same enviornment variables need to be set, this time via one of the possibilities of adding environment variables to Lagoon . Important: Environment variables set in the docker-compose.yaml for local development are not used by Lagoon in remote environments!","title":"Remote Usage of Blackfire"},{"location":"using-lagoon-advanced/blackfire/#debugging","text":"The Blackfire Agent running in the PHP containers outputs logs as normal container logs, which can be seen via docker-compose logs or via the Lagoon Logging Infrastructure for remote environments. By default the Logs are set to Level 3 (info), via the environment variable BLACKFIRE_LOG_LEVEL the level can be increased to 4 (debug) to generate more debugging ouput.","title":"Debugging"},{"location":"using-lagoon-advanced/custom-tasks/","text":"Custom Tasks # Lagoon allows for the definition of custom tasks at environment, project, and group levels. This is presently accomplished through the GraphQL API and exposed in the UI. Defining a custom task # When defining a task you need to determine a number of things. Which task do you want to run? # In most cases, the custom task you will be running will be something that will be run in a shell on one of the containers in your application. For instance, in a NodeJS application, you may be interested in running a yarn audit in your node container. The command, in this case, would simply be yarn audit . Where will this task be run? # We have to define where this task will be run -- this means two things, first, which project or environment we'll be running the task in, and, second, which service. Let's say that we'd like for our yarn audit task to be available to run in any environment in a specific project (let's say the project's ID is 42 for this example). We will therefore specify the project's id when we create our task definition, as we will describe below. The second question regards which environment we want to target with our task. When you set up your project, you specify several services in your docker-compose.yml . We use this service name to determine where the command is actually executed. Who can run this task? # There are three levels of permissions to the task system corresponding to project roles. Guest, Developer, and Maintainer -- from most restrictive to least restrictive, with each role being able to invoke the tasks defined for the lower role (Developer can see Guest tasks, Maintainers can see all tasks). Defining a task # Tasks are defined by calling the \"addAdvancedTaskDefinition\" mutation. Importantly, this simply defines the task, it does not invoke it. It simply makes it avaliable to be run in an environment. Schematically, the call looks like this mutation addAdvancedTask { addAdvancedTaskDefinition(input:{ name: string, confirmationText: string, type: [COMMAND|IMAGE], [project|environment]: int, description: string, service: string, command: string, advancedTaskDefinitionArguments: [ { name: \"ENVIROMENT_VARIABLE_NAME\", displayName: \"Friendly Name For Variable\", type: [STRING | ENVIRONMENT_SOURCE_NAME] } ] }) { ... on AdvancedTaskDefinitionImage { id name description service image confirmationText advancedTaskDefinitionArguments { type range name displayName } ... } ... on AdvancedTaskDefinitionCommand { id name description service command advancedTaskDefinitionArguments { type range name displayName } ... } } } Fields name and description are straightforward. They're simply the name and description of the task - these are used primarily in the UI. The type field needs some explanation - for now, only platform admins are able to define IMAGE type commands - these allow for the running of specifically created task images as tasks, rather than targeting existing services. Most tasks, though, will be COMMAND types. The [project|environment] set of fields will attach the task to either the project or environment (depending on the key you use), with the value being the id. In the case we're considering for our yarn audit we will specify we're targeting a project with an id of 42 . We put the service we'd like to target with our task in the service field, and command is the actual command that we'd like to run. Arguments passed to tasks # In order to give more flexibility to the users invoking the tasks via the Lagoon UI, we support defining task arguments. These arguments are displayed as text boxes or drop downs and are required for the task to be invoked. Here is an example of how we might set up two arguments. advancedTaskDefinitionArguments: [ { name: \"ENV_VAR_NAME_SOURCE\", displayName: \"Environment source\", type: ENVIRONMENT_SOURCE_NAME }, { name: \"ENV_VAR_NAME_STRING\", displayName: \"Echo value\", type: STRING } ] }) This fragment shows both types of arguments the system currently supports. The first, ENV_VAR_NAME_SOURCE is an example of type ENVIRONMENT_SOURCE_NAME , which will present the user of the UI a dropdown of the different environments inside of a project. The second ENV_VAR_NAME_STRING is of type STRING and will present the user with a textbox to fill in. The values that the user selects will be available as environment variables in the COMMAND type tasks when the task is run. Confirmation # When the confirmationText field has text, it will be displayed with a confirmation modal in the UI before the user is able to run the task. Invoking the task # With the task now defined, the task should now show up in the tasks dropdown in the Lagoon UI. We are also able to invoke it via the GraphQL api by using the invokeTask mutation. mutation invokeTask { invokeRegisteredTask(advancedTaskDefinition: int, environment: int) { status } } Note that invokeTask will always invoke a task on a specific environment . Example # Let's now setup our yarn audit example. mutation runYarnAudit { addAdvancedTaskDefinition(input:{ name:\"Run yarn audit\", project: 42, type:COMMAND, permission:DEVELOPER, description: \"Runs a 'yarn audit'\", service:\"node\", command: \"yarn audit\"}) { id } } This, then, will define our task for our project (42). When we run this, we will get the id of the task definition back (for argument's sake, let's say it's 9 ) This task will now be available to run from the UI for anyone with the DEVELOPER or MAINTAINER role.","title":"Custom Tasks"},{"location":"using-lagoon-advanced/custom-tasks/#custom-tasks","text":"Lagoon allows for the definition of custom tasks at environment, project, and group levels. This is presently accomplished through the GraphQL API and exposed in the UI.","title":"Custom Tasks"},{"location":"using-lagoon-advanced/custom-tasks/#defining-a-custom-task","text":"When defining a task you need to determine a number of things.","title":"Defining a custom task"},{"location":"using-lagoon-advanced/custom-tasks/#which-task-do-you-want-to-run","text":"In most cases, the custom task you will be running will be something that will be run in a shell on one of the containers in your application. For instance, in a NodeJS application, you may be interested in running a yarn audit in your node container. The command, in this case, would simply be yarn audit .","title":"Which task do you want to run?"},{"location":"using-lagoon-advanced/custom-tasks/#where-will-this-task-be-run","text":"We have to define where this task will be run -- this means two things, first, which project or environment we'll be running the task in, and, second, which service. Let's say that we'd like for our yarn audit task to be available to run in any environment in a specific project (let's say the project's ID is 42 for this example). We will therefore specify the project's id when we create our task definition, as we will describe below. The second question regards which environment we want to target with our task. When you set up your project, you specify several services in your docker-compose.yml . We use this service name to determine where the command is actually executed.","title":"Where will this task be run?"},{"location":"using-lagoon-advanced/custom-tasks/#who-can-run-this-task","text":"There are three levels of permissions to the task system corresponding to project roles. Guest, Developer, and Maintainer -- from most restrictive to least restrictive, with each role being able to invoke the tasks defined for the lower role (Developer can see Guest tasks, Maintainers can see all tasks).","title":"Who can run this task?"},{"location":"using-lagoon-advanced/custom-tasks/#defining-a-task","text":"Tasks are defined by calling the \"addAdvancedTaskDefinition\" mutation. Importantly, this simply defines the task, it does not invoke it. It simply makes it avaliable to be run in an environment. Schematically, the call looks like this mutation addAdvancedTask { addAdvancedTaskDefinition(input:{ name: string, confirmationText: string, type: [COMMAND|IMAGE], [project|environment]: int, description: string, service: string, command: string, advancedTaskDefinitionArguments: [ { name: \"ENVIROMENT_VARIABLE_NAME\", displayName: \"Friendly Name For Variable\", type: [STRING | ENVIRONMENT_SOURCE_NAME] } ] }) { ... on AdvancedTaskDefinitionImage { id name description service image confirmationText advancedTaskDefinitionArguments { type range name displayName } ... } ... on AdvancedTaskDefinitionCommand { id name description service command advancedTaskDefinitionArguments { type range name displayName } ... } } } Fields name and description are straightforward. They're simply the name and description of the task - these are used primarily in the UI. The type field needs some explanation - for now, only platform admins are able to define IMAGE type commands - these allow for the running of specifically created task images as tasks, rather than targeting existing services. Most tasks, though, will be COMMAND types. The [project|environment] set of fields will attach the task to either the project or environment (depending on the key you use), with the value being the id. In the case we're considering for our yarn audit we will specify we're targeting a project with an id of 42 . We put the service we'd like to target with our task in the service field, and command is the actual command that we'd like to run.","title":"Defining a task"},{"location":"using-lagoon-advanced/custom-tasks/#arguments-passed-to-tasks","text":"In order to give more flexibility to the users invoking the tasks via the Lagoon UI, we support defining task arguments. These arguments are displayed as text boxes or drop downs and are required for the task to be invoked. Here is an example of how we might set up two arguments. advancedTaskDefinitionArguments: [ { name: \"ENV_VAR_NAME_SOURCE\", displayName: \"Environment source\", type: ENVIRONMENT_SOURCE_NAME }, { name: \"ENV_VAR_NAME_STRING\", displayName: \"Echo value\", type: STRING } ] }) This fragment shows both types of arguments the system currently supports. The first, ENV_VAR_NAME_SOURCE is an example of type ENVIRONMENT_SOURCE_NAME , which will present the user of the UI a dropdown of the different environments inside of a project. The second ENV_VAR_NAME_STRING is of type STRING and will present the user with a textbox to fill in. The values that the user selects will be available as environment variables in the COMMAND type tasks when the task is run.","title":"Arguments passed to tasks"},{"location":"using-lagoon-advanced/custom-tasks/#confirmation","text":"When the confirmationText field has text, it will be displayed with a confirmation modal in the UI before the user is able to run the task.","title":"Confirmation"},{"location":"using-lagoon-advanced/custom-tasks/#invoking-the-task","text":"With the task now defined, the task should now show up in the tasks dropdown in the Lagoon UI. We are also able to invoke it via the GraphQL api by using the invokeTask mutation. mutation invokeTask { invokeRegisteredTask(advancedTaskDefinition: int, environment: int) { status } } Note that invokeTask will always invoke a task on a specific environment .","title":"Invoking the task"},{"location":"using-lagoon-advanced/custom-tasks/#example","text":"Let's now setup our yarn audit example. mutation runYarnAudit { addAdvancedTaskDefinition(input:{ name:\"Run yarn audit\", project: 42, type:COMMAND, permission:DEVELOPER, description: \"Runs a 'yarn audit'\", service:\"node\", command: \"yarn audit\"}) { id } } This, then, will define our task for our project (42). When we run this, we will get the id of the task definition back (for argument's sake, let's say it's 9 ) This task will now be available to run from the UI for anyone with the DEVELOPER or MAINTAINER role.","title":"Example"},{"location":"using-lagoon-advanced/deploytarget-configs/","text":"DeployTarget Configurations # Danger: This is an alpha feature in Lagoon. The way DeployTarget Configurations work could change in future releases. If you decide to use this feature, you do at your own risk. DeployTarget Configurations are a way to define how a project can deploy to multiple clusters. This feature is useful when you have two clusters, one which could be dedicated for running Production workloads, and another that is used for running Development workloads. The configuration for these is not limited to just a Production/Development split though, so projects could perceivably target more than 1 specific cluster. The basic idea of a DeployTarget configuration is that it is a way to easily define how a project can deploy across multiple clusters. It uses the existing methods of checking if a environment is valid Important Information # Before going in to how to configure a project to leverage DeployTarget configurations, there are some things you need to know. Environments now have two new fields available to them to identify which DeployTarget(Kubernetes or Openshift) they have been created on. kubernetesNamespacePattern kubernetes Once an environment has been deployed to a specific DeployTarget, it will always deploy to this target, even if the DeployTarget configuration, or project configuration is modified. This offers some safety to existing environments by preventing changes to DeployTarget configurations from creating new environments on different clusters. This is a new feature that is part of Lagoon, not specifically for DeployTarget configurations. By default, if no DeployTarget configurations are associated to a project, that project will continue to use the existing methods to determine which environments to deploy. These are the following fields used for this. branches pullrequests kubernetesNamespacePattern kubernetes As soon as any DeployTarget configurations are added to a project, then all future deployments for this project will use these configurations. What is defined in the project is ignored, and overwritten to inform users that DeployTarget configurations are in use. DeployTarget configurations are weighted, which means that a DeployTarget configuration with a larger weight is prioritised over one with lower weight. The order in which they are returned by the query is the order they are used to determine where an environment should be deployed. Active/Standby environments can only be deployed to the same cluster, so your DeployTarget configuration must be able to deploy both those environments to the same target. Projects that leverage the promote feature of Lagoon must be aware that DeployTarget configurations are ignored for the destination environment. The destination environment will always be deployed to the same target that the source environment is on, your DeployTarget configuration MUST be configured correctly for this source environment. For safety, it is best to define both the source and destination environment in the same DeployTarget configuration branch regex. Configuration # To configure a project to use DeployTarget configurations, the first step is to add a configuration to a project. The following GraphQL mutation can be used, this particular example will add a DeployTarget configuration to the project with the project ID 1. It will allow only the branches that match the name main to be deployed, and pullrequests is set to false . This means no other branches will be able to deploy to this particular target, and no pullrequests will be deployed to this particular target. The deployTarget is ID 1, this could be a kubernetes cluster in a specific region, or designated for a specific type of workload (production or development). mutation addDeployTargetConfig{ addDeployTargetConfig(input:{ project: 1 branches: \"main\" pullrequests: \"false\" deployTarget: 1 weight: 1 }){ id weight branches pullrequests deployTargetProjectPattern deployTarget{ name id } project{ name } } } Note: deployTarget is an alias the Kubernetes or Openshift ID in the Lagoon API It is also possible to configure multiple DeployTarget configurations. The following GraphQL mutation can be used, this particular example will add a DeployTarget configuration to the same project as above. It will allow only the branches that regex match with ^feature/|^(dev|test|develop)$ to be deployed, and pullrequests is set to true so all pullrequests will reach this target. The targeted cluster in this example is ID 2, which is a completely different kubernetes cluster to what was defined above for the main branch. mutation addDeployTargetConfig{ addDeployTargetConfig(input:{ project: 1 branches: \"^feature/|^(dev|test|develop)$\" pullrequests: \"true\" deployTarget: 2 weight: 1 }){ id weight branches pullrequests deployTargetProjectPattern deployTarget{ name id } project{ name } } } Once these have been added to a project, you can return all the DeployTarget configurations for a project using the following query query deployTargetConfigsByProjectId{ deployTargetConfigsByProjectId(project:1){ id weight branches pullrequests deployTargetProjectPattern deployTarget{ name id } project{ name } } } # result: { \"data\": { \"deployTargetConfigsByProjectId\": [ { \"id\": 1, \"weight\": 1, \"branches\": \"main\", \"pullrequests\": \"false\", \"deployTargetProjectPattern\": null, \"deployTarget\": { \"name\": \"production-cluster\", \"id\": 1 }, \"project\": { \"name\": \"my-project\" } }, { \"id\": 2, \"weight\": 1, \"branches\": \"^feature/|^(dev|test|develop)$\", \"pullrequests\": \"true\", \"deployTargetProjectPattern\": null, \"deployTarget\": { \"name\": \"development-cluster\", \"id\": 2 }, \"project\": { \"name\": \"my-project\" } } ] } }","title":"DeployTarget Configs"},{"location":"using-lagoon-advanced/deploytarget-configs/#deploytarget-configurations","text":"Danger: This is an alpha feature in Lagoon. The way DeployTarget Configurations work could change in future releases. If you decide to use this feature, you do at your own risk. DeployTarget Configurations are a way to define how a project can deploy to multiple clusters. This feature is useful when you have two clusters, one which could be dedicated for running Production workloads, and another that is used for running Development workloads. The configuration for these is not limited to just a Production/Development split though, so projects could perceivably target more than 1 specific cluster. The basic idea of a DeployTarget configuration is that it is a way to easily define how a project can deploy across multiple clusters. It uses the existing methods of checking if a environment is valid","title":"DeployTarget Configurations"},{"location":"using-lagoon-advanced/deploytarget-configs/#important-information","text":"Before going in to how to configure a project to leverage DeployTarget configurations, there are some things you need to know. Environments now have two new fields available to them to identify which DeployTarget(Kubernetes or Openshift) they have been created on. kubernetesNamespacePattern kubernetes Once an environment has been deployed to a specific DeployTarget, it will always deploy to this target, even if the DeployTarget configuration, or project configuration is modified. This offers some safety to existing environments by preventing changes to DeployTarget configurations from creating new environments on different clusters. This is a new feature that is part of Lagoon, not specifically for DeployTarget configurations. By default, if no DeployTarget configurations are associated to a project, that project will continue to use the existing methods to determine which environments to deploy. These are the following fields used for this. branches pullrequests kubernetesNamespacePattern kubernetes As soon as any DeployTarget configurations are added to a project, then all future deployments for this project will use these configurations. What is defined in the project is ignored, and overwritten to inform users that DeployTarget configurations are in use. DeployTarget configurations are weighted, which means that a DeployTarget configuration with a larger weight is prioritised over one with lower weight. The order in which they are returned by the query is the order they are used to determine where an environment should be deployed. Active/Standby environments can only be deployed to the same cluster, so your DeployTarget configuration must be able to deploy both those environments to the same target. Projects that leverage the promote feature of Lagoon must be aware that DeployTarget configurations are ignored for the destination environment. The destination environment will always be deployed to the same target that the source environment is on, your DeployTarget configuration MUST be configured correctly for this source environment. For safety, it is best to define both the source and destination environment in the same DeployTarget configuration branch regex.","title":"Important Information"},{"location":"using-lagoon-advanced/deploytarget-configs/#configuration","text":"To configure a project to use DeployTarget configurations, the first step is to add a configuration to a project. The following GraphQL mutation can be used, this particular example will add a DeployTarget configuration to the project with the project ID 1. It will allow only the branches that match the name main to be deployed, and pullrequests is set to false . This means no other branches will be able to deploy to this particular target, and no pullrequests will be deployed to this particular target. The deployTarget is ID 1, this could be a kubernetes cluster in a specific region, or designated for a specific type of workload (production or development). mutation addDeployTargetConfig{ addDeployTargetConfig(input:{ project: 1 branches: \"main\" pullrequests: \"false\" deployTarget: 1 weight: 1 }){ id weight branches pullrequests deployTargetProjectPattern deployTarget{ name id } project{ name } } } Note: deployTarget is an alias the Kubernetes or Openshift ID in the Lagoon API It is also possible to configure multiple DeployTarget configurations. The following GraphQL mutation can be used, this particular example will add a DeployTarget configuration to the same project as above. It will allow only the branches that regex match with ^feature/|^(dev|test|develop)$ to be deployed, and pullrequests is set to true so all pullrequests will reach this target. The targeted cluster in this example is ID 2, which is a completely different kubernetes cluster to what was defined above for the main branch. mutation addDeployTargetConfig{ addDeployTargetConfig(input:{ project: 1 branches: \"^feature/|^(dev|test|develop)$\" pullrequests: \"true\" deployTarget: 2 weight: 1 }){ id weight branches pullrequests deployTargetProjectPattern deployTarget{ name id } project{ name } } } Once these have been added to a project, you can return all the DeployTarget configurations for a project using the following query query deployTargetConfigsByProjectId{ deployTargetConfigsByProjectId(project:1){ id weight branches pullrequests deployTargetProjectPattern deployTarget{ name id } project{ name } } } # result: { \"data\": { \"deployTargetConfigsByProjectId\": [ { \"id\": 1, \"weight\": 1, \"branches\": \"main\", \"pullrequests\": \"false\", \"deployTargetProjectPattern\": null, \"deployTarget\": { \"name\": \"production-cluster\", \"id\": 1 }, \"project\": { \"name\": \"my-project\" } }, { \"id\": 2, \"weight\": 1, \"branches\": \"^feature/|^(dev|test|develop)$\", \"pullrequests\": \"true\", \"deployTargetProjectPattern\": null, \"deployTarget\": { \"name\": \"development-cluster\", \"id\": 2 }, \"project\": { \"name\": \"my-project\" } } ] } }","title":"Configuration"},{"location":"using-lagoon-advanced/environment-idling/","text":"Environment Idling # What is the Environment Idler? # Lagoon automatically idles environments if they have been unused for a couple of hours. This is done in order to reduce the load on the Kubernetes clusters and improve the overall performance of production environments and development environments that are actually in use. How does an environment get idled? # The Environment Idler has many different configuration capabilities. Here are the defaults of a standard Lagoon installation (these could be quite different in your Lagoon, check with your Lagoon administrator!) Idling is tried every 4 hours. Production environments are never idled. CLI pods are idled if they don't include a cronjob and if there is no remote shell connection active. All other services and pods are idled if there was no traffic on the environment in the last 4 hours. If there is an active build happening, there will be no idling. How does an environment get un-idled? # The Lagoon Idler will automatically un-idle an environment as soon as it is visited, therefore just visiting any URL of the environment will start the environment. The un-idling will take a couple of seconds, as the Kubernetes cluster needs to start all containers again. During this time there will be waiting screen shown to the visitor that their environment is currently started. Can I disable / prevent the Idler from idling my environment? # Yes, there is a field autoIdle on the project (impacts all environments) and environment (if you need to target just 1 environment), as to whether idling is allowed to take place. A value of 1 indicates the project/environment is eligible for idling. If the project is set to 0 the environments will never be idled, even if the environment is set to 0 The default is always 1 (idling is enabled). Talk to your Lagoon administrator if you are unsure how to set these project/environment fields.","title":"Environment Idling"},{"location":"using-lagoon-advanced/environment-idling/#environment-idling","text":"","title":"Environment Idling"},{"location":"using-lagoon-advanced/environment-idling/#what-is-the-environment-idler","text":"Lagoon automatically idles environments if they have been unused for a couple of hours. This is done in order to reduce the load on the Kubernetes clusters and improve the overall performance of production environments and development environments that are actually in use.","title":"What is the Environment Idler?"},{"location":"using-lagoon-advanced/environment-idling/#how-does-an-environment-get-idled","text":"The Environment Idler has many different configuration capabilities. Here are the defaults of a standard Lagoon installation (these could be quite different in your Lagoon, check with your Lagoon administrator!) Idling is tried every 4 hours. Production environments are never idled. CLI pods are idled if they don't include a cronjob and if there is no remote shell connection active. All other services and pods are idled if there was no traffic on the environment in the last 4 hours. If there is an active build happening, there will be no idling.","title":"How does an environment get idled?"},{"location":"using-lagoon-advanced/environment-idling/#how-does-an-environment-get-un-idled","text":"The Lagoon Idler will automatically un-idle an environment as soon as it is visited, therefore just visiting any URL of the environment will start the environment. The un-idling will take a couple of seconds, as the Kubernetes cluster needs to start all containers again. During this time there will be waiting screen shown to the visitor that their environment is currently started.","title":"How does an environment get un-idled?"},{"location":"using-lagoon-advanced/environment-idling/#can-i-disable-prevent-the-idler-from-idling-my-environment","text":"Yes, there is a field autoIdle on the project (impacts all environments) and environment (if you need to target just 1 environment), as to whether idling is allowed to take place. A value of 1 indicates the project/environment is eligible for idling. If the project is set to 0 the environments will never be idled, even if the environment is set to 0 The default is always 1 (idling is enabled). Talk to your Lagoon administrator if you are unsure how to set these project/environment fields.","title":"Can I disable / prevent the Idler from idling my environment?"},{"location":"using-lagoon-advanced/environment-types/","text":"Environment Types # Lagoon currently differentiates between two different environment types: production and development . When setting up your project via the Lagoon GraphQL API, you can define a productionEnvironment . On every deployment Lagoon executes, it checks if the current environment name matches what is defined in productionEnvironment . If it does, Lagoon will mark this environment as the production environment. This happens in two locations: Within the GraphQL API itself. As an environment variable named LAGOON_ENVIRONMENT_TYPE in every container. But that's it. Lagoon itself handles development and production environments in exactly the same way (in the end we want as few differences of the environments as possible - that's the beauty of Lagoon). There are a couple of things that will use this information: By default, development environments are idled after 4 hours with no hits (don't worry, they wake up automatically). It is also possible for your Lagoon administrator to disable auto-idling on a per-environment basis, just ask! Our default Drupal settings.php files load additional settings files for development.settings.php and production.settings.php so you can define settings and configurations different per environment type. If you try to delete an environment that is defined as the production environment (either via webhooks or REST), Lagoon will politely refuse to delete the production environment, as it tries to prevent you from making a mistake. In order to delete a production environment, you can either change the productionEnvironment in the API or use the secret forceDeleteProductionEnvironment: true POST payload for the REST API. The Lagoon administrator might use the production environment information for some additional things. For example, at amazee.io we're calculating only the hits of the production environments to calculate the price of the hosting.","title":"Environment Types"},{"location":"using-lagoon-advanced/environment-types/#environment-types","text":"Lagoon currently differentiates between two different environment types: production and development . When setting up your project via the Lagoon GraphQL API, you can define a productionEnvironment . On every deployment Lagoon executes, it checks if the current environment name matches what is defined in productionEnvironment . If it does, Lagoon will mark this environment as the production environment. This happens in two locations: Within the GraphQL API itself. As an environment variable named LAGOON_ENVIRONMENT_TYPE in every container. But that's it. Lagoon itself handles development and production environments in exactly the same way (in the end we want as few differences of the environments as possible - that's the beauty of Lagoon). There are a couple of things that will use this information: By default, development environments are idled after 4 hours with no hits (don't worry, they wake up automatically). It is also possible for your Lagoon administrator to disable auto-idling on a per-environment basis, just ask! Our default Drupal settings.php files load additional settings files for development.settings.php and production.settings.php so you can define settings and configurations different per environment type. If you try to delete an environment that is defined as the production environment (either via webhooks or REST), Lagoon will politely refuse to delete the production environment, as it tries to prevent you from making a mistake. In order to delete a production environment, you can either change the productionEnvironment in the API or use the secret forceDeleteProductionEnvironment: true POST payload for the REST API. The Lagoon administrator might use the production environment information for some additional things. For example, at amazee.io we're calculating only the hits of the production environments to calculate the price of the hosting.","title":"Environment Types"},{"location":"using-lagoon-advanced/environment-variables/","text":"Environment Variables # It is common to store API tokens or credentials for applications in environment variables. Following best practices, those credentials are different per environment. We allow each environment to use a separate set of environment variables defined in environment variables or environment files. As there can be environment variables defined in either the Dockerfile or during runtime (via API environment variables), we have a hierarchy of environment variables: environment variables defined in lower numbers are stronger. Environment variables (defined via Lagoon API) - environment specific. Environment variables (defined via Lagoon API) - project-wide. Environment variables defined in Dockerfile ( ENV command). Environment variables defined in .lagoon.env.$LAGOON_GIT_BRANCH or .lagoon.env.$LAGOON_GIT_SAFE_BRANCH (if the file exists and where $LAGOON_GIT_BRANCH $LAGOON_GIT_SAFE_BRANCH are the name and safe name of the branch this Docker image has been built for), use this for overwriting variables for only specific branches. Environment variables defined in .lagoon.env (if it exists), use this for overwriting variables for all branches. Environment variables defined in .env . Environment variables defined in .env.defaults . .lagoon.env.$LAGOON_GIT_BRANCH , .lagoon.env.$LAGOON_GIT_SAFE_BRANCH , .env , and .env.defaults are all sourced by the individual containers themselves as part of running their entrypoint scripts. They are not read by Lagoon, but by the containers ENTRYPOINT scripts, which look for them in the containers working directory. If environment variables don't appear as expected, check if your container has a WORKDIR setting that points to somewhere else. Environment Variables (Lagoon API) # We suggest using the Lagoon API environment variable system for variables that you don't want to keep in your Git repo (like secrets or API keys), as they could be compromised by somebody having them on their local development environment or on the internet, etc. The Lagoon API allows you to define project-wide or environment-specific variables. Additionally, they can be defined for a scope-only build-time or runtime. They are all created via the Lagoon GraphQL API. Read more on how to use the GraphQL API in our GraphQL API documentation. Runtime Environment Variables (Lagoon API) # Runtime environment variables are automatically made available in all containers, but they are only added or updated after an environment has been re-deployed. This defines a project wide runtime variable (available in all environments) for the project with ID 463 : mutation addRuntimeEnv { addEnvVariable( input:{ type:PROJECT, typeId:463, scope:RUNTIME, name:\"MYVARIABLENAME\", value:\"MyVariableValue\" } ) { id } } This defines a environment ID 546 specific runtime variable (available only in that specific environment): mutation addRuntimeEnv { addEnvVariable( input:{ type:ENVIRONMENT, typeId:546, scope:RUNTIME, name:\"MYVARIABLENAME\", value:\"MyVariableValue\" } ) { id } } Build-time Environment Variables (Lagoon API) # Build-time environment variables are only available during a build and need to be consumed in Dockerfiles via: ARG MYVARIABLENAME This defines a project-wide build-time variable (available in all environments) for the project with ID 463 : mutation addBuildtimeEnv { addEnvVariable( input:{ type:PROJECT, typeId:463, scope:BUILD, name:\"MYVARIABLENAME\", value:\"MyVariableValue\"} ) { id } } This defines an environment ID 546 specific build-time variable (available only in that specific environment): mutation addBuildtimeEnv { addEnvVariable(input:{type:ENVIRONMENT, typeId:546, scope:BUILD, name:\"MYVARIABLENAME\", value:\"MyVariableValue\"}) { id } } Container registry environment variables are only available during a build and are used when attempting to log in to a private registry. They are used to store the password for the user defined in Specials \u00bb container-registries . They can be applied at the project or environment level. This defines a project-wide container registry variable (available in all environments) for the project with ID 463 : mutation addContainerRegistryEnv { addEnvVariable( input:{ type:PROJECT, typeId:463, scope:CONTAINER_REGISTRY, name:\"MY_OWN_REGISTRY_PASSWORD\", value:\"MySecretPassword\"}) ) { id } } This defines a environment id 546 specific container registry variable (available only in that specific environment): mutation addContainerRegistryEnv { addEnvVariable( input:{ type:ENVIRONMENT, typeId:546, scope:CONTAINER_REGISTRY, name:\"MY_OWN_REGISTRY_PASSWORD\", value:\"MySecretPassword\"} ) { id } } Environment Files (existing directly in the Git Repo) # If you have environment variables that can safely be saved within a Git repository, we suggest adding them directly into the Git repository in an environment file. These variables will also be available within local development environments and are therefore more portable. The syntax in the environment files is as following: myenvironment.env MYVARIABLENAME = \"MyVariableValue\" MVARIABLENUMBER = 4242 DB_USER = $DB_USERNAME # Redefine DB_USER with the value of DB_USERNAME e.g. if your application expects another variable name for the Lagoon-provided variables. .lagoon.env.$BRANCHNAME # If you want to define environment variables different per environment you can create a .lagoon.env.$BRANCHNAME e.g. for the main branch .lagoon.env.main . This helps you keeping environment variables apart between environments. .env and .env.defaults # .env and .env.defaults will act as the default values for environment variables if none other is defined. For example, as default environment variables for pull request environments (see Workflows ). Special Environment Variables # PHP_ERROR_REPORTING # This variable, if set, will define the logging level you would like PHP to use. If not supplied, it will be set dynamically based on whether this is a production or development environment. On production environments, this value defaults to E_ALL & ~E_DEPRECATED & ~E_STRICT & ~E_NOTICE . On development environments, this value defaults to E_ALL & ~E_DEPRECATED & ~E_STRICT . Custom Backup Settings # Lagoon can support custom backup locations and credentials for any project when all four of the following variables are set as BUILD type variables. Please note that any use of these variables means that all environment and db backups created and managed by Lagoon will be stored using these credentials, meaning that any interruption of these credentials' may lead to failed or inaccessible backups. LAGOON_BAAS_CUSTOM_BACKUP_ENDPOINT # Specify the S3 compatible endpoint where any Lagoon initiated backups should be stored. An example custom setting would be: http://10.144.1.224:9000 LAGOON_BAAS_CUSTOM_BACKUP_BUCKET # Specify the bucket name where any Lagoon initiated backups should be stored. An example custom setting would be: example-restore-bucket LAGOON_BAAS_CUSTOM_BACKUP_ACCESS_KEY # Specify the access key Lagoon should use to access the custom backup bucket. An example custom setting would be: AAAAAAAAAAAA12345 LAGOON_BAAS_CUSTOM_BACKUP_SECRET_KEY # Specify the secret key Lagoon should use to access the custom backup bucket. An example custom setting would be: 12345AAAAAAAAAAAA Custom Restore Location # Lagoon can support custom restore locations and credentials for any project when all four of the following variables are set as BUILD type variables. Please note that any use of these variables means that all environment and db backups restored by Lagoon will be stored using these credentials, meaning that any interruption of these credentials' access may lead to failed or inaccessible restored files. LAGOON_BAAS_CUSTOM_RESTORE_ENDPOINT # Specify the S3 compatible endpoint where any Lagoon initiated restores should be stored. An example custom setting would be: http://10.144.1.224:9000 LAGOON_BAAS_CUSTOM_RESTORE_BUCKET # Specify the bucket name where any Lagoon initiated restores should be stored. An example custom setting would be: example-restore-bucket LAGOON_BAAS_CUSTOM_RESTORE_ACCESS_KEY # Specify the access key Lagoon should use to access the custom restore bucket. An example custom setting would be: AAAAAAAAAAAA12345 LAGOON_BAAS_CUSTOM_RESTORE_SECRET_KEY # Specify the secret key Lagoon should use to access the custom restore bucket. An example custom setting would be: 12345AAAAAAAAAAAA","title":"Environment Variables"},{"location":"using-lagoon-advanced/environment-variables/#environment-variables","text":"It is common to store API tokens or credentials for applications in environment variables. Following best practices, those credentials are different per environment. We allow each environment to use a separate set of environment variables defined in environment variables or environment files. As there can be environment variables defined in either the Dockerfile or during runtime (via API environment variables), we have a hierarchy of environment variables: environment variables defined in lower numbers are stronger. Environment variables (defined via Lagoon API) - environment specific. Environment variables (defined via Lagoon API) - project-wide. Environment variables defined in Dockerfile ( ENV command). Environment variables defined in .lagoon.env.$LAGOON_GIT_BRANCH or .lagoon.env.$LAGOON_GIT_SAFE_BRANCH (if the file exists and where $LAGOON_GIT_BRANCH $LAGOON_GIT_SAFE_BRANCH are the name and safe name of the branch this Docker image has been built for), use this for overwriting variables for only specific branches. Environment variables defined in .lagoon.env (if it exists), use this for overwriting variables for all branches. Environment variables defined in .env . Environment variables defined in .env.defaults . .lagoon.env.$LAGOON_GIT_BRANCH , .lagoon.env.$LAGOON_GIT_SAFE_BRANCH , .env , and .env.defaults are all sourced by the individual containers themselves as part of running their entrypoint scripts. They are not read by Lagoon, but by the containers ENTRYPOINT scripts, which look for them in the containers working directory. If environment variables don't appear as expected, check if your container has a WORKDIR setting that points to somewhere else.","title":"Environment Variables"},{"location":"using-lagoon-advanced/environment-variables/#environment-variables-lagoon-api","text":"We suggest using the Lagoon API environment variable system for variables that you don't want to keep in your Git repo (like secrets or API keys), as they could be compromised by somebody having them on their local development environment or on the internet, etc. The Lagoon API allows you to define project-wide or environment-specific variables. Additionally, they can be defined for a scope-only build-time or runtime. They are all created via the Lagoon GraphQL API. Read more on how to use the GraphQL API in our GraphQL API documentation.","title":"Environment Variables (Lagoon API)"},{"location":"using-lagoon-advanced/environment-variables/#runtime-environment-variables-lagoon-api","text":"Runtime environment variables are automatically made available in all containers, but they are only added or updated after an environment has been re-deployed. This defines a project wide runtime variable (available in all environments) for the project with ID 463 : mutation addRuntimeEnv { addEnvVariable( input:{ type:PROJECT, typeId:463, scope:RUNTIME, name:\"MYVARIABLENAME\", value:\"MyVariableValue\" } ) { id } } This defines a environment ID 546 specific runtime variable (available only in that specific environment): mutation addRuntimeEnv { addEnvVariable( input:{ type:ENVIRONMENT, typeId:546, scope:RUNTIME, name:\"MYVARIABLENAME\", value:\"MyVariableValue\" } ) { id } }","title":"Runtime Environment Variables (Lagoon API)"},{"location":"using-lagoon-advanced/environment-variables/#build-time-environment-variables-lagoon-api","text":"Build-time environment variables are only available during a build and need to be consumed in Dockerfiles via: ARG MYVARIABLENAME This defines a project-wide build-time variable (available in all environments) for the project with ID 463 : mutation addBuildtimeEnv { addEnvVariable( input:{ type:PROJECT, typeId:463, scope:BUILD, name:\"MYVARIABLENAME\", value:\"MyVariableValue\"} ) { id } } This defines an environment ID 546 specific build-time variable (available only in that specific environment): mutation addBuildtimeEnv { addEnvVariable(input:{type:ENVIRONMENT, typeId:546, scope:BUILD, name:\"MYVARIABLENAME\", value:\"MyVariableValue\"}) { id } } Container registry environment variables are only available during a build and are used when attempting to log in to a private registry. They are used to store the password for the user defined in Specials \u00bb container-registries . They can be applied at the project or environment level. This defines a project-wide container registry variable (available in all environments) for the project with ID 463 : mutation addContainerRegistryEnv { addEnvVariable( input:{ type:PROJECT, typeId:463, scope:CONTAINER_REGISTRY, name:\"MY_OWN_REGISTRY_PASSWORD\", value:\"MySecretPassword\"}) ) { id } } This defines a environment id 546 specific container registry variable (available only in that specific environment): mutation addContainerRegistryEnv { addEnvVariable( input:{ type:ENVIRONMENT, typeId:546, scope:CONTAINER_REGISTRY, name:\"MY_OWN_REGISTRY_PASSWORD\", value:\"MySecretPassword\"} ) { id } }","title":"Build-time Environment Variables (Lagoon API)"},{"location":"using-lagoon-advanced/environment-variables/#environment-files-existing-directly-in-the-git-repo","text":"If you have environment variables that can safely be saved within a Git repository, we suggest adding them directly into the Git repository in an environment file. These variables will also be available within local development environments and are therefore more portable. The syntax in the environment files is as following: myenvironment.env MYVARIABLENAME = \"MyVariableValue\" MVARIABLENUMBER = 4242 DB_USER = $DB_USERNAME # Redefine DB_USER with the value of DB_USERNAME e.g. if your application expects another variable name for the Lagoon-provided variables.","title":"Environment Files (existing directly in the Git Repo)"},{"location":"using-lagoon-advanced/environment-variables/#lagoonenvbranchname","text":"If you want to define environment variables different per environment you can create a .lagoon.env.$BRANCHNAME e.g. for the main branch .lagoon.env.main . This helps you keeping environment variables apart between environments.","title":".lagoon.env.$BRANCHNAME"},{"location":"using-lagoon-advanced/environment-variables/#env-and-envdefaults","text":".env and .env.defaults will act as the default values for environment variables if none other is defined. For example, as default environment variables for pull request environments (see Workflows ).","title":".env and .env.defaults"},{"location":"using-lagoon-advanced/environment-variables/#special-environment-variables","text":"","title":"Special Environment Variables"},{"location":"using-lagoon-advanced/environment-variables/#php_error_reporting","text":"This variable, if set, will define the logging level you would like PHP to use. If not supplied, it will be set dynamically based on whether this is a production or development environment. On production environments, this value defaults to E_ALL & ~E_DEPRECATED & ~E_STRICT & ~E_NOTICE . On development environments, this value defaults to E_ALL & ~E_DEPRECATED & ~E_STRICT .","title":"PHP_ERROR_REPORTING"},{"location":"using-lagoon-advanced/environment-variables/#custom-backup-settings","text":"Lagoon can support custom backup locations and credentials for any project when all four of the following variables are set as BUILD type variables. Please note that any use of these variables means that all environment and db backups created and managed by Lagoon will be stored using these credentials, meaning that any interruption of these credentials' may lead to failed or inaccessible backups.","title":"Custom Backup Settings"},{"location":"using-lagoon-advanced/environment-variables/#lagoon_baas_custom_backup_endpoint","text":"Specify the S3 compatible endpoint where any Lagoon initiated backups should be stored. An example custom setting would be: http://10.144.1.224:9000","title":"LAGOON_BAAS_CUSTOM_BACKUP_ENDPOINT"},{"location":"using-lagoon-advanced/environment-variables/#lagoon_baas_custom_backup_bucket","text":"Specify the bucket name where any Lagoon initiated backups should be stored. An example custom setting would be: example-restore-bucket","title":"LAGOON_BAAS_CUSTOM_BACKUP_BUCKET"},{"location":"using-lagoon-advanced/environment-variables/#lagoon_baas_custom_backup_access_key","text":"Specify the access key Lagoon should use to access the custom backup bucket. An example custom setting would be: AAAAAAAAAAAA12345","title":"LAGOON_BAAS_CUSTOM_BACKUP_ACCESS_KEY"},{"location":"using-lagoon-advanced/environment-variables/#lagoon_baas_custom_backup_secret_key","text":"Specify the secret key Lagoon should use to access the custom backup bucket. An example custom setting would be: 12345AAAAAAAAAAAA","title":"LAGOON_BAAS_CUSTOM_BACKUP_SECRET_KEY"},{"location":"using-lagoon-advanced/environment-variables/#custom-restore-location","text":"Lagoon can support custom restore locations and credentials for any project when all four of the following variables are set as BUILD type variables. Please note that any use of these variables means that all environment and db backups restored by Lagoon will be stored using these credentials, meaning that any interruption of these credentials' access may lead to failed or inaccessible restored files.","title":"Custom Restore Location"},{"location":"using-lagoon-advanced/environment-variables/#lagoon_baas_custom_restore_endpoint","text":"Specify the S3 compatible endpoint where any Lagoon initiated restores should be stored. An example custom setting would be: http://10.144.1.224:9000","title":"LAGOON_BAAS_CUSTOM_RESTORE_ENDPOINT"},{"location":"using-lagoon-advanced/environment-variables/#lagoon_baas_custom_restore_bucket","text":"Specify the bucket name where any Lagoon initiated restores should be stored. An example custom setting would be: example-restore-bucket","title":"LAGOON_BAAS_CUSTOM_RESTORE_BUCKET"},{"location":"using-lagoon-advanced/environment-variables/#lagoon_baas_custom_restore_access_key","text":"Specify the access key Lagoon should use to access the custom restore bucket. An example custom setting would be: AAAAAAAAAAAA12345","title":"LAGOON_BAAS_CUSTOM_RESTORE_ACCESS_KEY"},{"location":"using-lagoon-advanced/environment-variables/#lagoon_baas_custom_restore_secret_key","text":"Specify the secret key Lagoon should use to access the custom restore bucket. An example custom setting would be: 12345AAAAAAAAAAAA","title":"LAGOON_BAAS_CUSTOM_RESTORE_SECRET_KEY"},{"location":"using-lagoon-advanced/graphql/","text":"GraphQL # Connect to GraphQL API # API interactions in Lagoon are done via GraphQL. In order to authenticate to the API, you need a JWT (JSON Web Token), which will authenticate you against the API via your SSH public key. To generate this token, use the remote shell via the token command: ssh -p [ PORT ] -t lagoon@ [ HOST ] token Example for amazee.io: ssh -p 32222 -t lagoon@ssh.lagoon.amazeeio.cloud token This will return a long string, which is the JWT token. We also need the URL of the API endpoint. Ask your Lagoon administrator for this. On amazee.io this is https://api.lagoon.amazeeio.cloud/graphql . Now we need a GraphQL client! Technically this is just HTTP, but we suggest GraphiQL. It has a nice UI that allows you to write GraphQL requests with autocomplete. Download, install and start it. [ GraphiQL App ] Enter the API endpoint URL. Then click on \"Edit HTTP Headers\" and add a new Header: \"Header name\": Authorization \"Header value\": Bearer [jwt token] (make sure that the JWT token has no spaces, that won't work) Close the HTTP Header overlay (press ESC) and now you are ready to make your first GraphQL Request! Enter this on the left window: query whatIsThere { allProjects { id gitUrl name branches pullrequests productionEnvironment environments { name environmentType } } } And press the \u25b6\ufe0f button (or press CTRL+ENTER). If all went well, you should see your first GraphQL response. Mutations # The Lagoon GraphQL API can not only display objects and create objects, but it also has the capability to update existing objects. All of Lagoon's GraphQL uses best practices. Mutation queries in GraphQL modify the data in the data store, and return a value. They can be used to insert, update, and delete data. Mutations are defined as a part of the schema. Update the branches to deploy within a project: mutation editProjectBranches { updateProject(input:{id:109, patch:{branches:\"^(prod|stage|dev|update)$\"}}) { id } } Update the production environment within a project: Note: Important: This requires a redeploy in order for all changes to be reflected in the containers. mutation editProjectProductionEnvironment { updateProject(input:{id:109, patch:{productionEnvironment:\"prod\"}}) { id } } You can also combine multiple changes into a single query: mutation editProjectProductionEnvironmentAndBranches { updateProject(input:{id:109, patch:{productionEnvironment:\"prod\", branches:\"^(prod|stage|dev|update)$\"}}) { id } }","title":"GraphQL"},{"location":"using-lagoon-advanced/graphql/#graphql","text":"","title":"GraphQL"},{"location":"using-lagoon-advanced/graphql/#connect-to-graphql-api","text":"API interactions in Lagoon are done via GraphQL. In order to authenticate to the API, you need a JWT (JSON Web Token), which will authenticate you against the API via your SSH public key. To generate this token, use the remote shell via the token command: ssh -p [ PORT ] -t lagoon@ [ HOST ] token Example for amazee.io: ssh -p 32222 -t lagoon@ssh.lagoon.amazeeio.cloud token This will return a long string, which is the JWT token. We also need the URL of the API endpoint. Ask your Lagoon administrator for this. On amazee.io this is https://api.lagoon.amazeeio.cloud/graphql . Now we need a GraphQL client! Technically this is just HTTP, but we suggest GraphiQL. It has a nice UI that allows you to write GraphQL requests with autocomplete. Download, install and start it. [ GraphiQL App ] Enter the API endpoint URL. Then click on \"Edit HTTP Headers\" and add a new Header: \"Header name\": Authorization \"Header value\": Bearer [jwt token] (make sure that the JWT token has no spaces, that won't work) Close the HTTP Header overlay (press ESC) and now you are ready to make your first GraphQL Request! Enter this on the left window: query whatIsThere { allProjects { id gitUrl name branches pullrequests productionEnvironment environments { name environmentType } } } And press the \u25b6\ufe0f button (or press CTRL+ENTER). If all went well, you should see your first GraphQL response.","title":"Connect to GraphQL API"},{"location":"using-lagoon-advanced/graphql/#mutations","text":"The Lagoon GraphQL API can not only display objects and create objects, but it also has the capability to update existing objects. All of Lagoon's GraphQL uses best practices. Mutation queries in GraphQL modify the data in the data store, and return a value. They can be used to insert, update, and delete data. Mutations are defined as a part of the schema. Update the branches to deploy within a project: mutation editProjectBranches { updateProject(input:{id:109, patch:{branches:\"^(prod|stage|dev|update)$\"}}) { id } } Update the production environment within a project: Note: Important: This requires a redeploy in order for all changes to be reflected in the containers. mutation editProjectProductionEnvironment { updateProject(input:{id:109, patch:{productionEnvironment:\"prod\"}}) { id } } You can also combine multiple changes into a single query: mutation editProjectProductionEnvironmentAndBranches { updateProject(input:{id:109, patch:{productionEnvironment:\"prod\", branches:\"^(prod|stage|dev|update)$\"}}) { id } }","title":"Mutations"},{"location":"using-lagoon-advanced/nodejs/","text":"Node.js Graceful Shutdown # Node.js has integrated web server capabilities. Plus, with Express , these can be extended even more. Unfortunately, Node.js does not handle shutting itself down very nicely out of the box. This causes many issues with containerized systems. The biggest issue is that when a Node.js container is told to shut down, it will immediately kill all active connections, and does not allow them to stop gracefully. This part explains how you can teach Node.js to behave like a real web server: finishing active requests and then gracefully shutting down. As an example we use a no-frills Node.js server with Express: const express = require ( 'express' ); const app = express (); // Adds a 5 sec delay for all requests. app . use (( req , res , next ) => setTimeout ( next , 5000 )); app . get ( '/' , function ( req , res ) { res . send ( \"Hello World\" ); }) const server = app . listen ( 3000 , function () { console . log ( 'Example app listening on port 3000!' ); }) This will just show \"Hello World\" in when the web server is visited at localhost:3000 . Note the 5 second delay in the response in order to simulate a request that takes some computing time. Part A: Allow requests to be finished. # If we run the above example and stop the Node.js process while the request is handled (within the 5 seconds), we will see that the Node.js server immediately kills the connection, and our browser will show an error. To explain to our Node.js server that it should wait for all the requests to be finished before actually stopping itself, we add the following code: const startGracefulShutdown = () => { console . log ( 'Starting shutdown of express...' ); server . close ( function () { console . log ( 'Express shut down.' ); }); } process . on ( 'SIGTERM' , startGracefulShutdown ); process . on ( 'SIGINT' , startGracefulShutdown ); This basically calls server.close() , which will instruct the Node.js HTTP server to: Not accept any more requests. Finish all running requests. It will do this on SIGINT (when you press CTRL + C ) or on SIGTERM (the standard signal for a process to terminate). With this small addition, our Node.js will wait until all requests are finished, and then stop itself. If we were not running Node.js in a containerized environment, we would probably want to include some additional code that actually kills the Node.js server after a couple of seconds, as it is technically possible that some requests are either taking very long or are never stopped. Because it is running in a containerized system, if the container is not stopped, Docker and Kubernetes will run a SIGKILL after a couple of seconds (usually 30) which cannot be handled by the process itself, so this is not a concern for us. Part B: Yarn and NPM children spawning issues # If we only implemented Part A, we would have a good experience. In the real world, many Node.js systems are built with Yarn or NPM, which provide not only package management systems to Node.js, but also script management. With these script functionalities, we simplify the start of our application. We can see many package.json files that look like: package.json { \"name\" : \"node\" , \"version\" : \"1.0.0\" , \"main\" : \"index.js\" , \"license\" : \"MIT\" , \"dependencies\" : { \"express\" : \"^4.15.3\" }, \"scripts\" : { \"start\" : \"node index.js\" } } and with the defined scripts section we can run our application just with: yarn start or npm start This is nice and makes the life of developers easier. So we also end up using the same within Dockerfiles: .dockerfile CMD [\"yarn\", \"start\"] Unfortunately there is a big problem with this: If yarn or npm get a SIGINT or SIGTERM signal, they correctly forward the signal to spawned child process (in this case node index.js ). However, it does not wait for the child processes to stop. Instead, yarn / npm immediately stop themselves. This signals to Docker/Kubernetes that the container is finished and Docker/Kubernetes will kill all children processes immediately. There are issues open for Yarn and NPM but unfortunately they are not solved yet. The solution for the problem is to not use Yarn or NPM to start your application and instead use node directly: CMD [\"node\", \"index.js\"] This allows Node.js to properly terminate and Docker/Kubernetes will wait for Node.js to be finished.","title":"Node.js Graceful Shutdown"},{"location":"using-lagoon-advanced/nodejs/#nodejs-graceful-shutdown","text":"Node.js has integrated web server capabilities. Plus, with Express , these can be extended even more. Unfortunately, Node.js does not handle shutting itself down very nicely out of the box. This causes many issues with containerized systems. The biggest issue is that when a Node.js container is told to shut down, it will immediately kill all active connections, and does not allow them to stop gracefully. This part explains how you can teach Node.js to behave like a real web server: finishing active requests and then gracefully shutting down. As an example we use a no-frills Node.js server with Express: const express = require ( 'express' ); const app = express (); // Adds a 5 sec delay for all requests. app . use (( req , res , next ) => setTimeout ( next , 5000 )); app . get ( '/' , function ( req , res ) { res . send ( \"Hello World\" ); }) const server = app . listen ( 3000 , function () { console . log ( 'Example app listening on port 3000!' ); }) This will just show \"Hello World\" in when the web server is visited at localhost:3000 . Note the 5 second delay in the response in order to simulate a request that takes some computing time.","title":"Node.js Graceful Shutdown"},{"location":"using-lagoon-advanced/nodejs/#part-a-allow-requests-to-be-finished","text":"If we run the above example and stop the Node.js process while the request is handled (within the 5 seconds), we will see that the Node.js server immediately kills the connection, and our browser will show an error. To explain to our Node.js server that it should wait for all the requests to be finished before actually stopping itself, we add the following code: const startGracefulShutdown = () => { console . log ( 'Starting shutdown of express...' ); server . close ( function () { console . log ( 'Express shut down.' ); }); } process . on ( 'SIGTERM' , startGracefulShutdown ); process . on ( 'SIGINT' , startGracefulShutdown ); This basically calls server.close() , which will instruct the Node.js HTTP server to: Not accept any more requests. Finish all running requests. It will do this on SIGINT (when you press CTRL + C ) or on SIGTERM (the standard signal for a process to terminate). With this small addition, our Node.js will wait until all requests are finished, and then stop itself. If we were not running Node.js in a containerized environment, we would probably want to include some additional code that actually kills the Node.js server after a couple of seconds, as it is technically possible that some requests are either taking very long or are never stopped. Because it is running in a containerized system, if the container is not stopped, Docker and Kubernetes will run a SIGKILL after a couple of seconds (usually 30) which cannot be handled by the process itself, so this is not a concern for us.","title":"Part A: Allow requests to be finished."},{"location":"using-lagoon-advanced/nodejs/#part-b-yarn-and-npm-children-spawning-issues","text":"If we only implemented Part A, we would have a good experience. In the real world, many Node.js systems are built with Yarn or NPM, which provide not only package management systems to Node.js, but also script management. With these script functionalities, we simplify the start of our application. We can see many package.json files that look like: package.json { \"name\" : \"node\" , \"version\" : \"1.0.0\" , \"main\" : \"index.js\" , \"license\" : \"MIT\" , \"dependencies\" : { \"express\" : \"^4.15.3\" }, \"scripts\" : { \"start\" : \"node index.js\" } } and with the defined scripts section we can run our application just with: yarn start or npm start This is nice and makes the life of developers easier. So we also end up using the same within Dockerfiles: .dockerfile CMD [\"yarn\", \"start\"] Unfortunately there is a big problem with this: If yarn or npm get a SIGINT or SIGTERM signal, they correctly forward the signal to spawned child process (in this case node index.js ). However, it does not wait for the child processes to stop. Instead, yarn / npm immediately stop themselves. This signals to Docker/Kubernetes that the container is finished and Docker/Kubernetes will kill all children processes immediately. There are issues open for Yarn and NPM but unfortunately they are not solved yet. The solution for the problem is to not use Yarn or NPM to start your application and instead use node directly: CMD [\"node\", \"index.js\"] This allows Node.js to properly terminate and Docker/Kubernetes will wait for Node.js to be finished.","title":"Part B: Yarn and NPM children spawning issues"},{"location":"using-lagoon-advanced/private-repositories/","text":"Private Repositories # Give the deploy key access to the git repositories in your Bitbucket/GitHub. Add ARG LAGOON_SSH_PRIVATE_KEY to your dockerfile (before the step of the build process that needs the SSH key). add RUN /lagoon/entrypoints/05-ssh-key.sh to your dockerfile (before the step of the build process that needs the SSH key). RUN /lagoon/entrypoints/05-ssh-key.sh && composer install && rm /home/.ssh/key","title":"Private Repositories"},{"location":"using-lagoon-advanced/private-repositories/#private-repositories","text":"Give the deploy key access to the git repositories in your Bitbucket/GitHub. Add ARG LAGOON_SSH_PRIVATE_KEY to your dockerfile (before the step of the build process that needs the SSH key). add RUN /lagoon/entrypoints/05-ssh-key.sh to your dockerfile (before the step of the build process that needs the SSH key). RUN /lagoon/entrypoints/05-ssh-key.sh && composer install && rm /home/.ssh/key","title":"Private Repositories"},{"location":"using-lagoon-advanced/project-default-users-keys/","text":"Project Default Users and SSH Keys # When a Lagoon project is created, by default an associated SSH \"project key\" is generated and the private key made available inside the CLI pods of the project. A service account default-user@project is also created and given MAINTAINER access to the project. The SSH \"project key\" is attached to that default-user@project . The result of this is that from inside the CLI pod of any environment it is possible to SSH to any other environment within the same project. This access is used for running tasks from the command line such as synchronising databases between environments (e.g. drush sql-sync ). There is more information on the MAINTAINER role available in the RBAC documentation. Specifying the project key # It is possible to specify an SSH private key when creating a project, but this is not recommended as it has security implications.","title":"Project Default Users and SSH Keys"},{"location":"using-lagoon-advanced/project-default-users-keys/#project-default-users-and-ssh-keys","text":"When a Lagoon project is created, by default an associated SSH \"project key\" is generated and the private key made available inside the CLI pods of the project. A service account default-user@project is also created and given MAINTAINER access to the project. The SSH \"project key\" is attached to that default-user@project . The result of this is that from inside the CLI pod of any environment it is possible to SSH to any other environment within the same project. This access is used for running tasks from the command line such as synchronising databases between environments (e.g. drush sql-sync ). There is more information on the MAINTAINER role available in the RBAC documentation.","title":"Project Default Users and SSH Keys"},{"location":"using-lagoon-advanced/project-default-users-keys/#specifying-the-project-key","text":"It is possible to specify an SSH private key when creating a project, but this is not recommended as it has security implications.","title":"Specifying the project key"},{"location":"using-lagoon-advanced/service-types/","text":"Service Types # The below lists all service types that can be defined via lagoon.type within a docker-compose.yml file . Note: Once a lagoon.type is defined and the environment is deployed, changing it to a different type is not supported and could result in a broken environment. basic # Basic container, good to use for most applications that don't have an existing template. No persistent storage. The port can be changed using a label Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter TCP connection on 3000 3000 Yes No lagoon.service.port basic-persistent # Like basic . Will generate persistent storage, defines mount location via lagoon.persistent . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter TCP connection on 3000 3000 Yes Yes lagoon.service.port , lagoon.persistent , lagoon.persistent.name , lagoon.persistent.size , lagoon.persistent.class cli # Use for any kind of CLI container (like PHP, Node.js, etc.). Automatically gets the customer SSH private key that is mounted in /var/run/secrets/lagoon/sshkey/ssh-privatekey . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter - No No No - cli-persistent # Like cli , expects lagoon.persistent.name to be given the name of a service that has persistent storage, which will be mounted under defined lagoon.persistent label. Does NOT generate its own persistent storage, only used to mount another service's persistent storage. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter - No No Yes lagoon.persistent.name , lagoon.persistent elasticsearch # Elasticsearch container, will auto-generate persistent storage under /usr/share/elasticsearch/data . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter HTTP on localhost:9200/_cluster/health?local=true 9200 No Yes lagoon.persistent.size kibana # Kibana container. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter TCP connection on 5601 5601 Yes No - logstash # Logstash container. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter TCP connection on 9600 9600 No No - mariadb # A meta-service which will tell Lagoon to automatically decide between mariadb-single and mariadb-dbaas . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter - - - - - mariadb-single # MariaDB container. Creates cron job for backups running every 24h executing /lagoon/mysql-backup.sh 127.0.0.1 . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter TCP connection on 3306 3306 No Yes lagoon.persistent.size mariadb-dbaas # Uses a shared MariaDB server via the DBaaS Operator. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter Not Needed 3306 No - - mongo # A meta-service which will tell Lagoon to automatically decide between mongo-single and mongo-dbaas . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter - - - - - mongo-single # MongoDB container, will generate persistent storage of min 1GB mounted at /data/db . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter TCP connection on 27017 27017 No Yes lagoon.persistent.size mongo-dbaas # Uses a shared MongoDB server via the DBaaS Operator. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter Not Needed 27017 No - - nginx # Nginx container. No persistent storage. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter localhost:50000/nginx_status 8080 Yes No - nginx-php # Like nginx , but additionally a php container. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter Nginx: localhost:50000/nginx_status , PHP: /usr/sbin/check_fcgi 8080 Yes No - nginx-php-persistent # Like nginx-php. Will generate persistent storage, defines mount location via lagoon.persistent . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter Nginx: localhost:50000/nginx_status , PHP: /usr/sbin/check_fcgi http on 8080 Yes Yes lagoon.persistent , lagoon.persistent.name , lagoon.persistent.size , lagoon.persistent.class node # Node.js container. No persistent storage. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter TCP connection on 3000 3000 Yes No - node-persistent # Like node . Will generate persistent storage, defines mount location via lagoon.persistent . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter TCP connection on 3000 3000 Yes Yes lagoon.persistent , lagoon.persistent.name , lagoon.persistent.size , lagoon.persistent.class none # Instructs Lagoon to completely ignore this service. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter - - - - - postgres # A meta-service which will tell Lagoon to automatically decide between postgres-single and postgres-dbaas . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter - - - - - postgres-single # Postgres container. Creates cron job for backups running every 24h executing /lagoon/postgres-backup.sh localhost . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter TCP connection on 5432 5432 No Yes lagoon.persistent.size postgres-dbaas # Uses a shared PostgreSQL server via the DBaaS Operator. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter Not Needed 5432 No - - python # Python container. No persistent storage. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter HTTP connection on 8800 8800 Yes No - python-persistent # Python container. With persistent storage. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter HTTP connection on 8800 8800 Yes Yes - redis # Redis container. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter TCP connection on 6379 6379 No No - redis-persistent # Redis container with auto-generated persistent storage mounted under /data . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter TCP connection on 6379 6379 No Yes lagoon.persistent.size solr # Solr container with auto-generated persistent storage mounted under /var/solr . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter TCP connection on 8983 8983 No Yes lagoon.persistent.size varnish # Varnish container. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter HTTP request localhost:8080/varnish_status 8080 Yes No - varnish-persistent # Varnish container with auto-generated persistent storage mounted under /var/cache/varnish . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter HTTP request localhost:8080/varnish_status 8080 Yes Yes lagoon.persistent.size worker # Use for any kind of worker container (like queue workers, etc.) where there is no exposed service port. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter - No No No - worker-persistent # Like worker , expects lagoon.persistent.name to be given the name of a service that has persistent storage, which will be mounted under defined lagoon.persistent label. Does NOT generate its own persistent storage, only used to mount another service's persistent storage. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter - No No Yes lagoon.persistent.name , lagoon.persistent","title":"Service Types"},{"location":"using-lagoon-advanced/service-types/#service-types","text":"The below lists all service types that can be defined via lagoon.type within a docker-compose.yml file . Note: Once a lagoon.type is defined and the environment is deployed, changing it to a different type is not supported and could result in a broken environment.","title":"Service Types"},{"location":"using-lagoon-advanced/service-types/#basic","text":"Basic container, good to use for most applications that don't have an existing template. No persistent storage. The port can be changed using a label Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter TCP connection on 3000 3000 Yes No lagoon.service.port","title":"basic"},{"location":"using-lagoon-advanced/service-types/#basic-persistent","text":"Like basic . Will generate persistent storage, defines mount location via lagoon.persistent . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter TCP connection on 3000 3000 Yes Yes lagoon.service.port , lagoon.persistent , lagoon.persistent.name , lagoon.persistent.size , lagoon.persistent.class","title":"basic-persistent"},{"location":"using-lagoon-advanced/service-types/#cli","text":"Use for any kind of CLI container (like PHP, Node.js, etc.). Automatically gets the customer SSH private key that is mounted in /var/run/secrets/lagoon/sshkey/ssh-privatekey . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter - No No No -","title":"cli"},{"location":"using-lagoon-advanced/service-types/#cli-persistent","text":"Like cli , expects lagoon.persistent.name to be given the name of a service that has persistent storage, which will be mounted under defined lagoon.persistent label. Does NOT generate its own persistent storage, only used to mount another service's persistent storage. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter - No No Yes lagoon.persistent.name , lagoon.persistent","title":"cli-persistent"},{"location":"using-lagoon-advanced/service-types/#elasticsearch","text":"Elasticsearch container, will auto-generate persistent storage under /usr/share/elasticsearch/data . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter HTTP on localhost:9200/_cluster/health?local=true 9200 No Yes lagoon.persistent.size","title":"elasticsearch"},{"location":"using-lagoon-advanced/service-types/#kibana","text":"Kibana container. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter TCP connection on 5601 5601 Yes No -","title":"kibana"},{"location":"using-lagoon-advanced/service-types/#logstash","text":"Logstash container. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter TCP connection on 9600 9600 No No -","title":"logstash"},{"location":"using-lagoon-advanced/service-types/#mariadb","text":"A meta-service which will tell Lagoon to automatically decide between mariadb-single and mariadb-dbaas . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter - - - - -","title":"mariadb"},{"location":"using-lagoon-advanced/service-types/#mariadb-single","text":"MariaDB container. Creates cron job for backups running every 24h executing /lagoon/mysql-backup.sh 127.0.0.1 . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter TCP connection on 3306 3306 No Yes lagoon.persistent.size","title":"mariadb-single"},{"location":"using-lagoon-advanced/service-types/#mariadb-dbaas","text":"Uses a shared MariaDB server via the DBaaS Operator. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter Not Needed 3306 No - -","title":"mariadb-dbaas"},{"location":"using-lagoon-advanced/service-types/#mongo","text":"A meta-service which will tell Lagoon to automatically decide between mongo-single and mongo-dbaas . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter - - - - -","title":"mongo"},{"location":"using-lagoon-advanced/service-types/#mongo-single","text":"MongoDB container, will generate persistent storage of min 1GB mounted at /data/db . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter TCP connection on 27017 27017 No Yes lagoon.persistent.size","title":"mongo-single"},{"location":"using-lagoon-advanced/service-types/#mongo-dbaas","text":"Uses a shared MongoDB server via the DBaaS Operator. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter Not Needed 27017 No - -","title":"mongo-dbaas"},{"location":"using-lagoon-advanced/service-types/#nginx","text":"Nginx container. No persistent storage. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter localhost:50000/nginx_status 8080 Yes No -","title":"nginx"},{"location":"using-lagoon-advanced/service-types/#nginx-php","text":"Like nginx , but additionally a php container. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter Nginx: localhost:50000/nginx_status , PHP: /usr/sbin/check_fcgi 8080 Yes No -","title":"nginx-php"},{"location":"using-lagoon-advanced/service-types/#nginx-php-persistent","text":"Like nginx-php. Will generate persistent storage, defines mount location via lagoon.persistent . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter Nginx: localhost:50000/nginx_status , PHP: /usr/sbin/check_fcgi http on 8080 Yes Yes lagoon.persistent , lagoon.persistent.name , lagoon.persistent.size , lagoon.persistent.class","title":"nginx-php-persistent"},{"location":"using-lagoon-advanced/service-types/#node","text":"Node.js container. No persistent storage. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter TCP connection on 3000 3000 Yes No -","title":"node"},{"location":"using-lagoon-advanced/service-types/#node-persistent","text":"Like node . Will generate persistent storage, defines mount location via lagoon.persistent . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter TCP connection on 3000 3000 Yes Yes lagoon.persistent , lagoon.persistent.name , lagoon.persistent.size , lagoon.persistent.class","title":"node-persistent"},{"location":"using-lagoon-advanced/service-types/#none","text":"Instructs Lagoon to completely ignore this service. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter - - - - -","title":"none"},{"location":"using-lagoon-advanced/service-types/#postgres","text":"A meta-service which will tell Lagoon to automatically decide between postgres-single and postgres-dbaas . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter - - - - -","title":"postgres"},{"location":"using-lagoon-advanced/service-types/#postgres-single","text":"Postgres container. Creates cron job for backups running every 24h executing /lagoon/postgres-backup.sh localhost . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter TCP connection on 5432 5432 No Yes lagoon.persistent.size","title":"postgres-single"},{"location":"using-lagoon-advanced/service-types/#postgres-dbaas","text":"Uses a shared PostgreSQL server via the DBaaS Operator. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter Not Needed 5432 No - -","title":"postgres-dbaas"},{"location":"using-lagoon-advanced/service-types/#python","text":"Python container. No persistent storage. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter HTTP connection on 8800 8800 Yes No -","title":"python"},{"location":"using-lagoon-advanced/service-types/#python-persistent","text":"Python container. With persistent storage. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter HTTP connection on 8800 8800 Yes Yes -","title":"python-persistent"},{"location":"using-lagoon-advanced/service-types/#redis","text":"Redis container. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter TCP connection on 6379 6379 No No -","title":"redis"},{"location":"using-lagoon-advanced/service-types/#redis-persistent","text":"Redis container with auto-generated persistent storage mounted under /data . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter TCP connection on 6379 6379 No Yes lagoon.persistent.size","title":"redis-persistent"},{"location":"using-lagoon-advanced/service-types/#solr","text":"Solr container with auto-generated persistent storage mounted under /var/solr . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter TCP connection on 8983 8983 No Yes lagoon.persistent.size","title":"solr"},{"location":"using-lagoon-advanced/service-types/#varnish","text":"Varnish container. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter HTTP request localhost:8080/varnish_status 8080 Yes No -","title":"varnish"},{"location":"using-lagoon-advanced/service-types/#varnish-persistent","text":"Varnish container with auto-generated persistent storage mounted under /var/cache/varnish . Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter HTTP request localhost:8080/varnish_status 8080 Yes Yes lagoon.persistent.size","title":"varnish-persistent"},{"location":"using-lagoon-advanced/service-types/#worker","text":"Use for any kind of worker container (like queue workers, etc.) where there is no exposed service port. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter - No No No -","title":"worker"},{"location":"using-lagoon-advanced/service-types/#worker-persistent","text":"Like worker , expects lagoon.persistent.name to be given the name of a service that has persistent storage, which will be mounted under defined lagoon.persistent label. Does NOT generate its own persistent storage, only used to mount another service's persistent storage. Healthcheck Exposed Ports Auto Generated Routes Storage Additional customization parameter - No No Yes lagoon.persistent.name , lagoon.persistent","title":"worker-persistent"},{"location":"using-lagoon-advanced/setting-up-xdebug-with-lagoon/","text":"Setting up Xdebug with Lagoon # Enable Xdebug Extension # The uselagoon base images are pre-configured with Xdebug but, for performance reasons, the extension is not loaded by default. To enable the extension, the XDEBUG_ENABLE environment variable must be set to true : Locally (pygmy and Lando) If your project is based off the lagoon-examples docker-compose.yml file, the environment variable already exists. Uncomment these lines: https://github.com/lagoon-examples/drupal9-base/blob/main/docker-compose.yml#L16-L17 . Make sure to rebuild and restart the containers after changing this setting. Remotely (dev/prod) You can use the Lagoon API to add the environment variable to a running environment . Make sure to redeploy the environment after changing this setting. Activate Xdebug Extension # The default Xdebug configuration requires a \"trigger\" to activate the extension and start a session. You can view the complete documentation for activating the debugger but the most straightforward instructions are below. CLI # The php-cli image is configured to always activate Xdebug when it\u2019s enabled, so there is nothing else that needs to be done. Running any PHP script will start a debugging session. Web # Install a browser extension to set/unset an activation cookie. Make sure the activation cookie is set for the website you want to start debugging. Configure PHPStorm # PHPStorm is configured correctly by default. Click the \u201c Start Listening for PHP Debug Connections \u201d icon in the toolbar. Load a webpage or run a Drush command. On first run, PHPStorm should pop up a window asking you to: Confirm path mappings. Select the correct file locally that was triggered on the server. Configure Visual Studio Code # Install the PHP Debug extension by Felix Becker. Follow the instructions to create a basic launch.json for PHP. Add correct path mappings. For a typical Drupal site, an example would be: \"pathMappings\": { \"/app\": \"${workspaceFolder}\", }, In the Run tab of Visual Studio Code, click the green arrow next to \u201c Listen for Xdebug \u201d Load a webpage or run a Drush command. Troubleshooting # Verify that Xdebug extension is loaded. The best way to do this on a Drupal site is to check the PHP status page. You should find a section about Xdebug and all its settings. Verify the following settings: Directive Local Value xdebug.mode debug xdebug.client_host host.docker.internal or your IP address xdebug.client_port 9003 Verify you have the activation cookie set. You can use the browser tools in Chrome or Firefox to check that a XDEBUG_SESSION cookie is set. Verify that Xdebug is activated and attempting to start a debug session with your computer. You can use the nc -l 9003 command line tool to open the Xdebug port. If everything is configured in PHP correctly, you should get a Xdebug init response when you load a webpage or run a Drush command. Verify that the xdebug.client_host has been set correctly. For local debugging with Docker for Mac, this value should be host.docker.internal . For remote debugging this value should be your IP address. If this value was not correctly determined, you can override it by setting the DOCKERHOST environment variable. Verify that Docker for Mac networking is not broken. On your host machine, run nc -l 9003 , then in a new terminal window, run: docker-compose run cli nc -zv host.docker.internal 9003 You should see a message like: host.docker.internal (192.168.65.2:9003) open . When using Lando locally, in order to debug scripts run from the CLI you must first SSH into the cli container via lando ssh . You won\u2019t be able to debug things by running lando drush or lando php . You can enable the Xdebug log by setting the XDEBUG_LOG environment variable. Logs will be saved to /tmp/xdebug.log . Xdebug 2 # If you're running older images you may still be using Xdebug version 2. All the information on this page still applies, but some of the configuration names and values have changes: v3 v2 xdebug.mode xdebug.remote_enabled On xdebug.client_host xdebug.remote_host host.docker.internal or your IP address xdebug.client_port xdebug.remote_port 9000","title":"Setting up Xdebug with Lagoon"},{"location":"using-lagoon-advanced/setting-up-xdebug-with-lagoon/#setting-up-xdebug-with-lagoon","text":"","title":"Setting up Xdebug with Lagoon"},{"location":"using-lagoon-advanced/setting-up-xdebug-with-lagoon/#enable-xdebug-extension","text":"The uselagoon base images are pre-configured with Xdebug but, for performance reasons, the extension is not loaded by default. To enable the extension, the XDEBUG_ENABLE environment variable must be set to true : Locally (pygmy and Lando) If your project is based off the lagoon-examples docker-compose.yml file, the environment variable already exists. Uncomment these lines: https://github.com/lagoon-examples/drupal9-base/blob/main/docker-compose.yml#L16-L17 . Make sure to rebuild and restart the containers after changing this setting. Remotely (dev/prod) You can use the Lagoon API to add the environment variable to a running environment . Make sure to redeploy the environment after changing this setting.","title":"Enable Xdebug Extension"},{"location":"using-lagoon-advanced/setting-up-xdebug-with-lagoon/#activate-xdebug-extension","text":"The default Xdebug configuration requires a \"trigger\" to activate the extension and start a session. You can view the complete documentation for activating the debugger but the most straightforward instructions are below.","title":"Activate Xdebug Extension"},{"location":"using-lagoon-advanced/setting-up-xdebug-with-lagoon/#cli","text":"The php-cli image is configured to always activate Xdebug when it\u2019s enabled, so there is nothing else that needs to be done. Running any PHP script will start a debugging session.","title":"CLI"},{"location":"using-lagoon-advanced/setting-up-xdebug-with-lagoon/#web","text":"Install a browser extension to set/unset an activation cookie. Make sure the activation cookie is set for the website you want to start debugging.","title":"Web"},{"location":"using-lagoon-advanced/setting-up-xdebug-with-lagoon/#configure-phpstorm","text":"PHPStorm is configured correctly by default. Click the \u201c Start Listening for PHP Debug Connections \u201d icon in the toolbar. Load a webpage or run a Drush command. On first run, PHPStorm should pop up a window asking you to: Confirm path mappings. Select the correct file locally that was triggered on the server.","title":"Configure PHPStorm"},{"location":"using-lagoon-advanced/setting-up-xdebug-with-lagoon/#configure-visual-studio-code","text":"Install the PHP Debug extension by Felix Becker. Follow the instructions to create a basic launch.json for PHP. Add correct path mappings. For a typical Drupal site, an example would be: \"pathMappings\": { \"/app\": \"${workspaceFolder}\", }, In the Run tab of Visual Studio Code, click the green arrow next to \u201c Listen for Xdebug \u201d Load a webpage or run a Drush command.","title":"Configure Visual Studio Code"},{"location":"using-lagoon-advanced/setting-up-xdebug-with-lagoon/#troubleshooting","text":"Verify that Xdebug extension is loaded. The best way to do this on a Drupal site is to check the PHP status page. You should find a section about Xdebug and all its settings. Verify the following settings: Directive Local Value xdebug.mode debug xdebug.client_host host.docker.internal or your IP address xdebug.client_port 9003 Verify you have the activation cookie set. You can use the browser tools in Chrome or Firefox to check that a XDEBUG_SESSION cookie is set. Verify that Xdebug is activated and attempting to start a debug session with your computer. You can use the nc -l 9003 command line tool to open the Xdebug port. If everything is configured in PHP correctly, you should get a Xdebug init response when you load a webpage or run a Drush command. Verify that the xdebug.client_host has been set correctly. For local debugging with Docker for Mac, this value should be host.docker.internal . For remote debugging this value should be your IP address. If this value was not correctly determined, you can override it by setting the DOCKERHOST environment variable. Verify that Docker for Mac networking is not broken. On your host machine, run nc -l 9003 , then in a new terminal window, run: docker-compose run cli nc -zv host.docker.internal 9003 You should see a message like: host.docker.internal (192.168.65.2:9003) open . When using Lando locally, in order to debug scripts run from the CLI you must first SSH into the cli container via lando ssh . You won\u2019t be able to debug things by running lando drush or lando php . You can enable the Xdebug log by setting the XDEBUG_LOG environment variable. Logs will be saved to /tmp/xdebug.log .","title":"Troubleshooting"},{"location":"using-lagoon-advanced/setting-up-xdebug-with-lagoon/#xdebug-2","text":"If you're running older images you may still be using Xdebug version 2. All the information on this page still applies, but some of the configuration names and values have changes: v3 v2 xdebug.mode xdebug.remote_enabled On xdebug.client_host xdebug.remote_host host.docker.internal or your IP address xdebug.client_port xdebug.remote_port 9000","title":"Xdebug 2"},{"location":"using-lagoon-advanced/simplesaml/","text":"SimpleSAML # SimpleSAMLphp # This is an example of how to add SimpleSAMLphp to your project and then modify configuration to serve it via NGINX. Requirements # Add SimpleSAMLphp to your project: $ composer req simplesamlphp/simplesamlphp Modify configuration for SimpleSAMLphp # Copy authsources.php and config.php from vendor/simplesamlphp/simplesamlphp/config-templates to somewhere outside vendor directory, such as conf/simplesamlphp . You also need saml20-idp-remote.php from vendor/simplesamlphp/simplesamlphp/metadata-templates . In config.php set following values for Lagoon: Base URL path where SimpleSAMLphp is accessed: 'baseurlpath' => 'https://YOUR_DOMAIN.TLD/simplesaml/', Store sessions to database: 'store.type' => 'sql', 'store.sql.dsn' => vsprintf('mysql:host=%s;port=%s;dbname=%s', [ getenv('MARIADB_HOST'), getenv('MARIADB_PORT'), getenv('MARIADB_DATABASE'), ]), Alter other settings to your liking: Check the paths for logs and certs. Secure SimpleSAMLphp dashboard Set up level of logging Set technicalcontact and timezone Add authsources (IdPs) to authsources.php , see example: authsources.php 'default-sp' => [ 'saml:SP', // The entity ID of this SP. 'entityID' => 'https://YOUR_DOMAIN.TLD', // The entity ID of the IdP this should SP should contact. // Can be NULL/unset, in which case the user will be shown a list of available IdPs. 'idp' => 'https://YOUR_IDP_DOMAIN.TLD', // The URL to the discovery service. // Can be NULL/unset, in which case a builtin discovery service will be used. 'discoURL' => null, 'NameIDFormat' => 'urn:oasis:names:tc:SAML:2.0:nameid-format:transient', 'certificate' => '/app/conf/simplesamlphp/certs/saml.crt', 'privatekey' => '/app/conf/simplesamlphp/certs/saml.pem', 'redirect.sign' => TRUE, 'redirect.validate' => TRUE, 'authproc' => [ 50 => [ 'class' => 'core:AttributeCopy', 'urn:oid:1.3.6.1.4.1.5923.1.1.1.6' => 'eduPersonPrincipalName', ], 51 => [ 'class' => 'core:AttributeCopy', 'urn:oid:2.5.4.42' => 'givenName', ], 52 => [ 'class' => 'core:AttributeCopy', 'urn:oid:2.5.4.4' => 'sn', ], 53 => [ 'class' => 'core:AttributeCopy', 'urn:oid:0.9.2342.19200300.100.1.3' => 'mail', ], ], ], Add IdP metadata to saml20-idp-remote.php , see example: <?php /** * SAML 2.0 remote IdP metadata for SimpleSAMLphp. * * Remember to remove the IdPs you don't use from this file. * * See: https://simplesamlphp.org/docs/stable/simplesamlphp-reference-idp-remote */ /** * Some IdP. */ $metadata['https://YOUR_IDP_DOMAIN.TLD'] = [ 'entityid' => 'https://YOUR_IDP_DOMAIN.TLD', 'name' => [ 'en' => 'Some IdP', ], 'description' => 'Some IdP', ... ]; In your build process, copy config files to SimpleSAMLphp: vendor/simplesamlphp/simplesamlphp/config/authsources.php vendor/simplesamlphp/simplesamlphp/config/config.php vendor/simplesamlphp/simplesamlphp/metadata/saml20-idp-remote.php Create NGINX conf for SimpleSAMLphp # Create file lagoon/nginx/location_prepend_simplesamlphp.conf : location\\_prepend\\_simplesamlphp.conf location ^~ /simplesaml { alias /app/vendor/simplesamlphp/simplesamlphp/www; location ~ ^(?<prefix>/simplesaml)(?<phpfile>.+?\\.php)(?<pathinfo>/.*)?$ { include fastcgi_params; fastcgi_pass ${NGINX_FASTCGI_PASS:-php}:9000; fastcgi_param SCRIPT_FILENAME $document_root$phpfile; # Must be prepended with the baseurlpath fastcgi_param SCRIPT_NAME /simplesaml$phpfile; fastcgi_param PATH_INFO $pathinfo if_not_empty; } } This will route /simplesaml URLs to SimpleSAMLphp in vendor. Add additional Nginx conf to Nginx image # Modify nginx.dockerfile and add location_prepend_simplesamlphp.conf to the image: nginx.dockerfile ARG CLI_IMAGE FROM ${CLI_IMAGE} as cli FROM amazeeio/nginx-drupal COPY --from=cli /app /app COPY lagoon/nginx/location_prepend_simplesamlphp.conf /etc/nginx/conf.d/drupal/location_prepend_simplesamlphp.conf RUN fix-permissions /etc/nginx/conf.d/drupal/location_prepend_simplesamlphp.conf # Define where the Drupal Root is located ENV WEBROOT=public","title":"SimpleSAML"},{"location":"using-lagoon-advanced/simplesaml/#simplesaml","text":"","title":"SimpleSAML"},{"location":"using-lagoon-advanced/simplesaml/#simplesamlphp","text":"This is an example of how to add SimpleSAMLphp to your project and then modify configuration to serve it via NGINX.","title":"SimpleSAMLphp"},{"location":"using-lagoon-advanced/simplesaml/#requirements","text":"Add SimpleSAMLphp to your project: $ composer req simplesamlphp/simplesamlphp","title":"Requirements"},{"location":"using-lagoon-advanced/simplesaml/#modify-configuration-for-simplesamlphp","text":"Copy authsources.php and config.php from vendor/simplesamlphp/simplesamlphp/config-templates to somewhere outside vendor directory, such as conf/simplesamlphp . You also need saml20-idp-remote.php from vendor/simplesamlphp/simplesamlphp/metadata-templates . In config.php set following values for Lagoon: Base URL path where SimpleSAMLphp is accessed: 'baseurlpath' => 'https://YOUR_DOMAIN.TLD/simplesaml/', Store sessions to database: 'store.type' => 'sql', 'store.sql.dsn' => vsprintf('mysql:host=%s;port=%s;dbname=%s', [ getenv('MARIADB_HOST'), getenv('MARIADB_PORT'), getenv('MARIADB_DATABASE'), ]), Alter other settings to your liking: Check the paths for logs and certs. Secure SimpleSAMLphp dashboard Set up level of logging Set technicalcontact and timezone Add authsources (IdPs) to authsources.php , see example: authsources.php 'default-sp' => [ 'saml:SP', // The entity ID of this SP. 'entityID' => 'https://YOUR_DOMAIN.TLD', // The entity ID of the IdP this should SP should contact. // Can be NULL/unset, in which case the user will be shown a list of available IdPs. 'idp' => 'https://YOUR_IDP_DOMAIN.TLD', // The URL to the discovery service. // Can be NULL/unset, in which case a builtin discovery service will be used. 'discoURL' => null, 'NameIDFormat' => 'urn:oasis:names:tc:SAML:2.0:nameid-format:transient', 'certificate' => '/app/conf/simplesamlphp/certs/saml.crt', 'privatekey' => '/app/conf/simplesamlphp/certs/saml.pem', 'redirect.sign' => TRUE, 'redirect.validate' => TRUE, 'authproc' => [ 50 => [ 'class' => 'core:AttributeCopy', 'urn:oid:1.3.6.1.4.1.5923.1.1.1.6' => 'eduPersonPrincipalName', ], 51 => [ 'class' => 'core:AttributeCopy', 'urn:oid:2.5.4.42' => 'givenName', ], 52 => [ 'class' => 'core:AttributeCopy', 'urn:oid:2.5.4.4' => 'sn', ], 53 => [ 'class' => 'core:AttributeCopy', 'urn:oid:0.9.2342.19200300.100.1.3' => 'mail', ], ], ], Add IdP metadata to saml20-idp-remote.php , see example: <?php /** * SAML 2.0 remote IdP metadata for SimpleSAMLphp. * * Remember to remove the IdPs you don't use from this file. * * See: https://simplesamlphp.org/docs/stable/simplesamlphp-reference-idp-remote */ /** * Some IdP. */ $metadata['https://YOUR_IDP_DOMAIN.TLD'] = [ 'entityid' => 'https://YOUR_IDP_DOMAIN.TLD', 'name' => [ 'en' => 'Some IdP', ], 'description' => 'Some IdP', ... ]; In your build process, copy config files to SimpleSAMLphp: vendor/simplesamlphp/simplesamlphp/config/authsources.php vendor/simplesamlphp/simplesamlphp/config/config.php vendor/simplesamlphp/simplesamlphp/metadata/saml20-idp-remote.php","title":"Modify configuration for SimpleSAMLphp"},{"location":"using-lagoon-advanced/simplesaml/#create-nginx-conf-for-simplesamlphp","text":"Create file lagoon/nginx/location_prepend_simplesamlphp.conf : location\\_prepend\\_simplesamlphp.conf location ^~ /simplesaml { alias /app/vendor/simplesamlphp/simplesamlphp/www; location ~ ^(?<prefix>/simplesaml)(?<phpfile>.+?\\.php)(?<pathinfo>/.*)?$ { include fastcgi_params; fastcgi_pass ${NGINX_FASTCGI_PASS:-php}:9000; fastcgi_param SCRIPT_FILENAME $document_root$phpfile; # Must be prepended with the baseurlpath fastcgi_param SCRIPT_NAME /simplesaml$phpfile; fastcgi_param PATH_INFO $pathinfo if_not_empty; } } This will route /simplesaml URLs to SimpleSAMLphp in vendor.","title":"Create NGINX conf for SimpleSAMLphp"},{"location":"using-lagoon-advanced/simplesaml/#add-additional-nginx-conf-to-nginx-image","text":"Modify nginx.dockerfile and add location_prepend_simplesamlphp.conf to the image: nginx.dockerfile ARG CLI_IMAGE FROM ${CLI_IMAGE} as cli FROM amazeeio/nginx-drupal COPY --from=cli /app /app COPY lagoon/nginx/location_prepend_simplesamlphp.conf /etc/nginx/conf.d/drupal/location_prepend_simplesamlphp.conf RUN fix-permissions /etc/nginx/conf.d/drupal/location_prepend_simplesamlphp.conf # Define where the Drupal Root is located ENV WEBROOT=public","title":"Add additional Nginx conf to Nginx image"},{"location":"using-lagoon-advanced/ssh/","text":"SSH # Lagoon allows you to connect to your running containers via SSH. The containers themselves don't actually have an SSH server installed, but instead you connect via SSH to Lagoon, which then itself creates a remote shell connection via the Kubernetes API for you. Ensure you are set up for SSH access # Generating an SSH Key # It is recommended to generate a separate SSH key for each device as opposed to sharing the same key between multiple computers. Instructions for generating an SSH key on various systems can be found below: OSX (Mac) Mac Linux (Ubuntu) # Linux Windows # Windows SSH Agent # OSX (Mac) # OSX does not have its SSH agent configured to load configured SSH keys at startup, which can cause some headaches. You can find a handy guide to configuring this capability here: https://www.backarapper.com/add-ssh-keys-to-ssh-agent-on-startup-in-macos/ Linux # Linux distributions vary in how they use the ssh-agent . You can find a general guide here: https://www.ssh.com/academy/ssh/agent Windows # SSH key support in Windows has improved markedly as of recently, and is now supported natively. A handy guide to configuring the Windows 10 SSH agent can be found here: https://richardballard.co.uk/ssh-keys-on-windows-10/ Uploading SSH Keys # Via the UI # You can upload your SSH key(s) through the UI. Login as you normally would. In the upper right hand corner, click on Settings: You will then see a page where you can upload your SSH key(s), and it will show any uploaded keys. Paste your key into the text box, give it a name, and click \"Add.\" That's it! Add additional keys as needed. Via Command Line # A general example of using the Lagoon API via GraphQL to add an SSH key to a user can be found here SSH into a pod # Connection # Connecting is straightforward and follows the following pattern: ssh -p [ PORT ] -t [ PROJECT-ENVIRONMENT-NAME ] @ [ HOST ] PORT - The remote shell SSH endpoint port (for amazee.io: 32222 ). HOST - The remote shell SSH endpoint host (for amazee.io ssh.lagoon.amazeeio.cloud ). PROJECT-ENVIRONMENT-NAME - The environment you want to connect to. This is most commonly in the pattern PROJECTNAME-ENVIRONMENT . As an example: ssh -p 32222 -t drupal-example-main@ssh.lagoon.amazeeio.cloud This will connect you to the project drupal-example on the environment main . Pod/Service, Container Definition # By default, the remote shell will try to connect you to the container defined with the type cli . If you would like to connect to another pod/service you can define it via: ssh -p [ PORT ] -t [ PROJECT-ENVIRONMENT-NAME ] @ [ HOST ] service =[ SERVICE-NAME ] If your pod/service contains multiple containers, Lagoon will connect you to the first defined container. You can also define the specific container to connect to via: ssh -p [ PORT ] -t [ PROJECT-ENVIRONMENT-NAME ] @ [ HOST ] service =[ SERVICE-NAME ] container =[ CONTAINER-NAME ] For example, to connect to the php container within the nginx pod: ssh -p 32222 -t drupal-example-main@ssh.lagoon.amazeeio.cloud service = nginx container = php Copying files # The common case of copying a file into your cli pod can be acheived with the usual SSH-compatible tools. scp # scp -o UserKnownHostsFile = /dev/null -o StrictHostKeyChecking = no -P 32222 [ local_path ] [ project_name ] - [ environment_name ] @ssh.lagoon.amazeeio.cloud: [ remote_path ] rsync # rsync --rsh = 'ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -p 32222' [ local_path ] [ project_name ] - [ environment_name ] @ssh.lagoon.amazeeio.cloud: [ remote_path ] Specifying non-CLI pod/service # In the rare case that you need to specify a non-CLI service this can be acheived with rsync using a ssh wrapper script to reorder the arguments in the manner required by Lagoon's SSH service: #!/usr/bin/env sh svc = $1 user = $3 host = $4 shift 4 exec ssh -o UserKnownHostsFile = /dev/null -o StrictHostKeyChecking = no -p 32222 -l \" $user \" \" $host \" \" $svc \" \" $@ \" Put that in an executable shell script rsh.sh and specify the service=... in the rsync command: rsync --rsh = \"/path/to/rsh.sh service=cli\" /tmp/foo [ project_name ] - [ environment_name ] @ssh.lagoon.amazeeio.cloud:/tmp/foo The script could also be adjusted to also handle a container=... argument.","title":"SSH"},{"location":"using-lagoon-advanced/ssh/#ssh","text":"Lagoon allows you to connect to your running containers via SSH. The containers themselves don't actually have an SSH server installed, but instead you connect via SSH to Lagoon, which then itself creates a remote shell connection via the Kubernetes API for you.","title":"SSH"},{"location":"using-lagoon-advanced/ssh/#ensure-you-are-set-up-for-ssh-access","text":"","title":"Ensure you are set up for SSH access"},{"location":"using-lagoon-advanced/ssh/#generating-an-ssh-key","text":"It is recommended to generate a separate SSH key for each device as opposed to sharing the same key between multiple computers. Instructions for generating an SSH key on various systems can be found below: OSX (Mac) Mac","title":"Generating an SSH Key"},{"location":"using-lagoon-advanced/ssh/#linux-ubuntu","text":"Linux","title":"Linux (Ubuntu)"},{"location":"using-lagoon-advanced/ssh/#windows","text":"Windows","title":"Windows"},{"location":"using-lagoon-advanced/ssh/#ssh-agent","text":"","title":"SSH Agent"},{"location":"using-lagoon-advanced/ssh/#osx-mac","text":"OSX does not have its SSH agent configured to load configured SSH keys at startup, which can cause some headaches. You can find a handy guide to configuring this capability here: https://www.backarapper.com/add-ssh-keys-to-ssh-agent-on-startup-in-macos/","title":"OSX (Mac)"},{"location":"using-lagoon-advanced/ssh/#linux","text":"Linux distributions vary in how they use the ssh-agent . You can find a general guide here: https://www.ssh.com/academy/ssh/agent","title":"Linux"},{"location":"using-lagoon-advanced/ssh/#windows_1","text":"SSH key support in Windows has improved markedly as of recently, and is now supported natively. A handy guide to configuring the Windows 10 SSH agent can be found here: https://richardballard.co.uk/ssh-keys-on-windows-10/","title":"Windows"},{"location":"using-lagoon-advanced/ssh/#uploading-ssh-keys","text":"","title":"Uploading SSH Keys"},{"location":"using-lagoon-advanced/ssh/#via-the-ui","text":"You can upload your SSH key(s) through the UI. Login as you normally would. In the upper right hand corner, click on Settings: You will then see a page where you can upload your SSH key(s), and it will show any uploaded keys. Paste your key into the text box, give it a name, and click \"Add.\" That's it! Add additional keys as needed.","title":"Via the UI"},{"location":"using-lagoon-advanced/ssh/#via-command-line","text":"A general example of using the Lagoon API via GraphQL to add an SSH key to a user can be found here","title":"Via Command Line"},{"location":"using-lagoon-advanced/ssh/#ssh-into-a-pod","text":"","title":"SSH into a pod"},{"location":"using-lagoon-advanced/ssh/#connection","text":"Connecting is straightforward and follows the following pattern: ssh -p [ PORT ] -t [ PROJECT-ENVIRONMENT-NAME ] @ [ HOST ] PORT - The remote shell SSH endpoint port (for amazee.io: 32222 ). HOST - The remote shell SSH endpoint host (for amazee.io ssh.lagoon.amazeeio.cloud ). PROJECT-ENVIRONMENT-NAME - The environment you want to connect to. This is most commonly in the pattern PROJECTNAME-ENVIRONMENT . As an example: ssh -p 32222 -t drupal-example-main@ssh.lagoon.amazeeio.cloud This will connect you to the project drupal-example on the environment main .","title":"Connection"},{"location":"using-lagoon-advanced/ssh/#podservice-container-definition","text":"By default, the remote shell will try to connect you to the container defined with the type cli . If you would like to connect to another pod/service you can define it via: ssh -p [ PORT ] -t [ PROJECT-ENVIRONMENT-NAME ] @ [ HOST ] service =[ SERVICE-NAME ] If your pod/service contains multiple containers, Lagoon will connect you to the first defined container. You can also define the specific container to connect to via: ssh -p [ PORT ] -t [ PROJECT-ENVIRONMENT-NAME ] @ [ HOST ] service =[ SERVICE-NAME ] container =[ CONTAINER-NAME ] For example, to connect to the php container within the nginx pod: ssh -p 32222 -t drupal-example-main@ssh.lagoon.amazeeio.cloud service = nginx container = php","title":"Pod/Service, Container Definition"},{"location":"using-lagoon-advanced/ssh/#copying-files","text":"The common case of copying a file into your cli pod can be acheived with the usual SSH-compatible tools.","title":"Copying files"},{"location":"using-lagoon-advanced/ssh/#scp","text":"scp -o UserKnownHostsFile = /dev/null -o StrictHostKeyChecking = no -P 32222 [ local_path ] [ project_name ] - [ environment_name ] @ssh.lagoon.amazeeio.cloud: [ remote_path ]","title":"scp"},{"location":"using-lagoon-advanced/ssh/#rsync","text":"rsync --rsh = 'ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -p 32222' [ local_path ] [ project_name ] - [ environment_name ] @ssh.lagoon.amazeeio.cloud: [ remote_path ]","title":"rsync"},{"location":"using-lagoon-advanced/ssh/#specifying-non-cli-podservice","text":"In the rare case that you need to specify a non-CLI service this can be acheived with rsync using a ssh wrapper script to reorder the arguments in the manner required by Lagoon's SSH service: #!/usr/bin/env sh svc = $1 user = $3 host = $4 shift 4 exec ssh -o UserKnownHostsFile = /dev/null -o StrictHostKeyChecking = no -p 32222 -l \" $user \" \" $host \" \" $svc \" \" $@ \" Put that in an executable shell script rsh.sh and specify the service=... in the rsync command: rsync --rsh = \"/path/to/rsh.sh service=cli\" /tmp/foo [ project_name ] - [ environment_name ] @ssh.lagoon.amazeeio.cloud:/tmp/foo The script could also be adjusted to also handle a container=... argument.","title":"Specifying non-CLI pod/service"},{"location":"using-lagoon-advanced/triggering-deployments/","text":"Triggering Deployments # Trigger a new deployment using Azure Pipelines # In order to automatically trigger new deployments using Azure Pipelines follow these instructions: Add your deployment SSH private key to Azure as a secure file as id_rsa_lagoon . For more information about Secure Files have a look at the Azure Documentation Site . Add the following configuration to your azure-pipelines.yml : azure-pipelines.yml pool: vmImage: 'ubuntu-latest' stages: # .. other stages - stage: Deploy condition: and(succeeded(), in(variables['Build.SourceBranch'], 'refs/heads/staging', 'refs/heads/develop')) jobs: - job: DeployLagoon steps: - task: DownloadSecureFile@1 name: lagoonSshKey displayName: 'Download Lagoon SSH key' inputs: secureFile: id_rsa_lagoon - script: | curl -L \"https://github.com/amazeeio/lagoon-cli/releases/download/0.9.2/lagoon-cli-0.9.2-linux-amd64\" -o ./lagoon chmod +x ./lagoon displayName: 'Download lagoon-cli' - script: ./lagoon login -i $(lagoonSshKey.secureFilePath) displayName: 'Log into Lagoon' - script: ./lagoon deploy branch -e $(Build.SourceBranchName) -p my-awesome-project -b $(Build.SourceBranchName) --force displayName: 'Trigger deployment using lagoon-cli' This will trigger a new deployment whenever changes are made on the develop or staging branch. Adjust these values accordingly so they fit your deployment strategy and configuration. Push without deploying # There may be a case where you want to push without a deployment. Make sure your commit message contains \" [skip deploy] \" or \" [deploy skip] \" and Lagoon will not trigger a deployment from that commit.","title":"Triggering Deployments"},{"location":"using-lagoon-advanced/triggering-deployments/#triggering-deployments","text":"","title":"Triggering Deployments"},{"location":"using-lagoon-advanced/triggering-deployments/#trigger-a-new-deployment-using-azure-pipelines","text":"In order to automatically trigger new deployments using Azure Pipelines follow these instructions: Add your deployment SSH private key to Azure as a secure file as id_rsa_lagoon . For more information about Secure Files have a look at the Azure Documentation Site . Add the following configuration to your azure-pipelines.yml : azure-pipelines.yml pool: vmImage: 'ubuntu-latest' stages: # .. other stages - stage: Deploy condition: and(succeeded(), in(variables['Build.SourceBranch'], 'refs/heads/staging', 'refs/heads/develop')) jobs: - job: DeployLagoon steps: - task: DownloadSecureFile@1 name: lagoonSshKey displayName: 'Download Lagoon SSH key' inputs: secureFile: id_rsa_lagoon - script: | curl -L \"https://github.com/amazeeio/lagoon-cli/releases/download/0.9.2/lagoon-cli-0.9.2-linux-amd64\" -o ./lagoon chmod +x ./lagoon displayName: 'Download lagoon-cli' - script: ./lagoon login -i $(lagoonSshKey.secureFilePath) displayName: 'Log into Lagoon' - script: ./lagoon deploy branch -e $(Build.SourceBranchName) -p my-awesome-project -b $(Build.SourceBranchName) --force displayName: 'Trigger deployment using lagoon-cli' This will trigger a new deployment whenever changes are made on the develop or staging branch. Adjust these values accordingly so they fit your deployment strategy and configuration.","title":"Trigger a new deployment using Azure Pipelines"},{"location":"using-lagoon-advanced/triggering-deployments/#push-without-deploying","text":"There may be a case where you want to push without a deployment. Make sure your commit message contains \" [skip deploy] \" or \" [deploy skip] \" and Lagoon will not trigger a deployment from that commit.","title":"Push without deploying"},{"location":"using-lagoon-advanced/workflows/","text":"Workflows # Lagoon tries to support any development workflow possible. It specifically does not enforce any workflows onto teams, so that each development team can define how they would like to develop and deploy their code. Fixed Branches # The most straightforward workflows are deployment-based on some fixed branches: You define which branches (like develop , staging and main , which would be ^(develop|staging|main)$ as regular expressions) that Lagoon should deploy and it will do so. Done! If you would like to test a new feature, merge them into a branch that you have set up locally and push, and Lagoon will deploy the feature and you can test. When all is good, merge the branch into your production branch and push. Feature Branches # A bit more advanced are feature branches. Since Lagoon supports the ability to define the branches you would like to deploy via regular expressions, you can also extend the above regular expression to this: ^feature\\/|^(staging|main)$ . This will instruct Lagoon to deploy all branches that start with feature/ , plus the branches called staging and main . Our development workflow could be as following: Create a new branch from main called feature/myfeature and push feature/myfeature . Lagoon will deploy the branch feature/myfeature as a new environment, where you can test your feature independently of any other features. Merge feature/myfeature into the main branch and it will deploy to your production environment. If you like, you can also merge feature/myfeature and any other feature branches into staging first, in order to test the functionality of multiple features together. After you have tested the features together on staging, you can merge the features into main. This workflow needs a high level of branch pruning and cleanliness in your Git repository. Since each feature branch will create its own Lagoon environment, you can have very quickly generate a LOT of environments, which all of them will use resources. Be sure to merge or delete unused branches. Because of this, it could make sense to think about a pull request based workflow. Pull requests # Even more advanced are workflows via pull requests. Such workflows need the support of a Git hosting which supports pull requests (also called merge requests). The idea of pull request-based workflows lies behind that idea that you can test a feature together with a target branch, without actually needing to merge yet, as Lagoon will do the merging for you during the build. In our example we would configure Lagoon to deploy the branches ^(staging|main)$ and the pull requests to .* (to deploy all pull requests). Now our workflow would be: Create a new branch from main called feature/myfeature and push feature/myfeature (no deployment will happen now because we have only specific staging and main as our branches to be deployed). Create a pull request in your Git hosting from feature/myfeature into main . Lagoon will now merge the feature/myfeature branch on top of the main branch and deploy that resulting code for you. Now you can test the functionality of the feature/myfeature branch just as if it had been merged into main , so all changes that have happened in main since you created the feature/myfeature branch from it will be there, and you don't need to worry that you might have an older version of the main branch. If there is a merge conflict, the build will fail, Lagoon will stop and notify you. After you have tested your pull request branch, you can go back to your Git hosting and actually merge the code into main . This will now trigger a deployment of main . When the pull request is merged, it is automatically closed and Lagoon will remove the environment for the pull request automatically. Some teams might opt to create the pull request against a shared staging branch and then merge the staging branch into the main branch via another pull request. This depends on the kind of Git workflow you're using. Additionally, in Lagoon you can define that only pull requests with a specific text in the title are deployed. [BUILD] defined as regular expression will only deploy pull requests that have a title like [BUILD] My Pull Request , while a pull request with that title My other Pull Request is not automatically deployed. This helps to keep the amount of environments small and allows for pull requests that don't need an environment yet. Automatic Database Sync for Pull requests # Automatic pull request environments are a fantastic thing. But it would also be handy to have the database synced from another environment when those environments are created. Lagoon can handle that! The following example will sync the staging database on the first rollout of the pull request environment: .lagoon.yml tasks : post-rollout : - run : name : IF no Drupal installed & Pullrequest = Sync database from staging command : | if [[ -n ${LAGOON_PR_BASE_BRANCH} ]] && tables=$(drush sqlq 'show tables;') && [ -z \"$tables\" ]; then drush -y sql-sync @staging default fi service : cli shell : bash Promotion # Another way of deploying your code into an environment is the promotion workflow. The idea behind the promotion workflow comes from this (as an example): If you merge the branch staging into the main branch, and if there are no changes to main , so main and staging have the exact same code in Git, it could still technically be possible that the resulting Docker images are slightly different. This is because it's possible that between the last staging deployment and the current main deployment, some upstream Docker images may have changed, or dependencies loaded from the various package managers may have changed. This is a very small chance, but it's there. For this situation, Lagoon understands the concept of promoting Lagoon images from one environment to another. This basically means that it will take the already built and deployed Docker images from one environment, and will use those exact same Docker images for another environment. In our example, we want to promote the Docker images from the main environment to the production environment: First, we need a regular deployed environment with the name main . Make sure that the environment has deployed successfully. Also, make sure that you don't have a branch called production in your Git repository. This could lead to weird confusions (like people pushing into this branch, etc.). Now trigger a promotion deployment via this curl request: curl -X POST \\ https://rest.lagoon.amazeeio.cloud/promote \\ -H 'Content-Type: application/json' \\ -d '{ \"projectName\":\"myproject\", \"sourceEnvironmentName\": \"main\", \"branchName\": \"production\" }' This tells Lagoon that you want to promote from the source main to the destination production (yes, it really uses branchName as destination, which is a bit unfortunate, but it will be fixed soon). Lagoon will now do the following: Checkout the Git branch main in order to load the .lagoon.yml and docker-compose.yml files (Lagoon still needs these in order to fully work). Create all Kubernetes/OpenShift objects for the defined services in docker-compose.yml , but with LAGOON_GIT_BRANCH=production as environment variable. Copy the newest Images from the main environment and use them (instead of building Images or tagging them from upstream). Run all post-rollout tasks like a normal deployment. You will receive the same notifications of success or failures like any other deployment.","title":"Workflows"},{"location":"using-lagoon-advanced/workflows/#workflows","text":"Lagoon tries to support any development workflow possible. It specifically does not enforce any workflows onto teams, so that each development team can define how they would like to develop and deploy their code.","title":"Workflows"},{"location":"using-lagoon-advanced/workflows/#fixed-branches","text":"The most straightforward workflows are deployment-based on some fixed branches: You define which branches (like develop , staging and main , which would be ^(develop|staging|main)$ as regular expressions) that Lagoon should deploy and it will do so. Done! If you would like to test a new feature, merge them into a branch that you have set up locally and push, and Lagoon will deploy the feature and you can test. When all is good, merge the branch into your production branch and push.","title":"Fixed Branches"},{"location":"using-lagoon-advanced/workflows/#feature-branches","text":"A bit more advanced are feature branches. Since Lagoon supports the ability to define the branches you would like to deploy via regular expressions, you can also extend the above regular expression to this: ^feature\\/|^(staging|main)$ . This will instruct Lagoon to deploy all branches that start with feature/ , plus the branches called staging and main . Our development workflow could be as following: Create a new branch from main called feature/myfeature and push feature/myfeature . Lagoon will deploy the branch feature/myfeature as a new environment, where you can test your feature independently of any other features. Merge feature/myfeature into the main branch and it will deploy to your production environment. If you like, you can also merge feature/myfeature and any other feature branches into staging first, in order to test the functionality of multiple features together. After you have tested the features together on staging, you can merge the features into main. This workflow needs a high level of branch pruning and cleanliness in your Git repository. Since each feature branch will create its own Lagoon environment, you can have very quickly generate a LOT of environments, which all of them will use resources. Be sure to merge or delete unused branches. Because of this, it could make sense to think about a pull request based workflow.","title":"Feature Branches"},{"location":"using-lagoon-advanced/workflows/#pull-requests","text":"Even more advanced are workflows via pull requests. Such workflows need the support of a Git hosting which supports pull requests (also called merge requests). The idea of pull request-based workflows lies behind that idea that you can test a feature together with a target branch, without actually needing to merge yet, as Lagoon will do the merging for you during the build. In our example we would configure Lagoon to deploy the branches ^(staging|main)$ and the pull requests to .* (to deploy all pull requests). Now our workflow would be: Create a new branch from main called feature/myfeature and push feature/myfeature (no deployment will happen now because we have only specific staging and main as our branches to be deployed). Create a pull request in your Git hosting from feature/myfeature into main . Lagoon will now merge the feature/myfeature branch on top of the main branch and deploy that resulting code for you. Now you can test the functionality of the feature/myfeature branch just as if it had been merged into main , so all changes that have happened in main since you created the feature/myfeature branch from it will be there, and you don't need to worry that you might have an older version of the main branch. If there is a merge conflict, the build will fail, Lagoon will stop and notify you. After you have tested your pull request branch, you can go back to your Git hosting and actually merge the code into main . This will now trigger a deployment of main . When the pull request is merged, it is automatically closed and Lagoon will remove the environment for the pull request automatically. Some teams might opt to create the pull request against a shared staging branch and then merge the staging branch into the main branch via another pull request. This depends on the kind of Git workflow you're using. Additionally, in Lagoon you can define that only pull requests with a specific text in the title are deployed. [BUILD] defined as regular expression will only deploy pull requests that have a title like [BUILD] My Pull Request , while a pull request with that title My other Pull Request is not automatically deployed. This helps to keep the amount of environments small and allows for pull requests that don't need an environment yet.","title":"Pull requests"},{"location":"using-lagoon-advanced/workflows/#automatic-database-sync-for-pull-requests","text":"Automatic pull request environments are a fantastic thing. But it would also be handy to have the database synced from another environment when those environments are created. Lagoon can handle that! The following example will sync the staging database on the first rollout of the pull request environment: .lagoon.yml tasks : post-rollout : - run : name : IF no Drupal installed & Pullrequest = Sync database from staging command : | if [[ -n ${LAGOON_PR_BASE_BRANCH} ]] && tables=$(drush sqlq 'show tables;') && [ -z \"$tables\" ]; then drush -y sql-sync @staging default fi service : cli shell : bash","title":"Automatic Database Sync for Pull requests"},{"location":"using-lagoon-advanced/workflows/#promotion","text":"Another way of deploying your code into an environment is the promotion workflow. The idea behind the promotion workflow comes from this (as an example): If you merge the branch staging into the main branch, and if there are no changes to main , so main and staging have the exact same code in Git, it could still technically be possible that the resulting Docker images are slightly different. This is because it's possible that between the last staging deployment and the current main deployment, some upstream Docker images may have changed, or dependencies loaded from the various package managers may have changed. This is a very small chance, but it's there. For this situation, Lagoon understands the concept of promoting Lagoon images from one environment to another. This basically means that it will take the already built and deployed Docker images from one environment, and will use those exact same Docker images for another environment. In our example, we want to promote the Docker images from the main environment to the production environment: First, we need a regular deployed environment with the name main . Make sure that the environment has deployed successfully. Also, make sure that you don't have a branch called production in your Git repository. This could lead to weird confusions (like people pushing into this branch, etc.). Now trigger a promotion deployment via this curl request: curl -X POST \\ https://rest.lagoon.amazeeio.cloud/promote \\ -H 'Content-Type: application/json' \\ -d '{ \"projectName\":\"myproject\", \"sourceEnvironmentName\": \"main\", \"branchName\": \"production\" }' This tells Lagoon that you want to promote from the source main to the destination production (yes, it really uses branchName as destination, which is a bit unfortunate, but it will be fixed soon). Lagoon will now do the following: Checkout the Git branch main in order to load the .lagoon.yml and docker-compose.yml files (Lagoon still needs these in order to fully work). Create all Kubernetes/OpenShift objects for the defined services in docker-compose.yml , but with LAGOON_GIT_BRANCH=production as environment variable. Copy the newest Images from the main environment and use them (instead of building Images or tagging them from upstream). Run all post-rollout tasks like a normal deployment. You will receive the same notifications of success or failures like any other deployment.","title":"Promotion"},{"location":"using-lagoon-the-basics/","text":"Overview # Requirements # Docker # To run a Lagoon Project, your system must meet the requirements to run Docker. We suggest installing the latest version of Docker for your workstation. You can download Docker here . We also suggest allowing Docker at least 4 CPUs and 4 GB RAM . Local Development Environments # TL;DR: install and start pygmy : brew tap pygmystack/pygmy ; brew install pygmy ; pygmy up Pygmy is a container stack for local development, developed collaboratively with the Lagoon team. Learn more about Lagoon, pygmy, and Local Development Environments Step by Step Guides # General: set up a new project in Lagoon General: first deployment Drupal: first deployment in Drupal Drupal: Lagoonize your Drupal site All: build and deployment process of Lagoon Overview of Lagoon Configuration Files # .lagoon.yml # This is the main file that will be used by Lagoon to understand what should be deployed, as well as many other things. See documentation for .lagoon.yml . docker-compose.yml # This file is used by Docker Compose to start your local development environment. Lagoon also uses it to understand which of the services should be deployed, which type, and how to build them. This happens via labels . See documentation for docker-compose.yml . Dockerfiles # Some Docker images and containers need additional customizations from the provided images. This usually has two reasons: Application code : Containers like NGINX, PHP, Node.js, etc., need the actual programming code within their images. This is done during a Docker build step, which is configured in a Dockerfile. Lagoon has full support for Docker, and therefore also allows you full control over the resulting images via Dockerfile customizations. Customization of images : Lagoon also allows you to customize the base images according to your needs. This can be to inject an additional environment variable, change a service configuration, or even install additional tools. We advise caution with installing additional tools to the Docker images, as you will need to maintain any adaptions in the future! Supported Services & Base Images by Lagoon # Type Versions Dockerfile MariaDB 10.4 mariadb/Dockerfile PostgreSQL 11, 12 postgres/Dockerfile MongoDB 3.6 mongo/Dockerfile NGINX openresty/1.19 nginx/Dockerfile Node.js 10, 12, 14 node/Dockerfile PHP FPM 7.2, 7.3, 7.4 php/fpm/Dockerfile PHP CLI 7.2, 7.3, 7.4 php/cli/Dockerfile Python 2.7, 3.7, 3.8 python/Dockerfile Redis 5, 6 redis/Dockerfile Redis-persistent 5, 6 redis-persistent/Dockerfile Solr 5.5, 6.6, 7.7 solr/Dockerfile Varnish 5 varnish/Dockerfile Elasticsearch 6, 7 elasticsearch/Dockerfiles Logstash 6, 7 logstash/Dockerfiles Kibana 6, 7 kibana/Dockerfiles RabbitMQ 3.8 rabbitmq/Dockerfile All images are pushed to https://hub.docker.com/u/uselagoon . We suggest always using the latest tag (like uselagoon/nginx:latest ) or unsuffixed images (like amazeeio/node:14 ), as they are kept up to date in terms of features and security. If you choose to use a specific Lagoon version of an image like uselagoon/nginx:20.10.0 or uselagoon/node-10:20.10.0 it is your own responsibility to upgrade the version of the images as soon as a new Lagoon version is released!","title":"Overview"},{"location":"using-lagoon-the-basics/#overview","text":"","title":"Overview"},{"location":"using-lagoon-the-basics/#requirements","text":"","title":"Requirements"},{"location":"using-lagoon-the-basics/#docker","text":"To run a Lagoon Project, your system must meet the requirements to run Docker. We suggest installing the latest version of Docker for your workstation. You can download Docker here . We also suggest allowing Docker at least 4 CPUs and 4 GB RAM .","title":"Docker"},{"location":"using-lagoon-the-basics/#local-development-environments","text":"TL;DR: install and start pygmy : brew tap pygmystack/pygmy ; brew install pygmy ; pygmy up Pygmy is a container stack for local development, developed collaboratively with the Lagoon team. Learn more about Lagoon, pygmy, and Local Development Environments","title":"Local Development Environments"},{"location":"using-lagoon-the-basics/#step-by-step-guides","text":"General: set up a new project in Lagoon General: first deployment Drupal: first deployment in Drupal Drupal: Lagoonize your Drupal site All: build and deployment process of Lagoon","title":"Step by Step Guides"},{"location":"using-lagoon-the-basics/#overview-of-lagoon-configuration-files","text":"","title":"Overview of Lagoon Configuration Files"},{"location":"using-lagoon-the-basics/#lagoonyml","text":"This is the main file that will be used by Lagoon to understand what should be deployed, as well as many other things. See documentation for .lagoon.yml .","title":".lagoon.yml"},{"location":"using-lagoon-the-basics/#docker-composeyml","text":"This file is used by Docker Compose to start your local development environment. Lagoon also uses it to understand which of the services should be deployed, which type, and how to build them. This happens via labels . See documentation for docker-compose.yml .","title":"docker-compose.yml"},{"location":"using-lagoon-the-basics/#dockerfiles","text":"Some Docker images and containers need additional customizations from the provided images. This usually has two reasons: Application code : Containers like NGINX, PHP, Node.js, etc., need the actual programming code within their images. This is done during a Docker build step, which is configured in a Dockerfile. Lagoon has full support for Docker, and therefore also allows you full control over the resulting images via Dockerfile customizations. Customization of images : Lagoon also allows you to customize the base images according to your needs. This can be to inject an additional environment variable, change a service configuration, or even install additional tools. We advise caution with installing additional tools to the Docker images, as you will need to maintain any adaptions in the future!","title":"Dockerfiles"},{"location":"using-lagoon-the-basics/#supported-services-base-images-by-lagoon","text":"Type Versions Dockerfile MariaDB 10.4 mariadb/Dockerfile PostgreSQL 11, 12 postgres/Dockerfile MongoDB 3.6 mongo/Dockerfile NGINX openresty/1.19 nginx/Dockerfile Node.js 10, 12, 14 node/Dockerfile PHP FPM 7.2, 7.3, 7.4 php/fpm/Dockerfile PHP CLI 7.2, 7.3, 7.4 php/cli/Dockerfile Python 2.7, 3.7, 3.8 python/Dockerfile Redis 5, 6 redis/Dockerfile Redis-persistent 5, 6 redis-persistent/Dockerfile Solr 5.5, 6.6, 7.7 solr/Dockerfile Varnish 5 varnish/Dockerfile Elasticsearch 6, 7 elasticsearch/Dockerfiles Logstash 6, 7 logstash/Dockerfiles Kibana 6, 7 kibana/Dockerfiles RabbitMQ 3.8 rabbitmq/Dockerfile All images are pushed to https://hub.docker.com/u/uselagoon . We suggest always using the latest tag (like uselagoon/nginx:latest ) or unsuffixed images (like amazeeio/node:14 ), as they are kept up to date in terms of features and security. If you choose to use a specific Lagoon version of an image like uselagoon/nginx:20.10.0 or uselagoon/node-10:20.10.0 it is your own responsibility to upgrade the version of the images as soon as a new Lagoon version is released!","title":"Supported Services &amp; Base Images by Lagoon"},{"location":"using-lagoon-the-basics/build-and-deploy-process/","text":"Build and Deploy Process # This document describes what actually happens during a Lagoon build and deployment. It is heavily simplified from what actually happens, but it will help you to understand what is happening under the hood every time that Lagoon deploys new code for you. Watch the video below for a walk-through of the deployment process. 1. Set up OpenShift Project/Kubernetes Namespace for Environment # First, Lagoon checks if the OpenShift project/Kubernetes namespace for the given environment exists and is correctly set up. It will make sure that we have the needed service accounts, create secrets, and will configure environment variables into a ConfigMap lagoon-env which is filled with information like the environment type and name, the Lagoon project name, and so on. 2. Git Checkout & Merge # Next, Lagoon will check out your code from Git. It needs that to be able to read the .lagoon.yml , docker-compose.yml and any .env files, but also to build the Docker images. Note that Lagoon will only process these actions if the branch/PR matches the branch regex set in Lagoon. Based on how the deployment has been triggered, different things will happen: Branch Webhook Push # If the deployment is triggered automatically via a Git webhook and is for a single branch, Lagoon will check out the Git SHA which is included in the webhook payload. This will trigger a deployment for every Git SHA pushed. Branch REST trigger # If you trigger a branch deployment manually via the REST API (via the UI, or GraphQL) and do NOT define a SHA in the POST payload, Lagoon will just check out the latest commit in that branch and deploy it. Pull Requests # If the deployment is a pull request (PR) deployment, Lagoon will load the base and the HEAD branch and SHAs for the pull request and will: Check out the base branch (the branch the PR points to). Merge the HEAD branch (the branch that the PR originates from) on top of the base branch. More specifically: Lagoon will check out and merge particular SHAs which were sent in the webhook. Those SHAs may or may not point to the branch heads. For example, if you make a new push to a GitHub pull request, it can happen that SHA of the base branch will not point to the current base branch HEAD. If the merge fails, Lagoon will also stop and inform you about this. 3. Build Image # For each service defined in the docker-compose.yml Lagoon will check if images need to be built or not. If they need to be built, this will happen now. The order of building is based on the order they are configured in docker-compose.yml , and some build arguments are injected: LAGOON_GIT_SHA LAGOON_GIT_BRANCH LAGOON_PROJECT LAGOON_BUILD_TYPE (either pullrequest , branch or promote ) LAGOON_SSH_PRIVATE_KEY - The SSH private key that is used to clone the source repository. Use RUN /lagoon/entrypoints/05-ssh-key.sh to convert the build argument into an actual key at /home/.ssh/key which will be used by SSH and Git automatically. For safety, remove the key again via RUN rm /home/.ssh/key . LAGOON_GIT_SOURCE_REPOSITORY - The full Git URL of the source repository. Also, if this is a pull request build: LAGOON_PR_HEAD_BRANCH LAGOON_PR_HEAD_SHA LAGOON_PR_BASE_BRANCH LAGOON_PR_BASE_SHA LAGOON_PR_TITLE Additionally, for each already built image, its name is also injected. If your docker-compose.yml is configured to first build the cli image and then the nginx image, the name of the nginx image is injected as NGINX_IMAGE . 4. Configure Kubernetes or Openshift Services and Routes # Next, Lagoon will configure Kubernetes or Openshift with all services and routes that are defined from the service types, plus possible additional custom routes that you have defined in .lagoon.yml . In this step it will expose all defined routes in the LAGOON_ROUTES as comma separated URLs. It will also define one route as the \"main\" route, in this order: If custom routes defined: the first defined custom route in .lagoon.yml . The first auto-generated route from a service defined in docker-compose.yml . None. The \"main\" route is injected via the LAGOON_ROUTE environment variable. 5. Push and Tag Images # Now it is time to push the previously built Docker images into the internal Docker image registry. For services that didn't specify a Dockerfile to be built in docker-compose.yml and only gave an image, they are also tagged and will cause the internal Docker image registry to know about the images, so that they can be used in containers. 6. Persistent Storage # Lagoon will now create persistent storage (PVC) for each service that needs and requested persistent storage. 7. Cron jobs # For each service that requests a cron job (like MariaDB), plus for each custom cron job defined in .lagoon.yml, Lagoon will now generate the cron job environment variables which are later injected into the Deployment . 8. Run defined pre-rollout tasks # Now Lagoon will check the .lagoon.yml file for defined tasks in pre-rollout and will run them one by one in the defined services. Note that these tasks are executed on the pods currently running (so cannot utilize features or scripts that only exist in the latest commit) and therefore they are also not run on first deployments. If any of them fail, Lagoon will immediately stop and notify you, and the rollout will not proceed. 9. DeploymentConfigs, Statefulsets, Daemonsets # This is probably the most important step. Based on the defined service type, Lagoon will create the Deployment , Statefulset or Daemonsets for the service. (Note that Deployments are analogous to DeploymentConfigs in OpenShift) It will include all previously gathered information like the cron jobs, the location of persistent storage, the pushed images and so on. Creation of these objects will also automatically cause Kubernetes or Openshift to trigger new deployments of the pods if necessary, like when an environment variable has changed or an image has changed. But if there is no change, there will be no deployment! This means if you only update the PHP code in your application, the Varnish, Solr, MariaDB, Redis and any other service that is defined but does not include your code will not be deployed. This makes everything much much faster. 10. Wait for all rollouts to be done # Now Lagoon waits! It waits for all of the just-triggered deployments of the new pods to be finished, as well as for their health checks to be successful. If any of the deployments or health checks fail, the deployment will be stopped here, and you will be informed via the defined notification systems (like Slack) that the deployment has failed. 11. Run defined post-rollout tasks # Now Lagoon will check the .lagoon.yml file for defined tasks in post-rollout and will run them one by one in the defined services. If any of them fail, Lagoon will immediately stop and notify you. 12. Success # If all went well and nothing threw any errors, Lagoon will mark this build as successful and inform you via defined notifications. \u2705","title":"Build and Deploy Process"},{"location":"using-lagoon-the-basics/build-and-deploy-process/#build-and-deploy-process","text":"This document describes what actually happens during a Lagoon build and deployment. It is heavily simplified from what actually happens, but it will help you to understand what is happening under the hood every time that Lagoon deploys new code for you. Watch the video below for a walk-through of the deployment process.","title":"Build and Deploy Process"},{"location":"using-lagoon-the-basics/build-and-deploy-process/#1-set-up-openshift-projectkubernetes-namespace-for-environment","text":"First, Lagoon checks if the OpenShift project/Kubernetes namespace for the given environment exists and is correctly set up. It will make sure that we have the needed service accounts, create secrets, and will configure environment variables into a ConfigMap lagoon-env which is filled with information like the environment type and name, the Lagoon project name, and so on.","title":"1. Set up OpenShift Project/Kubernetes Namespace for Environment"},{"location":"using-lagoon-the-basics/build-and-deploy-process/#2-git-checkout-merge","text":"Next, Lagoon will check out your code from Git. It needs that to be able to read the .lagoon.yml , docker-compose.yml and any .env files, but also to build the Docker images. Note that Lagoon will only process these actions if the branch/PR matches the branch regex set in Lagoon. Based on how the deployment has been triggered, different things will happen:","title":"2. Git Checkout &amp; Merge"},{"location":"using-lagoon-the-basics/build-and-deploy-process/#branch-webhook-push","text":"If the deployment is triggered automatically via a Git webhook and is for a single branch, Lagoon will check out the Git SHA which is included in the webhook payload. This will trigger a deployment for every Git SHA pushed.","title":"Branch Webhook Push"},{"location":"using-lagoon-the-basics/build-and-deploy-process/#branch-rest-trigger","text":"If you trigger a branch deployment manually via the REST API (via the UI, or GraphQL) and do NOT define a SHA in the POST payload, Lagoon will just check out the latest commit in that branch and deploy it.","title":"Branch REST trigger"},{"location":"using-lagoon-the-basics/build-and-deploy-process/#pull-requests","text":"If the deployment is a pull request (PR) deployment, Lagoon will load the base and the HEAD branch and SHAs for the pull request and will: Check out the base branch (the branch the PR points to). Merge the HEAD branch (the branch that the PR originates from) on top of the base branch. More specifically: Lagoon will check out and merge particular SHAs which were sent in the webhook. Those SHAs may or may not point to the branch heads. For example, if you make a new push to a GitHub pull request, it can happen that SHA of the base branch will not point to the current base branch HEAD. If the merge fails, Lagoon will also stop and inform you about this.","title":"Pull Requests"},{"location":"using-lagoon-the-basics/build-and-deploy-process/#3-build-image","text":"For each service defined in the docker-compose.yml Lagoon will check if images need to be built or not. If they need to be built, this will happen now. The order of building is based on the order they are configured in docker-compose.yml , and some build arguments are injected: LAGOON_GIT_SHA LAGOON_GIT_BRANCH LAGOON_PROJECT LAGOON_BUILD_TYPE (either pullrequest , branch or promote ) LAGOON_SSH_PRIVATE_KEY - The SSH private key that is used to clone the source repository. Use RUN /lagoon/entrypoints/05-ssh-key.sh to convert the build argument into an actual key at /home/.ssh/key which will be used by SSH and Git automatically. For safety, remove the key again via RUN rm /home/.ssh/key . LAGOON_GIT_SOURCE_REPOSITORY - The full Git URL of the source repository. Also, if this is a pull request build: LAGOON_PR_HEAD_BRANCH LAGOON_PR_HEAD_SHA LAGOON_PR_BASE_BRANCH LAGOON_PR_BASE_SHA LAGOON_PR_TITLE Additionally, for each already built image, its name is also injected. If your docker-compose.yml is configured to first build the cli image and then the nginx image, the name of the nginx image is injected as NGINX_IMAGE .","title":"3. Build Image"},{"location":"using-lagoon-the-basics/build-and-deploy-process/#4-configure-kubernetes-or-openshift-services-and-routes","text":"Next, Lagoon will configure Kubernetes or Openshift with all services and routes that are defined from the service types, plus possible additional custom routes that you have defined in .lagoon.yml . In this step it will expose all defined routes in the LAGOON_ROUTES as comma separated URLs. It will also define one route as the \"main\" route, in this order: If custom routes defined: the first defined custom route in .lagoon.yml . The first auto-generated route from a service defined in docker-compose.yml . None. The \"main\" route is injected via the LAGOON_ROUTE environment variable.","title":"4. Configure Kubernetes or Openshift Services and Routes"},{"location":"using-lagoon-the-basics/build-and-deploy-process/#5-push-and-tag-images","text":"Now it is time to push the previously built Docker images into the internal Docker image registry. For services that didn't specify a Dockerfile to be built in docker-compose.yml and only gave an image, they are also tagged and will cause the internal Docker image registry to know about the images, so that they can be used in containers.","title":"5. Push and Tag Images"},{"location":"using-lagoon-the-basics/build-and-deploy-process/#6-persistent-storage","text":"Lagoon will now create persistent storage (PVC) for each service that needs and requested persistent storage.","title":"6. Persistent Storage"},{"location":"using-lagoon-the-basics/build-and-deploy-process/#7-cron-jobs","text":"For each service that requests a cron job (like MariaDB), plus for each custom cron job defined in .lagoon.yml, Lagoon will now generate the cron job environment variables which are later injected into the Deployment .","title":"7. Cron jobs"},{"location":"using-lagoon-the-basics/build-and-deploy-process/#8-run-defined-pre-rollout-tasks","text":"Now Lagoon will check the .lagoon.yml file for defined tasks in pre-rollout and will run them one by one in the defined services. Note that these tasks are executed on the pods currently running (so cannot utilize features or scripts that only exist in the latest commit) and therefore they are also not run on first deployments. If any of them fail, Lagoon will immediately stop and notify you, and the rollout will not proceed.","title":"8. Run defined pre-rollout tasks"},{"location":"using-lagoon-the-basics/build-and-deploy-process/#9-deploymentconfigs-statefulsets-daemonsets","text":"This is probably the most important step. Based on the defined service type, Lagoon will create the Deployment , Statefulset or Daemonsets for the service. (Note that Deployments are analogous to DeploymentConfigs in OpenShift) It will include all previously gathered information like the cron jobs, the location of persistent storage, the pushed images and so on. Creation of these objects will also automatically cause Kubernetes or Openshift to trigger new deployments of the pods if necessary, like when an environment variable has changed or an image has changed. But if there is no change, there will be no deployment! This means if you only update the PHP code in your application, the Varnish, Solr, MariaDB, Redis and any other service that is defined but does not include your code will not be deployed. This makes everything much much faster.","title":"9. DeploymentConfigs, Statefulsets, Daemonsets"},{"location":"using-lagoon-the-basics/build-and-deploy-process/#10-wait-for-all-rollouts-to-be-done","text":"Now Lagoon waits! It waits for all of the just-triggered deployments of the new pods to be finished, as well as for their health checks to be successful. If any of the deployments or health checks fail, the deployment will be stopped here, and you will be informed via the defined notification systems (like Slack) that the deployment has failed.","title":"10. Wait for all rollouts to be done"},{"location":"using-lagoon-the-basics/build-and-deploy-process/#11-run-defined-post-rollout-tasks","text":"Now Lagoon will check the .lagoon.yml file for defined tasks in post-rollout and will run them one by one in the defined services. If any of them fail, Lagoon will immediately stop and notify you.","title":"11. Run defined post-rollout tasks"},{"location":"using-lagoon-the-basics/build-and-deploy-process/#12-success","text":"If all went well and nothing threw any errors, Lagoon will mark this build as successful and inform you via defined notifications. \u2705","title":"12. Success"},{"location":"using-lagoon-the-basics/configure-webhooks/","text":"Configure Webhooks # Your Lagoon administrator will also give you the route to the webhook-handler . You will add this to your repository as an outgoing webhook, and choose which events to send to Lagoon. Typically, you will send all push and pull request events. In Lagoon it is possible to add a regular expression to determine which branches and pull requests actually result in a deploy, and your Lagoon administrator can set that up for you. For example, all branches that start with feature- could be deployed to Lagoon. Note: If you are an amazee.io customer, the route to the webhook-handler is: https://hooks.lagoon.amazeeio.cloud . Warning: Managing the following settings will require you to have a high level of access to these repositories, which will be controlled by your organization. If you cannot access these settings, please contact your systems administrator or the appropriate person within your organization . GitHub # Proceed to Settings -> Webhooks -> Add webhook in your GitHub repository. The Payload URL is the route to the webhook-handler of your Lagoon instance, provided by your Lagoon administrator. Set Content type to application/json . Choose \" Let me select individual events .\" Choose which events will trigger your webhook. We suggest that you send Push and Pull request events, and then filter further in the Lagoon configuration of your project. Make sure the webhook is set to Active . Click Add webhook to save your configuration. GitLab # Navigate to Settings -> Integrations in your GitLab repository. The URL is the route to the webhook-handler of your Lagoon instance, provided by your Lagoon administrator. Select the Trigger events which will send a notification to Lagoon. We suggest that you send Push events and Merge request events , and then filter further in the Lagoon configuration of your project. Click Add webhook to save your configuration. Bitbucket # Navigate to Settings -> Webhooks -> Add new webhook in your repository. Title is for your reference. URL is the route to the webhook-handler of your Lagoon instance, provided by your Lagoon administrator. Choose from a full list of triggers and select the following: Repository Push Pull Request Created Updated Approved Approval removed Merged Declined 5. Click Save to save the webhook configurations for Bitbucket.","title":"Configure Webhooks"},{"location":"using-lagoon-the-basics/configure-webhooks/#configure-webhooks","text":"Your Lagoon administrator will also give you the route to the webhook-handler . You will add this to your repository as an outgoing webhook, and choose which events to send to Lagoon. Typically, you will send all push and pull request events. In Lagoon it is possible to add a regular expression to determine which branches and pull requests actually result in a deploy, and your Lagoon administrator can set that up for you. For example, all branches that start with feature- could be deployed to Lagoon. Note: If you are an amazee.io customer, the route to the webhook-handler is: https://hooks.lagoon.amazeeio.cloud . Warning: Managing the following settings will require you to have a high level of access to these repositories, which will be controlled by your organization. If you cannot access these settings, please contact your systems administrator or the appropriate person within your organization .","title":"Configure Webhooks"},{"location":"using-lagoon-the-basics/configure-webhooks/#github","text":"Proceed to Settings -> Webhooks -> Add webhook in your GitHub repository. The Payload URL is the route to the webhook-handler of your Lagoon instance, provided by your Lagoon administrator. Set Content type to application/json . Choose \" Let me select individual events .\" Choose which events will trigger your webhook. We suggest that you send Push and Pull request events, and then filter further in the Lagoon configuration of your project. Make sure the webhook is set to Active . Click Add webhook to save your configuration.","title":"GitHub"},{"location":"using-lagoon-the-basics/configure-webhooks/#gitlab","text":"Navigate to Settings -> Integrations in your GitLab repository. The URL is the route to the webhook-handler of your Lagoon instance, provided by your Lagoon administrator. Select the Trigger events which will send a notification to Lagoon. We suggest that you send Push events and Merge request events , and then filter further in the Lagoon configuration of your project. Click Add webhook to save your configuration.","title":"GitLab"},{"location":"using-lagoon-the-basics/configure-webhooks/#bitbucket","text":"Navigate to Settings -> Webhooks -> Add new webhook in your repository. Title is for your reference. URL is the route to the webhook-handler of your Lagoon instance, provided by your Lagoon administrator. Choose from a full list of triggers and select the following: Repository Push Pull Request Created Updated Approved Approval removed Merged Declined 5. Click Save to save the webhook configurations for Bitbucket.","title":"Bitbucket"},{"location":"using-lagoon-the-basics/docker-compose-yml/","text":"docker-compose.yml # The docker-compose.yml file is used by Lagoon to: Learn which services/containers should be deployed. Define how the images for the containers are built. Define additional configurations like persistent volumes. Docker-compose (the tool) is very strict in validating the content of the YAML file, so we can only do configuration within labels of a service definition. Warning: Lagoon only reads the labels, service names, image names and build definitions from a docker-compose.yml file. Definitions like: ports, environment variables, volumes, networks, links, users, etc. are IGNORED. This is intentional as the docker-compose file is there to define your local environment configuration. Lagoon learns from the lagoon.type the type of service you are deploying and from that knows about ports, networks and any additional configuration that this service might need. Here a straightforward example of a docker-compose.yml file for Drupal: docker-compose.yml version : '2.3' x-lagoon-project : # Lagoon project name (leave `&lagoon-project` when you edit this) &lagoon-project drupal-example x-volumes : &default-volumes # Define all volumes you would like to have real-time mounted into the docker containers volumes : - .:/app:delegated x-environment : &default-environment LAGOON_PROJECT : *lagoon-project # Route that should be used locally, if you are using pygmy, this route *must* end with .docker.amazee.io LAGOON_ROUTE : http://drupal-example.docker.amazee.io # Uncomment if you like to have the system behave like in production #LAGOON_ENVIRONMENT_TYPE: production # Uncomment to enable xdebug and then restart via `docker-compose up -d` #XDEBUG_ENABLE: \"true\" x-user : &default-user # The default user under which the containers should run. Change this if you are on linux and run with another user than id `1000` user : '1000' services : nginx : build : context : . dockerfile : nginx.dockerfile labels : lagoon.type : nginx-php-persistent lagoon.persistent : /app/web/sites/default/files/ php : build : context : . dockerfile : php.dockerfile labels : lagoon.type : nginx-php-persistent lagoon.name : nginx lagoon.persistent : /app/web/sites/default/files/ mariadb : image : amazeeio/mariadb-drupal labels : lagoon.type : mariadb Basic settings # x-lagoon-project : This is the machine name of your project, define it here. We\u2019ll use \u201cdrupal-example.\u201d x-volumes : This tells Lagoon what to mount into the container. Your web application lives in /app , but you can add or change this if needed. x-environment : Here you can set your local development url. If you are using pygmy, it must end with .docker.amazee.io . If you want to exactly mimic the production environment, uncomment LAGOON_ENVIRONMENT_TYPE: production . If you want to enable xd-ebug, uncomment DEBUG_ENABLE: \"true\" . x-user : You are unlikely to need to change this, unless you are on Linux and would like to run with a user other than 1000 . services # This defines all the services you want to deploy. Unfortunately, docker-compose calls them services, even though they are actually containers. Going forward we'll be calling them services, and throughout this documentation. The name of the service ( nginx , php , and mariadb in the example above) is used by Lagoon as the name of the Kubernetes pod (yet another term - again, we'll be calling them services) that is generated, plus also any additional Kubernetes objects that are created based on the defined lagoon.type , which could be things like services, routes, persistent storage, etc. Warning: Once you have set the name of a service, do NOT rename it. This will cause all kind of havoc in your containers and break things. Docker Images # build # If you want Lagoon to build a Dockerfile for your service during every deployment, you can define it here: build context The build context path that should be passed on into the docker build command. dockerfile: Location and name of the Dockerfile that should be built. Warning: Lagoon does NOT support the short version of build: <Dockerfile> and will fail if it finds such a definition. image # If you don't need to build a Dockerfile and just want to use an existing Dockerfile, define it via image . Types # Lagoon needs to know what type of service you are deploying in order to configure the correct Kubernetes or OpenShift objects. This is done via the lagoon.type label. There are many different types to choose from. Check Service Types to see all of them and their additional configuration possibilities. Skip/Ignore containers # If you'd like Lagoon to ignore a service completely - for example, you need a container only during local development - give it the type none . Persistent Storage # Some containers need persistent storage. In many cases, Lagoon knows where that persistent storage needs to go. For example, for a MariaDB container, Lagoon knows that the persistent storage should be put into /var/lib/mysql , and puts it there automatically without any extra configuration to define that. For some situations, though, Lagoon needs your help to know where to put the persistent storage: lagoon.persistent - The absolute path where the persistent storage should be mounted (the above example uses /app/web/sites/default/files/ which is where Drupal expects its persistent storage). lagoon.persistent.name - Tells Lagoon to not create a new persistent storage for that service, but instead mounts the persistent storage of another defined service into this service. lagoon.persistent.size - The size of persistent storage you require (Lagoon usually gives you minimum 5G of persistent storage, if you need more, define it here). lagoon.persistent.class - By default Lagoon automatically assigns the right storage class for your service (like SSDs for MySQL, bulk storage for Nginx, etc.). If you need to overwrite this, you can do so here. This is highly dependent on the underlying Kubernetes/OpenShift that Lagoon runs on. Ask your Lagoon administrator about this. Multi-Container Pods # Kubernetes and OpenShift don't deploy plain containers. Instead, they deploy pods, with each one or more containers. Usually Lagoon creates a single pod with a container inside for each defined docker-compose service. For some cases, we need to put two containers inside a single pod, as these containers are so dependent on each other that they should always stay together. An example for such a situation is the PHP and Nginx containers that both contain PHP code of a web application like Drupal. For these cases, it is possible to tell Lagoon which services should stay together, which is done in the following way (remember that we are calling containers services because of docker-compose : Define both services with a lagoon.type that expects two services (in the example this is nginx-php-persistent defined on the nginx and php services). Link the second service with the first one, defining the label lagoon.name of the second one with the first one. (in the example this is done with defining lagoon.name: nginx ). This will cause Lagoon to realize that the nginx and php containers are combined in a pod that will be called nginx . Warning: Once you have set the lagooon.name of a service, do NOT rename it. This will cause all kind of havoc in your containers and break things. Lagoon still needs to understand which of the two services is the actual individual service type ( nginx and php in this case). It does this by searching for service names with the same name that are given by the type, so nginx-php-persistent expects one service with the name nginx and one with php in the docker-compose.yml. If for any reason you want to use different names for the services, or you need for than one pod with the type nginx-php-persistent there is an additional label lagoon.deployment.servicetype which can be used to define the actual service type. An example: docker-compose.yml nginx : build : context : . dockerfile : nginx.dockerfile labels : lagoon.type : nginx-php-persistent lagoon.persistent : /app/web/sites/default/files/ lagoon.name : nginx # If this isn't present, Lagoon will use the container name, which in this case is nginx. lagoon.deployment.servicetype : nginx php : build : context : . dockerfile : php.dockerfile labels : lagoon.type : nginx-php-persistent lagoon.persistent : /app/web/sites/default/files/ lagoon.name : nginx # We want this service be part of the nginx pod in Lagoon. lagoon.deployment.servicetype : php In the example above, the services are named nginx and php (but you can call them whatever you want). The lagoon.name tells Lagoon which services go together - all of the services with the same name go together. In order for Lagoon to realize which one is the nginx and which one is the php service, we define it via lagoon.deployment.servicetype: nginx and lagoon.deployment.servicetype: php . Helm Templates (Kubernetes only) # Lagoon uses Helm for templating on Kubernetes. To do this, a series of Charts are included with the kubectl-build-deploy-dind service. Custom Rollout Monitor Types # By default , Lagoon expects that services from custom templates are rolled out via a DeploymentConfig object within Kubernetes or Openshift. It monitors the rollout based on this object. In some cases, the services that are defined via custom deployment need a different way of monitoring. This can be defined via lagoon.rollout : deploymentconfig - This is the default. Expects a DeploymentConfig object in the template for the service. statefulset - Expects a Statefulset object in the template for the service. daemonset - Expects a Daemonset object in the template for the service. false - Will not monitor any rollouts, and will just be happy if the template applies and does not throw any errors. You can also overwrite the rollout for just one specific environment. This is done in .lagoon.yml .","title":"docker-compose.yml"},{"location":"using-lagoon-the-basics/docker-compose-yml/#docker-composeyml","text":"The docker-compose.yml file is used by Lagoon to: Learn which services/containers should be deployed. Define how the images for the containers are built. Define additional configurations like persistent volumes. Docker-compose (the tool) is very strict in validating the content of the YAML file, so we can only do configuration within labels of a service definition. Warning: Lagoon only reads the labels, service names, image names and build definitions from a docker-compose.yml file. Definitions like: ports, environment variables, volumes, networks, links, users, etc. are IGNORED. This is intentional as the docker-compose file is there to define your local environment configuration. Lagoon learns from the lagoon.type the type of service you are deploying and from that knows about ports, networks and any additional configuration that this service might need. Here a straightforward example of a docker-compose.yml file for Drupal: docker-compose.yml version : '2.3' x-lagoon-project : # Lagoon project name (leave `&lagoon-project` when you edit this) &lagoon-project drupal-example x-volumes : &default-volumes # Define all volumes you would like to have real-time mounted into the docker containers volumes : - .:/app:delegated x-environment : &default-environment LAGOON_PROJECT : *lagoon-project # Route that should be used locally, if you are using pygmy, this route *must* end with .docker.amazee.io LAGOON_ROUTE : http://drupal-example.docker.amazee.io # Uncomment if you like to have the system behave like in production #LAGOON_ENVIRONMENT_TYPE: production # Uncomment to enable xdebug and then restart via `docker-compose up -d` #XDEBUG_ENABLE: \"true\" x-user : &default-user # The default user under which the containers should run. Change this if you are on linux and run with another user than id `1000` user : '1000' services : nginx : build : context : . dockerfile : nginx.dockerfile labels : lagoon.type : nginx-php-persistent lagoon.persistent : /app/web/sites/default/files/ php : build : context : . dockerfile : php.dockerfile labels : lagoon.type : nginx-php-persistent lagoon.name : nginx lagoon.persistent : /app/web/sites/default/files/ mariadb : image : amazeeio/mariadb-drupal labels : lagoon.type : mariadb","title":"docker-compose.yml"},{"location":"using-lagoon-the-basics/docker-compose-yml/#basic-settings","text":"x-lagoon-project : This is the machine name of your project, define it here. We\u2019ll use \u201cdrupal-example.\u201d x-volumes : This tells Lagoon what to mount into the container. Your web application lives in /app , but you can add or change this if needed. x-environment : Here you can set your local development url. If you are using pygmy, it must end with .docker.amazee.io . If you want to exactly mimic the production environment, uncomment LAGOON_ENVIRONMENT_TYPE: production . If you want to enable xd-ebug, uncomment DEBUG_ENABLE: \"true\" . x-user : You are unlikely to need to change this, unless you are on Linux and would like to run with a user other than 1000 .","title":"Basic settings"},{"location":"using-lagoon-the-basics/docker-compose-yml/#services","text":"This defines all the services you want to deploy. Unfortunately, docker-compose calls them services, even though they are actually containers. Going forward we'll be calling them services, and throughout this documentation. The name of the service ( nginx , php , and mariadb in the example above) is used by Lagoon as the name of the Kubernetes pod (yet another term - again, we'll be calling them services) that is generated, plus also any additional Kubernetes objects that are created based on the defined lagoon.type , which could be things like services, routes, persistent storage, etc. Warning: Once you have set the name of a service, do NOT rename it. This will cause all kind of havoc in your containers and break things.","title":"services"},{"location":"using-lagoon-the-basics/docker-compose-yml/#docker-images","text":"","title":"Docker Images"},{"location":"using-lagoon-the-basics/docker-compose-yml/#build","text":"If you want Lagoon to build a Dockerfile for your service during every deployment, you can define it here: build context The build context path that should be passed on into the docker build command. dockerfile: Location and name of the Dockerfile that should be built. Warning: Lagoon does NOT support the short version of build: <Dockerfile> and will fail if it finds such a definition.","title":"build"},{"location":"using-lagoon-the-basics/docker-compose-yml/#image","text":"If you don't need to build a Dockerfile and just want to use an existing Dockerfile, define it via image .","title":"image"},{"location":"using-lagoon-the-basics/docker-compose-yml/#types","text":"Lagoon needs to know what type of service you are deploying in order to configure the correct Kubernetes or OpenShift objects. This is done via the lagoon.type label. There are many different types to choose from. Check Service Types to see all of them and their additional configuration possibilities.","title":"Types"},{"location":"using-lagoon-the-basics/docker-compose-yml/#skipignore-containers","text":"If you'd like Lagoon to ignore a service completely - for example, you need a container only during local development - give it the type none .","title":"Skip/Ignore containers"},{"location":"using-lagoon-the-basics/docker-compose-yml/#persistent-storage","text":"Some containers need persistent storage. In many cases, Lagoon knows where that persistent storage needs to go. For example, for a MariaDB container, Lagoon knows that the persistent storage should be put into /var/lib/mysql , and puts it there automatically without any extra configuration to define that. For some situations, though, Lagoon needs your help to know where to put the persistent storage: lagoon.persistent - The absolute path where the persistent storage should be mounted (the above example uses /app/web/sites/default/files/ which is where Drupal expects its persistent storage). lagoon.persistent.name - Tells Lagoon to not create a new persistent storage for that service, but instead mounts the persistent storage of another defined service into this service. lagoon.persistent.size - The size of persistent storage you require (Lagoon usually gives you minimum 5G of persistent storage, if you need more, define it here). lagoon.persistent.class - By default Lagoon automatically assigns the right storage class for your service (like SSDs for MySQL, bulk storage for Nginx, etc.). If you need to overwrite this, you can do so here. This is highly dependent on the underlying Kubernetes/OpenShift that Lagoon runs on. Ask your Lagoon administrator about this.","title":"Persistent Storage"},{"location":"using-lagoon-the-basics/docker-compose-yml/#multi-container-pods","text":"Kubernetes and OpenShift don't deploy plain containers. Instead, they deploy pods, with each one or more containers. Usually Lagoon creates a single pod with a container inside for each defined docker-compose service. For some cases, we need to put two containers inside a single pod, as these containers are so dependent on each other that they should always stay together. An example for such a situation is the PHP and Nginx containers that both contain PHP code of a web application like Drupal. For these cases, it is possible to tell Lagoon which services should stay together, which is done in the following way (remember that we are calling containers services because of docker-compose : Define both services with a lagoon.type that expects two services (in the example this is nginx-php-persistent defined on the nginx and php services). Link the second service with the first one, defining the label lagoon.name of the second one with the first one. (in the example this is done with defining lagoon.name: nginx ). This will cause Lagoon to realize that the nginx and php containers are combined in a pod that will be called nginx . Warning: Once you have set the lagooon.name of a service, do NOT rename it. This will cause all kind of havoc in your containers and break things. Lagoon still needs to understand which of the two services is the actual individual service type ( nginx and php in this case). It does this by searching for service names with the same name that are given by the type, so nginx-php-persistent expects one service with the name nginx and one with php in the docker-compose.yml. If for any reason you want to use different names for the services, or you need for than one pod with the type nginx-php-persistent there is an additional label lagoon.deployment.servicetype which can be used to define the actual service type. An example: docker-compose.yml nginx : build : context : . dockerfile : nginx.dockerfile labels : lagoon.type : nginx-php-persistent lagoon.persistent : /app/web/sites/default/files/ lagoon.name : nginx # If this isn't present, Lagoon will use the container name, which in this case is nginx. lagoon.deployment.servicetype : nginx php : build : context : . dockerfile : php.dockerfile labels : lagoon.type : nginx-php-persistent lagoon.persistent : /app/web/sites/default/files/ lagoon.name : nginx # We want this service be part of the nginx pod in Lagoon. lagoon.deployment.servicetype : php In the example above, the services are named nginx and php (but you can call them whatever you want). The lagoon.name tells Lagoon which services go together - all of the services with the same name go together. In order for Lagoon to realize which one is the nginx and which one is the php service, we define it via lagoon.deployment.servicetype: nginx and lagoon.deployment.servicetype: php .","title":"Multi-Container Pods"},{"location":"using-lagoon-the-basics/docker-compose-yml/#helm-templates-kubernetes-only","text":"Lagoon uses Helm for templating on Kubernetes. To do this, a series of Charts are included with the kubectl-build-deploy-dind service.","title":"Helm Templates (Kubernetes only)"},{"location":"using-lagoon-the-basics/docker-compose-yml/#custom-rollout-monitor-types","text":"By default , Lagoon expects that services from custom templates are rolled out via a DeploymentConfig object within Kubernetes or Openshift. It monitors the rollout based on this object. In some cases, the services that are defined via custom deployment need a different way of monitoring. This can be defined via lagoon.rollout : deploymentconfig - This is the default. Expects a DeploymentConfig object in the template for the service. statefulset - Expects a Statefulset object in the template for the service. daemonset - Expects a Daemonset object in the template for the service. false - Will not monitor any rollouts, and will just be happy if the template applies and does not throw any errors. You can also overwrite the rollout for just one specific environment. This is done in .lagoon.yml .","title":"Custom Rollout Monitor Types"},{"location":"using-lagoon-the-basics/first-deployment/","text":"First Deployment # Note: If you are deploying a Drupal Project, skip this and read the Drupal-specific first deployment documentation . 1. Make sure you are ready # In order to make your first deployment a successful one, please make sure that your project is Lagoonized and that you have set up the project in Lagoon. If not, or you're not sure, or that doesn't sound familiar, don't worry, go back and follow the Step-by-Step Guides which show you how this works, and then come back and deploy! 2. Push! # With Lagoon, you create a new deployment by pushing into a branch that is configured to be deployed. If you don't have any new code to push, don't worry! Run: git commit --allow-empty -m \"go, go! Power Rangers!\" git push This will trigger a push, and your Git hosting will inform Lagoon about this push via the configured webhook. If all is correct, you should see a notification in your configured chat system (this has been configured by your friendly Lagoon administrator): This informs you that Lagoon has just started to deploy your code. Depending on the size of the code and amount of containers, this will take a couple of seconds. Just relax. If you want to know what's happening now, check out the Build and Deploy Process of Lagoon . You can also check your Lagoon UI to see the progress of any deployment (your Lagoon administrator has the info). 3. It's done! # As soon as Lagoon is done building and deploying it will send a second notification to the chat system, here an example: It tells you: Which project has been deployed. Which branch and Git SHA have been deployed. A link to the full logs of the build and deployment. Links to all routes (URLs) where the environment can be reached. You can also quickly tell what kind of notification it is by the emoji at the beginning - whether it's just info that the build has started, a success, or fail. That's it! We hope that wasn't too hard - making devOps accessible is what we are striving for! But wait, how about other branches or the production environment? # That's the beauty of Lagoon: it's exactly the same! Just push the name of the branch and that one will be deployed. Failure? Don't worry. # Did the deployment fail? Oh no! But we're here to help: If you deployed a Drupal site, make sure to read the Drupal-specific first deployment documentation , which explains why this happens. Click on the Logs link in the error notification, it will tell you where in the deployment process the failure happened. If you can't figure it out, just ask your Lagoon support, we are here to help! Reach out to us in Rocket Chat .","title":"First Deployment"},{"location":"using-lagoon-the-basics/first-deployment/#first-deployment","text":"Note: If you are deploying a Drupal Project, skip this and read the Drupal-specific first deployment documentation .","title":"First Deployment"},{"location":"using-lagoon-the-basics/first-deployment/#1-make-sure-you-are-ready","text":"In order to make your first deployment a successful one, please make sure that your project is Lagoonized and that you have set up the project in Lagoon. If not, or you're not sure, or that doesn't sound familiar, don't worry, go back and follow the Step-by-Step Guides which show you how this works, and then come back and deploy!","title":"1. Make sure you are ready"},{"location":"using-lagoon-the-basics/first-deployment/#2-push","text":"With Lagoon, you create a new deployment by pushing into a branch that is configured to be deployed. If you don't have any new code to push, don't worry! Run: git commit --allow-empty -m \"go, go! Power Rangers!\" git push This will trigger a push, and your Git hosting will inform Lagoon about this push via the configured webhook. If all is correct, you should see a notification in your configured chat system (this has been configured by your friendly Lagoon administrator): This informs you that Lagoon has just started to deploy your code. Depending on the size of the code and amount of containers, this will take a couple of seconds. Just relax. If you want to know what's happening now, check out the Build and Deploy Process of Lagoon . You can also check your Lagoon UI to see the progress of any deployment (your Lagoon administrator has the info).","title":"2. Push!"},{"location":"using-lagoon-the-basics/first-deployment/#3-its-done","text":"As soon as Lagoon is done building and deploying it will send a second notification to the chat system, here an example: It tells you: Which project has been deployed. Which branch and Git SHA have been deployed. A link to the full logs of the build and deployment. Links to all routes (URLs) where the environment can be reached. You can also quickly tell what kind of notification it is by the emoji at the beginning - whether it's just info that the build has started, a success, or fail. That's it! We hope that wasn't too hard - making devOps accessible is what we are striving for!","title":"3. It's done!"},{"location":"using-lagoon-the-basics/first-deployment/#but-wait-how-about-other-branches-or-the-production-environment","text":"That's the beauty of Lagoon: it's exactly the same! Just push the name of the branch and that one will be deployed.","title":"But wait, how about other branches or the production environment?"},{"location":"using-lagoon-the-basics/first-deployment/#failure-dont-worry","text":"Did the deployment fail? Oh no! But we're here to help: If you deployed a Drupal site, make sure to read the Drupal-specific first deployment documentation , which explains why this happens. Click on the Logs link in the error notification, it will tell you where in the deployment process the failure happened. If you can't figure it out, just ask your Lagoon support, we are here to help! Reach out to us in Rocket Chat .","title":"Failure? Don't worry."},{"location":"using-lagoon-the-basics/going-live/","text":"Going Live # Congratulations, you're this close to going live with your website on Lagoon! In order to make this as seamless as possible, we've got this final checklist for you. It leads you through the last few things you should check before taking your site live. Check your .lagoon.yml # Routes / SSL # Check to be sure that all routes have been set up in your .lagoon.yml . Be aware that if you don't point the domains towards Lagoon, you should disable Let's Encrypt (LE) certificate creation, as it will lead to issues. Domains not pointing towards Lagoon will be disabled after a while in order to not exceed the Let's Encrypt quotas. If you use Certificate Authority (CA) signed certificates, you can set tls-acme to false , but leave the insecure flag set to Allow or Redirect . In the case of CA certificates, let your Lagoon administrator know the routes and the SSL certificate that needs to be put in place. .lagoon.yml environments : main : routes : - nginx : - example.com : tls-acme : 'false' insecure : Allow - www.example.com : tls-acme : 'false' insecure : Allow As soon as the DNS entries point towards your Lagoon installation, you can switch the flags: tls-acme to true and insecure to Redirect .lagoon.yml environments : main : routes : - nginx : - example.com : tls-acme : 'true' insecure : Redirect - www.example.com : tls-acme : 'true' insecure : Redirect Note: As checking every page of your website might be a bit a tedious job, you can make use of mixed-content-scan . This will crawl the entire site and give you back pages that include assets from a non-HTTPS site. Redirects # If you need non-www to www redirects, make sure you have them set up in the redirects-map.conf - see Documentation . Cron jobs # Check if your cron jobs have been set up for your production environment - see .lagoon.yml . DNS # To make it as smooth as possible for you to get your site pointing to our servers, we have dedicated load-balancer DNS records. Those technical DNS resource records are used for getting your site linked to the amazee.io infrastructure and serve no other purpose. If you are in doubt of the CNAME record, ask your Lagoon administrator about the exact CNAME you need to set up. Example on amazee.io : <region-identifier>.amazee.io Before you switch over your domain to Lagoon, make sure you lower the Time-to-Live (TTL) before you go live. This will ensure that the switch from the old to the new servers will go quickly. We usually advise a TTL of 300-600 seconds prior to the DNS switch. More information about TTL . Recommended settings for Fastly (CNAME record): # The recommended method of pointing your domain's DNS records at Lagoon is via a CNAME record as shown below: CNAME : cdn.amazee.io Alternate Settings for Fastly (A records): # If your DNS provider does not support the use of CNAME records, you can use these A records instead. Please ensure you set up individual records for each IP listed below: A : 151.101.2.191 A : 151.101.66.191 A : 151.101.130.191 A : 151.101.194.191 Note: We do not suggest configuring any static IP addresses in your DNS zones. The Lagoon load balancer infrastructure may change over time which can have impact on your site availability if you configure a static IP address. Root Domains # Configuring the root domain (e.g. example.com) can be a bit tricky because the DNS specification does not allow the root domain to point to a CNAME entry. Depending on your DNS provider, the record name is different: ALIAS at DNSimple ANAME at DNS Made Easy ANAME at easyDNS ALIAS at PointDNS CNAME at CloudFlare CNAME at NS1 If your DNS provider needs an IP address for the root domain, get in touch with your Lagoon administrator to give you the load balancer IP addresses. Production environment # Lagoon understands the concept of development and production environments. Development environments automatically send noindex and nofollow headers in order to prohibit indexing by search engines. X-Robots-Tag: noindex, nofollow During project setup, the production environment should already be defined. If that's omitted, your environment will run in development mode. You can check if the environment is set as production environment in the Lagoon user interface. If the production environment is not set, let your Lagoon administrator know, and they will configure the system accordingly.","title":"Going Live"},{"location":"using-lagoon-the-basics/going-live/#going-live","text":"Congratulations, you're this close to going live with your website on Lagoon! In order to make this as seamless as possible, we've got this final checklist for you. It leads you through the last few things you should check before taking your site live.","title":"Going Live"},{"location":"using-lagoon-the-basics/going-live/#check-your-lagoonyml","text":"","title":"Check your .lagoon.yml"},{"location":"using-lagoon-the-basics/going-live/#routes-ssl","text":"Check to be sure that all routes have been set up in your .lagoon.yml . Be aware that if you don't point the domains towards Lagoon, you should disable Let's Encrypt (LE) certificate creation, as it will lead to issues. Domains not pointing towards Lagoon will be disabled after a while in order to not exceed the Let's Encrypt quotas. If you use Certificate Authority (CA) signed certificates, you can set tls-acme to false , but leave the insecure flag set to Allow or Redirect . In the case of CA certificates, let your Lagoon administrator know the routes and the SSL certificate that needs to be put in place. .lagoon.yml environments : main : routes : - nginx : - example.com : tls-acme : 'false' insecure : Allow - www.example.com : tls-acme : 'false' insecure : Allow As soon as the DNS entries point towards your Lagoon installation, you can switch the flags: tls-acme to true and insecure to Redirect .lagoon.yml environments : main : routes : - nginx : - example.com : tls-acme : 'true' insecure : Redirect - www.example.com : tls-acme : 'true' insecure : Redirect Note: As checking every page of your website might be a bit a tedious job, you can make use of mixed-content-scan . This will crawl the entire site and give you back pages that include assets from a non-HTTPS site.","title":"Routes / SSL"},{"location":"using-lagoon-the-basics/going-live/#redirects","text":"If you need non-www to www redirects, make sure you have them set up in the redirects-map.conf - see Documentation .","title":"Redirects"},{"location":"using-lagoon-the-basics/going-live/#cron-jobs","text":"Check if your cron jobs have been set up for your production environment - see .lagoon.yml .","title":"Cron jobs"},{"location":"using-lagoon-the-basics/going-live/#dns","text":"To make it as smooth as possible for you to get your site pointing to our servers, we have dedicated load-balancer DNS records. Those technical DNS resource records are used for getting your site linked to the amazee.io infrastructure and serve no other purpose. If you are in doubt of the CNAME record, ask your Lagoon administrator about the exact CNAME you need to set up. Example on amazee.io : <region-identifier>.amazee.io Before you switch over your domain to Lagoon, make sure you lower the Time-to-Live (TTL) before you go live. This will ensure that the switch from the old to the new servers will go quickly. We usually advise a TTL of 300-600 seconds prior to the DNS switch. More information about TTL .","title":"DNS"},{"location":"using-lagoon-the-basics/going-live/#recommended-settings-for-fastly-cname-record","text":"The recommended method of pointing your domain's DNS records at Lagoon is via a CNAME record as shown below: CNAME : cdn.amazee.io","title":"Recommended settings for Fastly (CNAME record):"},{"location":"using-lagoon-the-basics/going-live/#alternate-settings-for-fastly-a-records","text":"If your DNS provider does not support the use of CNAME records, you can use these A records instead. Please ensure you set up individual records for each IP listed below: A : 151.101.2.191 A : 151.101.66.191 A : 151.101.130.191 A : 151.101.194.191 Note: We do not suggest configuring any static IP addresses in your DNS zones. The Lagoon load balancer infrastructure may change over time which can have impact on your site availability if you configure a static IP address.","title":"Alternate Settings for Fastly (A records):"},{"location":"using-lagoon-the-basics/going-live/#root-domains","text":"Configuring the root domain (e.g. example.com) can be a bit tricky because the DNS specification does not allow the root domain to point to a CNAME entry. Depending on your DNS provider, the record name is different: ALIAS at DNSimple ANAME at DNS Made Easy ANAME at easyDNS ALIAS at PointDNS CNAME at CloudFlare CNAME at NS1 If your DNS provider needs an IP address for the root domain, get in touch with your Lagoon administrator to give you the load balancer IP addresses.","title":"Root Domains"},{"location":"using-lagoon-the-basics/going-live/#production-environment","text":"Lagoon understands the concept of development and production environments. Development environments automatically send noindex and nofollow headers in order to prohibit indexing by search engines. X-Robots-Tag: noindex, nofollow During project setup, the production environment should already be defined. If that's omitted, your environment will run in development mode. You can check if the environment is set as production environment in the Lagoon user interface. If the production environment is not set, let your Lagoon administrator know, and they will configure the system accordingly.","title":"Production environment"},{"location":"using-lagoon-the-basics/lagoon-yml/","text":".lagoon.yml # The .lagoon.yml file is the central file to set up your project. It contains configuration in order to do the following: Define routes for accessing your sites . Define pre-rollout tasks . Define post-rollout tasks . Set up SSL certificates . Add cron jobs for environments . The .lagoon.yml file must be placed at the root of your Git repository. General Settings # docker-compose-yaml # Tells the build script which docker-compose YAML file should be used, in order to learn which services and containers should be deployed. This defaults to docker-compose.yml , but could be used for a specific Lagoon docker-compose YAML file if needed. environment_variables.git_sha # This setting allows you to enable injecting the deployed Git SHA into your project as an environment variable. By default this is disabled. Setting the value to true sets the SHA as the environment variable LAGOON_GIT_SHA . Tasks # There are different type of tasks you can define, and they differ in when exactly they are executed in a build flow: Pre-Rollout Tasks - pre_rollout.[i].run # Here you can specify tasks which will run against your project after all images have been successfully built, but before : Any running containers are updated with the newly built images. Any other changes are made to your existing environment. This feature enables you to, for example, create a database dump before updating your application. This can make it easier to roll back in case of a problem with the deploy. Note: The pre-rollout tasks run in the existing pods before they are updated , which means: Changes made to your Dockerfile since the last deploy will not be visible when pre-rollout tasks run. If there are no existing containers (e.g. on the initial deployment of a new environment), pre-rollout tasks are skipped. Post-Rollout Tasks - post_rollout.[i].run # Here you can specify tasks which need to run against your project, after : All images have been successfully built. All containers are updated with the new images. All containers are running have passed their readiness checks. Common uses for post-rollout tasks include running drush updb , drush cim , or clearing various caches. name The name is an arbitrary label for making it easier to identify each task in the logs. command Here you specify what command should run. These are run in the WORKDIR of each container, for Lagoon images this is /app , keep this in mind if you need to cd into a specific location to run your task. service The service which to run the task in. If following our Drupal example, this will be the CLI container, as it has all your site code, files, and a connection to the database. Typically you do not need to change this. shell Which shell should be used to run the task in. By default sh is used, but if the container also has other shells (like bash , you can define it here). This is useful if you want to run some small if/else bash scripts within the post-rollouts. (see the example above how to write a script with multiple lines). when The \"when\" clause allows for the conditional running of tasks. It expects an expression that will evaluate to a true/false value which determines whether the task should be run. Note: If you would like to temporarily disable pre/post-rollout tasks during a deployment, you can set either of the following environment variables in the API at the project or environment level (see how on Environment Variables ). LAGOON_PREROLLOUT_DISABLED=true LAGOON_POSTROLLOUT_DISABLED=true Example post-rollout tasks # Here are some useful examples of post-rollout tasks that you may want to use or adapt for your projects. Run only if Drupal not installed: .lagoon.yml - run : name : IF no Drupal installed command : | if tables=$(drush sqlq \"show tables like 'node';\") && [ -z \"$tables\" ]; then #### whatever you like fi service : cli shell : bash Different tasks based on branch name: .lagoon.yml - run : name : Different tasks based on branch Name command : | ### Runs if current branch is not 'production' service : cli when : LAGOON_GIT_BRANCH != \"production\" Run shell script: .lagoon.yml - run : name : Run Script command : './scripts/script.sh' service : cli Drupal & Drush 9: Sync database & files from master environment: .lagoon.yml - run : name : Sync DB and Files from master if we are not on master command : | # Only if we don't have a database yet if tables=$(drush sqlq 'show tables;') && [ -z \"$tables\" ]; then drush sql-sync @lagoon.master @self drush rsync @lagoon.master:%files @self:%files -- --omit-dir-times --no-perms --no-group --no-owner --chmod=ugo=rwX fi service : cli when : LAGOON_ENVIRONMENT_TYPE != \"production\" Backup Retention # backup-retention.production.monthly # Specify the number of monthly backups Lagoon should retain for your project's production environment(s). The global default is 1 if this value is not specified. backup-retention.production.weekly # Specify the number of weekly backups Lagoon should retain for your project's production environment(s). The global default is 6 if this value is not specified. backup-retention.production.daily # Specify the number of daily backups Lagoon should retain for your project's production environment(s). The global default is 7 if this value is not specified. backup-retention.production.hourly # Specify the number of hourly backups Lagoon should retain for your project's production environment(s). The global default is 0 if this value is not specified. Backup Schedule # backup-schedule.production # Specify the schedule for which backups will be ran for this project. Accepts cron compatible syntax with the notable exception that the Minute block must be the letter M . Any other value in the Minute block will cause the Lagoon build to fail. This allows Lagoon to randomly choose a specific minute for these backups to happen, while users can specify the remainder of the schedule down to the hour. The global default is M H(22-2) * * * if this value is not specified. Take note that these backups will use the cluster's local timezone. Routes # routes.autogenerate.enabled # This allows for the disabling of the automatically created routes (NOT the custom routes per environment, see below for them) all together. routes.autogenerate.allowPullrequests # This allows pull request to get autogenerated routes when route autogeneration is disabled. .lagoon.yml routes : autogenerate : enabled : false allowPullrequests : true routes.autogenerate.insecure # This allows you to define the behavior of the automatic creates routes (NOT the custom routes per environment, see below for more). The following options are allowed: Allow simply sets up routes for both HTTP and HTTPS (this is the default). Redirect will redirect any HTTP requests to HTTPS. None will mean a route for HTTP will not be created, and no redirect. routes.autogenerate.prefixes # This allows you to define an array of prefixes to be prepended to the autogenerated routes of each environment. This is useful for things like language prefix domains, or a multi-domain site using the Drupal domain module. NOTE: This is only available for projects which deploy to a Kubernetes cluster. .lagoon.yml routes : autogenerate : prefixes : - www - de - fr - it Environments # Environment names match your deployed branches or pull requests. This allows for each environment to have a different config. In our example it will apply to the main and staging environment. environments.[name].monitoring_urls # Danger: This feature will be removed in an upcoming release of Lagoon. Please use the newer monitoring-path method on your specific route. Note: Please note, Lagoon does not provide any direct integration to a monitoring service, this just adds the URLs to the API. On amazee.io, we take the monitoring_urls and add them to our StatusCake account. At the end of a deploy, Lagoon will check this field for any URLs which you have specified to add to the API for the purpose of monitoring. The default value for this field is the first route for a project. It is useful for adding specific paths of a project to the API, for consumption by a monitoring service. environments.[name].routes # In the route section, we identify the domain names to which the environment will respond. It is typical to only have an environment with routes specified for your production environment. All environments receive a generated route, but sometimes there is a need for a non-production environment to have its own domain name. You can specify it here, and then add that domain with your DNS provider as a CNAME to the generated route name (these routes publish in deploy messages). The first element after the environment is the target service, Nginx in our example. This is how we identify which service incoming requests will be sent to. The simplest route is the example.com example in our sample .lagoon.yml above - you can see it has no additional configuration. This will assume that you want a Let's Encrypt certificate for your route and no redirect from HTTPS to HTTP. In the \"www.example.com\" example repeated below, we see two more options (also notice the : at the end of the route and that the route is wrapped in \" , that's important!): SSL Configuration - tls-acme # tls-acme: 'true' tells Lagoon to issue a Let's Encrypt certificate for that route. This is the default. If you don't want a Let's Encrypt, set this to tls-acme: 'false' insecure can be set to None , Allow or Redirect . Allow simply sets up both routes for HTTP and HTTPS (this is the default). Redirect will redirect any HTTP requests to HTTPS. None will mean a route for HTTP will not be created, and no redirect will take place. hsts can be set to a value of max-age=31536000;includeSubDomains;preload . Ensure there are no spaces and no other parameters included. Only the max-age parameter is required. The required max-age parameter indicates the length of time, in seconds, the HSTS policy is in effect for. Note: If you plan to switch from a SSL certificate signed by a Certificate Authority (CA) to a Let's Encrypt certificate, it's best to get in touch with your Lagoon administrator to oversee the transition. There are known issues during the transition. The workaround would be manually removing the CA certificate and then triggering the Let's Encrypt process. .lagoon.yml - \"www.example.com\" : tls-acme : 'true' insecure : Redirect hsts : max-age=31536000 Monitoring a specific path # When UptimeRobot is configured for your cluster (Kubernetes or OpenShift), Lagoon will inject annotations to each route/ingress for use by the stakater/IngressControllerMonitor . The default action is to monitor the homepage of the route. If you have a specific route to be monitored, this can be overridden by adding a monitoring-path to your route specification. A common use is to set up a path for monitoring which bypasses caching to give a more real-time monitoring of your site. .lagoon.yml - \"www.example.com\" : monitoring-path : \"/bypass-cache\" Ingress annotations # Note: Route/Ingress annotations are only supported by projects that deploy into clusters that run nginx-ingress controllers! Check with your Lagoon administrator if this is supported. annotations can be a yaml map of annotations supported by the nginx-ingress controller , this is specifically useful for easy redirects and other configurations. Restrictions # Some annotations are disallowed or partially restricted in Lagoon. The table below describes these rules. If your .lagoon.yml contains one of these annotations it will cause a build failure. Annotation Notes nginx.ingress.kubernetes.io/auth-snippet Disallowed nginx.ingress.kubernetes.io/configuration-snippet Restricted to rewrite , add_header , set_real_ip , and more_set_headers directives. nginx.ingress.kubernetes.io/modsecurity-snippet Disallowed nginx.ingress.kubernetes.io/server-snippet Restricted to rewrite , add_header , set_real_ip , and more_set_headers directives. nginx.ingress.kubernetes.io/stream-snippet Disallowed nginx.ingress.kubernetes.io/use-regex Disallowed Ingress annotations redirects # In this example any requests to example.ch will be redirected to https://www.example.ch with keeping folders or query parameters intact ( example.com/folder?query -> https://www.example.ch/folder?query ) .lagoon.yml - \"example.ch\" : annotations : nginx.ingress.kubernetes.io/permanent-redirect : https://www.example.ch$request_uri - www.example.ch You can of course also redirect to any other URL not hosted on Lagoon, this will direct requests to example.de to https://www.google.com .lagoon.yml - \"example.de\" : annotations : nginx.ingress.kubernetes.io/permanent-redirect : https://www.google.com Trusted Reverse Proxies # Warning: Kubernetes will only process a single nginx.ingress.kubernetes.io/server-snippet annotation. Please ensure that if you use this annotation on a non-production environment route that you also include the add_header X-Robots-Tag \"noindex, nofollow\"; annotation as part of your server-snippet. This is needed to stop robots from crawling development environments as the default server-snippet set to prevent this in development environments in the ingress templates will get overwritten with any server-snippets set in .lagoon.yml. Some configurations involve a reverse proxy (like a CDN) in front of the Kubernetes Clusters. In these configurations the IP of the Reverse Proxy will appear as the REMOTE_ADDR HTTP_X_REAL_IP HTTP_X_FORWARDED_FOR headers field in your applications. While the original IP of the requester can be found in the HTTP_X_ORIGINAL_FORWARDED_FOR header. If you like the original IP to appear in the REMOTE_ADDR HTTP_X_REAL_IP HTTP_X_FORWARDED_FOR headers, you need to tell the ingress which reverse proxy IPs you want to trust: .lagoon.yml - \"example.ch\" : annotations : nginx.ingress.kubernetes.io/server-snippet : | set_real_ip_from 1.2.3.4/32; This example would trust the CIDR 1.2.3.4/32 (the IP 1.2.3.4 in this case). Therefore if there is a request sent to the Kubernetes cluster from the IP 1.2.3.4 the X-Forwarded-For Header is analyzed and it's contents injected into REMOTE_ADDR HTTP_X_REAL_IP HTTP_X_FORWARDED_FOR headers. Environments.[name].types # The Lagoon build process checks the lagoon.type label from the docker-compose.yml file in order to learn what type of service should be deployed (read more about them in the documentation of docker-compose.yml ). Sometimes you might want to override the type just for a single environment, and not for all of them. For example, if you want a standalone MariaDB database (instead of letting the Service Broker/operator provision a shared one) for your non-production environment called develop : service-name: service-type service-name is the name of the service from docker-compose.yml you would like to override. service-type the type of the service you would like to use in your override. Example for setting up MariaDB_Galera: .lagoon.yml environments : develop : types : mariadb : mariadb-single environments.[name].templates # The Lagoon build process checks the lagoon.template label from the docker-compose.yml file in order to check if the service needs a custom template file (read more about them in the documentation of docker-compose.yml ). Sometimes you might want to override the template just for a single environment, and not for all of them: service-name: template-file service-name is the name of the service from docker-compose.yml you would like to override. template-file is the path and name of the template to use for this service in this environment. Example : .lagoon.yml environments : main : templates : mariadb : mariadb.main.deployment.yml environments.[name].rollouts # The Lagoon build process checks the lagoon.rollout label from the docker-compose.yml file in order to check if the service needs a special rollout type (read more about them in the documentation of docker-compose.yml ) Sometimes you might want to override the rollout type just for a single environment, especially if you also overwrote the template type for the environment: service-name: rollout-type service-name is the name of the service from docker-compose.yml you would like to override. rollout-type is the type of rollout. See documentation of docker-compose.yml ) for possible values. Example: .lagoon.yml environments : main : rollouts : mariadb : statefulset environments.[name].autogenerateRoutes # This allows for any environments to get autogenerated routes when route autogeneration is disabled. .lagoon.yml routes : autogenerate : enabled : false environments : develop : autogenerateRoutes : true Cron jobs - environments.[name].cronjobs # As most of the time it is not desirable to run the same cron jobs across all environments, you must explicitly define which jobs you want to run for each environment. Example: .lagoon.yml cronjobs : - name : drush cron schedule : \"M * * * *\" # This will run the cron once per hour. command : drush cron service : cli name: Just a friendly name for identifying what the cron job will do. schedule: The schedule for executing the cron job. This follows the standard convention of cron. If you're not sure about the syntax, Crontab Generator can help. You can specify M for the minute, and your cron job will run once per hour at a random minute (the same minute each hour), or M/15 to run it every 15 mins, but with a random offset from the hour (like 6,21,36,51 ). It is a good idea to spread out your cron jobs using this feature, rather than have them all fire off on minute 0 . You can specify H for the hour, and your cron job will run once per day at a random hour (the same hour every day), or H(2-4) to run it once per day within the hours of 2-4. Notes on timezones: The default timezone for cron jobs is UTC. Native cron jobs will run in timezone of the node, which is UTC. In-pod cron jobs == timezone of the pod it is running in, which defaults to UTC but may be different if you have configured it. command: The command to execute. Like the tasks, this executes in the WORKDIR of the service. For Lagoon images, this is /app . service: Which service of your project to run the command in. For most projects, this is the CLI service. Polysite # In Lagoon, the same Git repository can be added to multiple projects, creating what is called a polysite. This allows you to run the same codebase, but allow for different, isolated, databases and persistent files. In .lagoon.yml , we currently only support specifying custom routes for a polysite project. The key difference from a standard project is that the environments becomes the second-level element, and the project name the top level. To utilise this, you will need to: Create two (or more) projects in Lagoon, each configured with the same gitUrl and production branch, named as per the .lagoon.yml (i.e poly-project1 and poly-project2 below) Add the deploy keys from each project to the git repo Configure the webhook for the repo (if required) - you can then push/deploy. Note that a push to the repo will simultaneously deploy all projects/branches for that gitUrl Example: .lagoon.yml poly-project1 : environments : main : routes : - nginx : - project1.com poly-project2 : environments : main : routes : - nginx : - project2.com Specials # api # Note: If you run directly on amazee.io hosted Lagoon you will not need this key set. With the key api you can define another URL that should be used by the Lagoon CLI and drush to connect to the Lagoon GraphQL API. This needs to be a full URL with a scheme, like: http://localhost:3000 This usually does not need to be changed, but there might be situations where your Lagoon administrator tells you to do so. ssh # Note: If you run directly on amazee.io hosted Lagoon you will not need this key set. With the key ssh you can define another SSH endpoint that should be used by the Lagoon CLI and drush to connect to the Lagoon remote shell service. This needs to be a hostname and a port separated by a colon, like: localhost:2020 This usually does not need to be changed, but there might be situations where your Lagoon administrator tells you to do so. container-registries # The container-registries block allows you to define your own private container registries to pull custom or private images. To use a private container registry, you will need a username , password , and optionally the url for your registry. If you don't specify a url in your YAML, it will default to using Docker Hub. There are 2 ways to define the password used for your registry user. Create an environment variable in the Lagoon API with the type container_registry : lagoon add variable -p <project_name> -N <registry_password_variable_name> -V <password_goes_here> -S container_registry (see more on Environment Variables ) The name of the variable you create can then be set as the password: container-registries : my-custom-registry : username : myownregistryuser password : <registry_password_variable_name> url : my.own.registry.com You can also define the password directly in the .lagoon.yml file in plain text: .lagoon.yml container-registries : docker-hub : username : dockerhubuser password : MySecretPassword Consuming a custom or private container registry image # To consume a custom or private container registry image, you need to update the service inside your docker-compose.yml file to use a build context instead of defining an image: .docker-compose.yml services : mariadb : build : context : . dockerfile : Dockerfile.mariadb Once the docker-compose.yml file has been updated to use a build, you need to create the Dockerfile.<service> and then set your private image as the FROM <repo>/<name>:<tag> FROM dockerhubuser/my-private-database:tag Example .lagoon.yml # This is an example .lagoon.yml which showcases all possible settings. You will need to adapt it to your project. .lagoon.yml docker-compose-yaml : docker-compose.yml environment_variables : git_sha : 'true' tasks : pre-rollout : - run : name : drush sql-dump command : mkdir -p /app/web/sites/default/files/private/ && drush sql-dump --ordered-dump --gzip --result-file=/app/web/sites/default/files/private/pre-deploy-dump.sql.gz service : cli post-rollout : - run : name : drush cim command : drush -y cim service : cli shell : bash - run : name : drush cr command : drush -y cr service : cli routes : autogenerate : insecure : Redirect environments : main : monitoring_urls : - \"https://www.example.com\" - \"https://www.example.com/special_page\" routes : - nginx : - example.com - example.net - \"www.example.com\" : tls-acme : 'true' insecure : Redirect hsts : max-age=31536000 - \"example.ch\" : annotations : nginx.ingress.kubernetes.io/permanent-redirect : https://www.example.ch$request_uri - www.example.ch types : mariadb : mariadb templates : mariadb : mariadb.main.deployment.yml rollouts : mariadb : statefulset cronjobs : - name : drush cron schedule : \"M * * * *\" # This will run the cron once per hour. command : drush cron service : cli staging : cronjobs : - name : drush cron schedule : \"M * * * *\" # This will run the cron once per hour. command : drush cron service : cli feature/feature-branch : cronjobs : - name : drush cron schedule : \"H * * * *\" # This will run the cron once per hour. command : drush cron service : cli","title":".lagoon.yml"},{"location":"using-lagoon-the-basics/lagoon-yml/#lagoonyml","text":"The .lagoon.yml file is the central file to set up your project. It contains configuration in order to do the following: Define routes for accessing your sites . Define pre-rollout tasks . Define post-rollout tasks . Set up SSL certificates . Add cron jobs for environments . The .lagoon.yml file must be placed at the root of your Git repository.","title":".lagoon.yml"},{"location":"using-lagoon-the-basics/lagoon-yml/#general-settings","text":"","title":"General Settings"},{"location":"using-lagoon-the-basics/lagoon-yml/#docker-compose-yaml","text":"Tells the build script which docker-compose YAML file should be used, in order to learn which services and containers should be deployed. This defaults to docker-compose.yml , but could be used for a specific Lagoon docker-compose YAML file if needed.","title":"docker-compose-yaml"},{"location":"using-lagoon-the-basics/lagoon-yml/#environment_variablesgit_sha","text":"This setting allows you to enable injecting the deployed Git SHA into your project as an environment variable. By default this is disabled. Setting the value to true sets the SHA as the environment variable LAGOON_GIT_SHA .","title":"environment_variables.git_sha"},{"location":"using-lagoon-the-basics/lagoon-yml/#tasks","text":"There are different type of tasks you can define, and they differ in when exactly they are executed in a build flow:","title":"Tasks"},{"location":"using-lagoon-the-basics/lagoon-yml/#pre-rollout-tasks-pre_rolloutirun","text":"Here you can specify tasks which will run against your project after all images have been successfully built, but before : Any running containers are updated with the newly built images. Any other changes are made to your existing environment. This feature enables you to, for example, create a database dump before updating your application. This can make it easier to roll back in case of a problem with the deploy. Note: The pre-rollout tasks run in the existing pods before they are updated , which means: Changes made to your Dockerfile since the last deploy will not be visible when pre-rollout tasks run. If there are no existing containers (e.g. on the initial deployment of a new environment), pre-rollout tasks are skipped.","title":"Pre-Rollout Tasks - pre_rollout.[i].run"},{"location":"using-lagoon-the-basics/lagoon-yml/#post-rollout-tasks-post_rolloutirun","text":"Here you can specify tasks which need to run against your project, after : All images have been successfully built. All containers are updated with the new images. All containers are running have passed their readiness checks. Common uses for post-rollout tasks include running drush updb , drush cim , or clearing various caches. name The name is an arbitrary label for making it easier to identify each task in the logs. command Here you specify what command should run. These are run in the WORKDIR of each container, for Lagoon images this is /app , keep this in mind if you need to cd into a specific location to run your task. service The service which to run the task in. If following our Drupal example, this will be the CLI container, as it has all your site code, files, and a connection to the database. Typically you do not need to change this. shell Which shell should be used to run the task in. By default sh is used, but if the container also has other shells (like bash , you can define it here). This is useful if you want to run some small if/else bash scripts within the post-rollouts. (see the example above how to write a script with multiple lines). when The \"when\" clause allows for the conditional running of tasks. It expects an expression that will evaluate to a true/false value which determines whether the task should be run. Note: If you would like to temporarily disable pre/post-rollout tasks during a deployment, you can set either of the following environment variables in the API at the project or environment level (see how on Environment Variables ). LAGOON_PREROLLOUT_DISABLED=true LAGOON_POSTROLLOUT_DISABLED=true","title":"Post-Rollout Tasks - post_rollout.[i].run"},{"location":"using-lagoon-the-basics/lagoon-yml/#example-post-rollout-tasks","text":"Here are some useful examples of post-rollout tasks that you may want to use or adapt for your projects. Run only if Drupal not installed: .lagoon.yml - run : name : IF no Drupal installed command : | if tables=$(drush sqlq \"show tables like 'node';\") && [ -z \"$tables\" ]; then #### whatever you like fi service : cli shell : bash Different tasks based on branch name: .lagoon.yml - run : name : Different tasks based on branch Name command : | ### Runs if current branch is not 'production' service : cli when : LAGOON_GIT_BRANCH != \"production\" Run shell script: .lagoon.yml - run : name : Run Script command : './scripts/script.sh' service : cli Drupal & Drush 9: Sync database & files from master environment: .lagoon.yml - run : name : Sync DB and Files from master if we are not on master command : | # Only if we don't have a database yet if tables=$(drush sqlq 'show tables;') && [ -z \"$tables\" ]; then drush sql-sync @lagoon.master @self drush rsync @lagoon.master:%files @self:%files -- --omit-dir-times --no-perms --no-group --no-owner --chmod=ugo=rwX fi service : cli when : LAGOON_ENVIRONMENT_TYPE != \"production\"","title":"Example post-rollout tasks"},{"location":"using-lagoon-the-basics/lagoon-yml/#backup-retention","text":"","title":"Backup Retention"},{"location":"using-lagoon-the-basics/lagoon-yml/#backup-retentionproductionmonthly","text":"Specify the number of monthly backups Lagoon should retain for your project's production environment(s). The global default is 1 if this value is not specified.","title":"backup-retention.production.monthly"},{"location":"using-lagoon-the-basics/lagoon-yml/#backup-retentionproductionweekly","text":"Specify the number of weekly backups Lagoon should retain for your project's production environment(s). The global default is 6 if this value is not specified.","title":"backup-retention.production.weekly"},{"location":"using-lagoon-the-basics/lagoon-yml/#backup-retentionproductiondaily","text":"Specify the number of daily backups Lagoon should retain for your project's production environment(s). The global default is 7 if this value is not specified.","title":"backup-retention.production.daily"},{"location":"using-lagoon-the-basics/lagoon-yml/#backup-retentionproductionhourly","text":"Specify the number of hourly backups Lagoon should retain for your project's production environment(s). The global default is 0 if this value is not specified.","title":"backup-retention.production.hourly"},{"location":"using-lagoon-the-basics/lagoon-yml/#backup-schedule","text":"","title":"Backup Schedule"},{"location":"using-lagoon-the-basics/lagoon-yml/#backup-scheduleproduction","text":"Specify the schedule for which backups will be ran for this project. Accepts cron compatible syntax with the notable exception that the Minute block must be the letter M . Any other value in the Minute block will cause the Lagoon build to fail. This allows Lagoon to randomly choose a specific minute for these backups to happen, while users can specify the remainder of the schedule down to the hour. The global default is M H(22-2) * * * if this value is not specified. Take note that these backups will use the cluster's local timezone.","title":"backup-schedule.production"},{"location":"using-lagoon-the-basics/lagoon-yml/#routes","text":"","title":"Routes"},{"location":"using-lagoon-the-basics/lagoon-yml/#routesautogenerateenabled","text":"This allows for the disabling of the automatically created routes (NOT the custom routes per environment, see below for them) all together.","title":"routes.autogenerate.enabled"},{"location":"using-lagoon-the-basics/lagoon-yml/#routesautogenerateallowpullrequests","text":"This allows pull request to get autogenerated routes when route autogeneration is disabled. .lagoon.yml routes : autogenerate : enabled : false allowPullrequests : true","title":"routes.autogenerate.allowPullrequests"},{"location":"using-lagoon-the-basics/lagoon-yml/#routesautogenerateinsecure","text":"This allows you to define the behavior of the automatic creates routes (NOT the custom routes per environment, see below for more). The following options are allowed: Allow simply sets up routes for both HTTP and HTTPS (this is the default). Redirect will redirect any HTTP requests to HTTPS. None will mean a route for HTTP will not be created, and no redirect.","title":"routes.autogenerate.insecure"},{"location":"using-lagoon-the-basics/lagoon-yml/#routesautogenerateprefixes","text":"This allows you to define an array of prefixes to be prepended to the autogenerated routes of each environment. This is useful for things like language prefix domains, or a multi-domain site using the Drupal domain module. NOTE: This is only available for projects which deploy to a Kubernetes cluster. .lagoon.yml routes : autogenerate : prefixes : - www - de - fr - it","title":"routes.autogenerate.prefixes"},{"location":"using-lagoon-the-basics/lagoon-yml/#environments","text":"Environment names match your deployed branches or pull requests. This allows for each environment to have a different config. In our example it will apply to the main and staging environment.","title":"Environments"},{"location":"using-lagoon-the-basics/lagoon-yml/#environmentsnamemonitoring_urls","text":"Danger: This feature will be removed in an upcoming release of Lagoon. Please use the newer monitoring-path method on your specific route. Note: Please note, Lagoon does not provide any direct integration to a monitoring service, this just adds the URLs to the API. On amazee.io, we take the monitoring_urls and add them to our StatusCake account. At the end of a deploy, Lagoon will check this field for any URLs which you have specified to add to the API for the purpose of monitoring. The default value for this field is the first route for a project. It is useful for adding specific paths of a project to the API, for consumption by a monitoring service.","title":"environments.[name].monitoring_urls"},{"location":"using-lagoon-the-basics/lagoon-yml/#environmentsnameroutes","text":"In the route section, we identify the domain names to which the environment will respond. It is typical to only have an environment with routes specified for your production environment. All environments receive a generated route, but sometimes there is a need for a non-production environment to have its own domain name. You can specify it here, and then add that domain with your DNS provider as a CNAME to the generated route name (these routes publish in deploy messages). The first element after the environment is the target service, Nginx in our example. This is how we identify which service incoming requests will be sent to. The simplest route is the example.com example in our sample .lagoon.yml above - you can see it has no additional configuration. This will assume that you want a Let's Encrypt certificate for your route and no redirect from HTTPS to HTTP. In the \"www.example.com\" example repeated below, we see two more options (also notice the : at the end of the route and that the route is wrapped in \" , that's important!):","title":"environments.[name].routes"},{"location":"using-lagoon-the-basics/lagoon-yml/#ssl-configuration-tls-acme","text":"tls-acme: 'true' tells Lagoon to issue a Let's Encrypt certificate for that route. This is the default. If you don't want a Let's Encrypt, set this to tls-acme: 'false' insecure can be set to None , Allow or Redirect . Allow simply sets up both routes for HTTP and HTTPS (this is the default). Redirect will redirect any HTTP requests to HTTPS. None will mean a route for HTTP will not be created, and no redirect will take place. hsts can be set to a value of max-age=31536000;includeSubDomains;preload . Ensure there are no spaces and no other parameters included. Only the max-age parameter is required. The required max-age parameter indicates the length of time, in seconds, the HSTS policy is in effect for. Note: If you plan to switch from a SSL certificate signed by a Certificate Authority (CA) to a Let's Encrypt certificate, it's best to get in touch with your Lagoon administrator to oversee the transition. There are known issues during the transition. The workaround would be manually removing the CA certificate and then triggering the Let's Encrypt process. .lagoon.yml - \"www.example.com\" : tls-acme : 'true' insecure : Redirect hsts : max-age=31536000","title":"SSL Configuration - tls-acme"},{"location":"using-lagoon-the-basics/lagoon-yml/#monitoring-a-specific-path","text":"When UptimeRobot is configured for your cluster (Kubernetes or OpenShift), Lagoon will inject annotations to each route/ingress for use by the stakater/IngressControllerMonitor . The default action is to monitor the homepage of the route. If you have a specific route to be monitored, this can be overridden by adding a monitoring-path to your route specification. A common use is to set up a path for monitoring which bypasses caching to give a more real-time monitoring of your site. .lagoon.yml - \"www.example.com\" : monitoring-path : \"/bypass-cache\"","title":"Monitoring a specific path"},{"location":"using-lagoon-the-basics/lagoon-yml/#ingress-annotations","text":"Note: Route/Ingress annotations are only supported by projects that deploy into clusters that run nginx-ingress controllers! Check with your Lagoon administrator if this is supported. annotations can be a yaml map of annotations supported by the nginx-ingress controller , this is specifically useful for easy redirects and other configurations.","title":"Ingress annotations"},{"location":"using-lagoon-the-basics/lagoon-yml/#restrictions","text":"Some annotations are disallowed or partially restricted in Lagoon. The table below describes these rules. If your .lagoon.yml contains one of these annotations it will cause a build failure. Annotation Notes nginx.ingress.kubernetes.io/auth-snippet Disallowed nginx.ingress.kubernetes.io/configuration-snippet Restricted to rewrite , add_header , set_real_ip , and more_set_headers directives. nginx.ingress.kubernetes.io/modsecurity-snippet Disallowed nginx.ingress.kubernetes.io/server-snippet Restricted to rewrite , add_header , set_real_ip , and more_set_headers directives. nginx.ingress.kubernetes.io/stream-snippet Disallowed nginx.ingress.kubernetes.io/use-regex Disallowed","title":"Restrictions"},{"location":"using-lagoon-the-basics/lagoon-yml/#ingress-annotations-redirects","text":"In this example any requests to example.ch will be redirected to https://www.example.ch with keeping folders or query parameters intact ( example.com/folder?query -> https://www.example.ch/folder?query ) .lagoon.yml - \"example.ch\" : annotations : nginx.ingress.kubernetes.io/permanent-redirect : https://www.example.ch$request_uri - www.example.ch You can of course also redirect to any other URL not hosted on Lagoon, this will direct requests to example.de to https://www.google.com .lagoon.yml - \"example.de\" : annotations : nginx.ingress.kubernetes.io/permanent-redirect : https://www.google.com","title":"Ingress annotations redirects"},{"location":"using-lagoon-the-basics/lagoon-yml/#trusted-reverse-proxies","text":"Warning: Kubernetes will only process a single nginx.ingress.kubernetes.io/server-snippet annotation. Please ensure that if you use this annotation on a non-production environment route that you also include the add_header X-Robots-Tag \"noindex, nofollow\"; annotation as part of your server-snippet. This is needed to stop robots from crawling development environments as the default server-snippet set to prevent this in development environments in the ingress templates will get overwritten with any server-snippets set in .lagoon.yml. Some configurations involve a reverse proxy (like a CDN) in front of the Kubernetes Clusters. In these configurations the IP of the Reverse Proxy will appear as the REMOTE_ADDR HTTP_X_REAL_IP HTTP_X_FORWARDED_FOR headers field in your applications. While the original IP of the requester can be found in the HTTP_X_ORIGINAL_FORWARDED_FOR header. If you like the original IP to appear in the REMOTE_ADDR HTTP_X_REAL_IP HTTP_X_FORWARDED_FOR headers, you need to tell the ingress which reverse proxy IPs you want to trust: .lagoon.yml - \"example.ch\" : annotations : nginx.ingress.kubernetes.io/server-snippet : | set_real_ip_from 1.2.3.4/32; This example would trust the CIDR 1.2.3.4/32 (the IP 1.2.3.4 in this case). Therefore if there is a request sent to the Kubernetes cluster from the IP 1.2.3.4 the X-Forwarded-For Header is analyzed and it's contents injected into REMOTE_ADDR HTTP_X_REAL_IP HTTP_X_FORWARDED_FOR headers.","title":"Trusted Reverse Proxies"},{"location":"using-lagoon-the-basics/lagoon-yml/#environmentsnametypes","text":"The Lagoon build process checks the lagoon.type label from the docker-compose.yml file in order to learn what type of service should be deployed (read more about them in the documentation of docker-compose.yml ). Sometimes you might want to override the type just for a single environment, and not for all of them. For example, if you want a standalone MariaDB database (instead of letting the Service Broker/operator provision a shared one) for your non-production environment called develop : service-name: service-type service-name is the name of the service from docker-compose.yml you would like to override. service-type the type of the service you would like to use in your override. Example for setting up MariaDB_Galera: .lagoon.yml environments : develop : types : mariadb : mariadb-single","title":"Environments.[name].types"},{"location":"using-lagoon-the-basics/lagoon-yml/#environmentsnametemplates","text":"The Lagoon build process checks the lagoon.template label from the docker-compose.yml file in order to check if the service needs a custom template file (read more about them in the documentation of docker-compose.yml ). Sometimes you might want to override the template just for a single environment, and not for all of them: service-name: template-file service-name is the name of the service from docker-compose.yml you would like to override. template-file is the path and name of the template to use for this service in this environment. Example : .lagoon.yml environments : main : templates : mariadb : mariadb.main.deployment.yml","title":"environments.[name].templates"},{"location":"using-lagoon-the-basics/lagoon-yml/#environmentsnamerollouts","text":"The Lagoon build process checks the lagoon.rollout label from the docker-compose.yml file in order to check if the service needs a special rollout type (read more about them in the documentation of docker-compose.yml ) Sometimes you might want to override the rollout type just for a single environment, especially if you also overwrote the template type for the environment: service-name: rollout-type service-name is the name of the service from docker-compose.yml you would like to override. rollout-type is the type of rollout. See documentation of docker-compose.yml ) for possible values. Example: .lagoon.yml environments : main : rollouts : mariadb : statefulset","title":"environments.[name].rollouts"},{"location":"using-lagoon-the-basics/lagoon-yml/#environmentsnameautogenerateroutes","text":"This allows for any environments to get autogenerated routes when route autogeneration is disabled. .lagoon.yml routes : autogenerate : enabled : false environments : develop : autogenerateRoutes : true","title":"environments.[name].autogenerateRoutes"},{"location":"using-lagoon-the-basics/lagoon-yml/#cron-jobs-environmentsnamecronjobs","text":"As most of the time it is not desirable to run the same cron jobs across all environments, you must explicitly define which jobs you want to run for each environment. Example: .lagoon.yml cronjobs : - name : drush cron schedule : \"M * * * *\" # This will run the cron once per hour. command : drush cron service : cli name: Just a friendly name for identifying what the cron job will do. schedule: The schedule for executing the cron job. This follows the standard convention of cron. If you're not sure about the syntax, Crontab Generator can help. You can specify M for the minute, and your cron job will run once per hour at a random minute (the same minute each hour), or M/15 to run it every 15 mins, but with a random offset from the hour (like 6,21,36,51 ). It is a good idea to spread out your cron jobs using this feature, rather than have them all fire off on minute 0 . You can specify H for the hour, and your cron job will run once per day at a random hour (the same hour every day), or H(2-4) to run it once per day within the hours of 2-4. Notes on timezones: The default timezone for cron jobs is UTC. Native cron jobs will run in timezone of the node, which is UTC. In-pod cron jobs == timezone of the pod it is running in, which defaults to UTC but may be different if you have configured it. command: The command to execute. Like the tasks, this executes in the WORKDIR of the service. For Lagoon images, this is /app . service: Which service of your project to run the command in. For most projects, this is the CLI service.","title":"Cron jobs - environments.[name].cronjobs"},{"location":"using-lagoon-the-basics/lagoon-yml/#polysite","text":"In Lagoon, the same Git repository can be added to multiple projects, creating what is called a polysite. This allows you to run the same codebase, but allow for different, isolated, databases and persistent files. In .lagoon.yml , we currently only support specifying custom routes for a polysite project. The key difference from a standard project is that the environments becomes the second-level element, and the project name the top level. To utilise this, you will need to: Create two (or more) projects in Lagoon, each configured with the same gitUrl and production branch, named as per the .lagoon.yml (i.e poly-project1 and poly-project2 below) Add the deploy keys from each project to the git repo Configure the webhook for the repo (if required) - you can then push/deploy. Note that a push to the repo will simultaneously deploy all projects/branches for that gitUrl Example: .lagoon.yml poly-project1 : environments : main : routes : - nginx : - project1.com poly-project2 : environments : main : routes : - nginx : - project2.com","title":"Polysite"},{"location":"using-lagoon-the-basics/lagoon-yml/#specials","text":"","title":"Specials"},{"location":"using-lagoon-the-basics/lagoon-yml/#api","text":"Note: If you run directly on amazee.io hosted Lagoon you will not need this key set. With the key api you can define another URL that should be used by the Lagoon CLI and drush to connect to the Lagoon GraphQL API. This needs to be a full URL with a scheme, like: http://localhost:3000 This usually does not need to be changed, but there might be situations where your Lagoon administrator tells you to do so.","title":"api"},{"location":"using-lagoon-the-basics/lagoon-yml/#ssh","text":"Note: If you run directly on amazee.io hosted Lagoon you will not need this key set. With the key ssh you can define another SSH endpoint that should be used by the Lagoon CLI and drush to connect to the Lagoon remote shell service. This needs to be a hostname and a port separated by a colon, like: localhost:2020 This usually does not need to be changed, but there might be situations where your Lagoon administrator tells you to do so.","title":"ssh"},{"location":"using-lagoon-the-basics/lagoon-yml/#container-registries","text":"The container-registries block allows you to define your own private container registries to pull custom or private images. To use a private container registry, you will need a username , password , and optionally the url for your registry. If you don't specify a url in your YAML, it will default to using Docker Hub. There are 2 ways to define the password used for your registry user. Create an environment variable in the Lagoon API with the type container_registry : lagoon add variable -p <project_name> -N <registry_password_variable_name> -V <password_goes_here> -S container_registry (see more on Environment Variables ) The name of the variable you create can then be set as the password: container-registries : my-custom-registry : username : myownregistryuser password : <registry_password_variable_name> url : my.own.registry.com You can also define the password directly in the .lagoon.yml file in plain text: .lagoon.yml container-registries : docker-hub : username : dockerhubuser password : MySecretPassword","title":"container-registries"},{"location":"using-lagoon-the-basics/lagoon-yml/#consuming-a-custom-or-private-container-registry-image","text":"To consume a custom or private container registry image, you need to update the service inside your docker-compose.yml file to use a build context instead of defining an image: .docker-compose.yml services : mariadb : build : context : . dockerfile : Dockerfile.mariadb Once the docker-compose.yml file has been updated to use a build, you need to create the Dockerfile.<service> and then set your private image as the FROM <repo>/<name>:<tag> FROM dockerhubuser/my-private-database:tag","title":"Consuming a custom or private container registry image"},{"location":"using-lagoon-the-basics/lagoon-yml/#example-lagoonyml","text":"This is an example .lagoon.yml which showcases all possible settings. You will need to adapt it to your project. .lagoon.yml docker-compose-yaml : docker-compose.yml environment_variables : git_sha : 'true' tasks : pre-rollout : - run : name : drush sql-dump command : mkdir -p /app/web/sites/default/files/private/ && drush sql-dump --ordered-dump --gzip --result-file=/app/web/sites/default/files/private/pre-deploy-dump.sql.gz service : cli post-rollout : - run : name : drush cim command : drush -y cim service : cli shell : bash - run : name : drush cr command : drush -y cr service : cli routes : autogenerate : insecure : Redirect environments : main : monitoring_urls : - \"https://www.example.com\" - \"https://www.example.com/special_page\" routes : - nginx : - example.com - example.net - \"www.example.com\" : tls-acme : 'true' insecure : Redirect hsts : max-age=31536000 - \"example.ch\" : annotations : nginx.ingress.kubernetes.io/permanent-redirect : https://www.example.ch$request_uri - www.example.ch types : mariadb : mariadb templates : mariadb : mariadb.main.deployment.yml rollouts : mariadb : statefulset cronjobs : - name : drush cron schedule : \"M * * * *\" # This will run the cron once per hour. command : drush cron service : cli staging : cronjobs : - name : drush cron schedule : \"M * * * *\" # This will run the cron once per hour. command : drush cron service : cli feature/feature-branch : cronjobs : - name : drush cron schedule : \"H * * * *\" # This will run the cron once per hour. command : drush cron service : cli","title":"Example .lagoon.yml"},{"location":"using-lagoon-the-basics/local-development-environments/","text":"Local Development Environments # Even though Lagoon has only a hard dependency on Docker and Docker Compose (which is mostly shipped with Docker) there are some things which are nice for local development that are not included in Docker: An HTTP reverse proxy for nice URLs and HTTPS offloading. A DNS system so we don't have to remember IP addresses. SSH agents to use SSH keys within containers. A system that receives and displays mail locally. Warning: You do not need to install Lagoon locally to use it locally! That sounds confusing but follow the documentation. Lagoon is the system that deploys your local development environment to your production environment, it's not the environment itself. pygmy or Lando - the choice is yours # Lagoon has traditionally worked best with pygmy , which is the amazee.io flavored system of the above tools and works out of the box with Lagoon. It lives at https://github.com/pygmystack/pygmy pygmy is written in Golang, so to install it, run: brew tap pygmystack/pygmy && brew install pygmy . For detailed usage or installation info on pygmy, see its documentation . As announced in our blog post , Lagoon is now also compatible with Lando! For more information, please see the documentation at https://docs.lando.dev/config/lagoon.html to get yourself up and running. Lando's workflow for Lagoon will be familiar to users of Lando, and will also be the easiest way for Lagoon newcomers to get up and running. Pygmy presents a closer integration with Docker, which will lend itself better to more complex scenarios and use cases but will also require a deeper understanding. We have previously evaluated adding support for other systems like Docksal and Docker4Drupal , and while we may add support for these in the future, our current focus is on supporting using Lando and pygmy. If you do have Lagoon running with one of these (or other) tools, we would love for you to submit a PR on GitHub !","title":"Local Development Environments"},{"location":"using-lagoon-the-basics/local-development-environments/#local-development-environments","text":"Even though Lagoon has only a hard dependency on Docker and Docker Compose (which is mostly shipped with Docker) there are some things which are nice for local development that are not included in Docker: An HTTP reverse proxy for nice URLs and HTTPS offloading. A DNS system so we don't have to remember IP addresses. SSH agents to use SSH keys within containers. A system that receives and displays mail locally. Warning: You do not need to install Lagoon locally to use it locally! That sounds confusing but follow the documentation. Lagoon is the system that deploys your local development environment to your production environment, it's not the environment itself.","title":"Local Development Environments"},{"location":"using-lagoon-the-basics/local-development-environments/#pygmy-or-lando-the-choice-is-yours","text":"Lagoon has traditionally worked best with pygmy , which is the amazee.io flavored system of the above tools and works out of the box with Lagoon. It lives at https://github.com/pygmystack/pygmy pygmy is written in Golang, so to install it, run: brew tap pygmystack/pygmy && brew install pygmy . For detailed usage or installation info on pygmy, see its documentation . As announced in our blog post , Lagoon is now also compatible with Lando! For more information, please see the documentation at https://docs.lando.dev/config/lagoon.html to get yourself up and running. Lando's workflow for Lagoon will be familiar to users of Lando, and will also be the easiest way for Lagoon newcomers to get up and running. Pygmy presents a closer integration with Docker, which will lend itself better to more complex scenarios and use cases but will also require a deeper understanding. We have previously evaluated adding support for other systems like Docksal and Docker4Drupal , and while we may add support for these in the future, our current focus is on supporting using Lando and pygmy. If you do have Lagoon running with one of these (or other) tools, we would love for you to submit a PR on GitHub !","title":"pygmy or Lando - the choice is yours"},{"location":"using-lagoon-the-basics/setup-project/","text":"Set Up a New Project # Note: NOTE: We are working hard on getting our CLI and GraphQL API set up to allow everyone using Lagoon to setup and configure their projects themselves. Right now, it needs more testing before we can release those features, so hold tight! Until then, the setup of a new project involves talking to your Lagoon administrator, which is ok, as they are much friendlier than APIs. \ud83d\ude0a Please have the following information ready for your Lagoon administrator: A name you would like the project to be know by This name can only contain lowercase characters, numbers and dashes Double dashes ( -- ) are not allowed within a project name SSH public keys, email addresses and the names of everybody that will work on this project. Here are instructions for generating and copying SSH keys for GitHub , GitLab , and Bitbucket . The URL of the Git repository where your code is hosted ( git@example.com:test/test.git ). The name of the Git branch you would like to use for your production environment (see Environment Types for details about the environments). Which branches and pull requests you would like to deploy to your additional environments. With Lagoon, you can filter branches and pull requests by name with regular expressions, and your Lagoon administrator can get this set up for you. We suggest deploying specific important branches (like develop and main ) and pull requests. But that's all up to you! (see Workflows for some more information) 1. Make sure your project is Lagoonized # This means that the .lagoon.yml and docker-compose.yml files are available in your Git repository and configured accordingly. If this is not the case, check out the list of Step-by-Step Guides on how to do so before proceeding. 2. Provide access to your code # In order to deploy your code, Lagoon needs access to it. By design and for security, Lagoon only needs read access to your Git repository. Your Lagoon administrator will tell you the SSH public key or the Git account to give read access to. 3. Configure Webhooks # Lagoon needs to be informed about a couple of events that are happening to your Git repository. Currently these are pushes and pull requests, but we may add more in the future. As Lagoon supports many different Git hosts, we have split off those instructions into this documentation: Configure Webhooks . 4. Next: First deployment # Congratulations, you are now ready to run your first deployment .","title":"Set Up a New Project"},{"location":"using-lagoon-the-basics/setup-project/#set-up-a-new-project","text":"Note: NOTE: We are working hard on getting our CLI and GraphQL API set up to allow everyone using Lagoon to setup and configure their projects themselves. Right now, it needs more testing before we can release those features, so hold tight! Until then, the setup of a new project involves talking to your Lagoon administrator, which is ok, as they are much friendlier than APIs. \ud83d\ude0a Please have the following information ready for your Lagoon administrator: A name you would like the project to be know by This name can only contain lowercase characters, numbers and dashes Double dashes ( -- ) are not allowed within a project name SSH public keys, email addresses and the names of everybody that will work on this project. Here are instructions for generating and copying SSH keys for GitHub , GitLab , and Bitbucket . The URL of the Git repository where your code is hosted ( git@example.com:test/test.git ). The name of the Git branch you would like to use for your production environment (see Environment Types for details about the environments). Which branches and pull requests you would like to deploy to your additional environments. With Lagoon, you can filter branches and pull requests by name with regular expressions, and your Lagoon administrator can get this set up for you. We suggest deploying specific important branches (like develop and main ) and pull requests. But that's all up to you! (see Workflows for some more information)","title":"Set Up a New Project"},{"location":"using-lagoon-the-basics/setup-project/#1-make-sure-your-project-is-lagoonized","text":"This means that the .lagoon.yml and docker-compose.yml files are available in your Git repository and configured accordingly. If this is not the case, check out the list of Step-by-Step Guides on how to do so before proceeding.","title":"1. Make sure your project is Lagoonized"},{"location":"using-lagoon-the-basics/setup-project/#2-provide-access-to-your-code","text":"In order to deploy your code, Lagoon needs access to it. By design and for security, Lagoon only needs read access to your Git repository. Your Lagoon administrator will tell you the SSH public key or the Git account to give read access to.","title":"2. Provide access to your code"},{"location":"using-lagoon-the-basics/setup-project/#3-configure-webhooks","text":"Lagoon needs to be informed about a couple of events that are happening to your Git repository. Currently these are pushes and pull requests, but we may add more in the future. As Lagoon supports many different Git hosts, we have split off those instructions into this documentation: Configure Webhooks .","title":"3. Configure Webhooks"},{"location":"using-lagoon-the-basics/setup-project/#4-next-first-deployment","text":"Congratulations, you are now ready to run your first deployment .","title":"4. Next: First deployment"}]}